[
["index.html", "Quantitative sociology of academic work in an era of hypercompetition and rankings Chapter 1 Prologue 1.1 Foreword 1.2 Acknowledgments 1.3 Summary of the thesis", " Quantitative sociology of academic work in an era of hypercompetition and rankings Aliakbar Akbaritabar 2019-04-01 Chapter 1 Prologue 1.1 Foreword This dissertation aims to investigate the academic work in 21st century with a quantitative approach. It is a collection of individual articles that revolve around a general theme, i.e., understanding scientist behavior and changing patterns of collaboration, with a special attention to sociologists. We are focused on the tension between “publish or perish” from one hand and being part of the “scholarly community” on the other. The “Summary” Section clarifies the outline of the articles and introduces the reader to the subject, trying to provide a coherent picture of the main challenges of studying academic work today. 1.2 Acknowledgments During my master studies, I started to develop an interest in studying scientific collaborations, scientist behaviour and the evolution of the scientific community. My main puzzle was to understand why sociologists in my home country, Iran, never developed a transparent reward system. Reputation, academic credit and status were not coherent with knowledge development and international standards of evaluation were not considered. Each sociologist I was being trained with in three different universities was genuinely convinced that his/her way of doing sociology was the right way, probably even the unique, whether qualitative, quantitative or – tribute paid to a modern fashion probably - mixed methods. When I proposed this subject as my master dissertation, I was unable to convince anyone of the importance of it. This is when I started studying online social networks. Indeed, in my first PhD thesis in Iran, I examined cyber social capital and resource exchange in online networks. When I started my second PhD in Brescia and Milan, my research proposal was simply a follow-up of the former. However, when I started collaborating with my supervisor, Flaminio Squazzoni, I realized that he had a deep interest in science [sociology] of science, also due to his role as chair of an ongoing COST action on peer review, i.e., PEERE. Our discussion reinvigorated my original interest in studying scientific collaboration and eventually we agreed to make this the subject of my research project. I must say that I am happy that this happened. I am deeply indebted to Flaminio’s kind help and our discussions around different aspects of the academic life in 21st century. I am even no longer able to differentiate what idea is mine and what is his here. I am indebted of his genuine collaboration in improving our research, from initial ideas to final versions of manuscripts. I also have benefited from presenting my research project and preliminary versions of the chapters during the past three years in different venues which are presented in the “Timeline of PhD” Section. In different articles we had unique opportunity of receiving insights from knowledgeable coauthors whose names are mentioned in each chapter. During my research visit in CWTS (Center for Science and Technology Studies), Leiden university, I was closely supervised by Vincent Traag. His helps was immense in all aspects of research from introducing up-to-date literature (e.g., to read and replicate), to his deep knowledge of cutting edge techniques and methodologies. He was ready to take my laptop and dive into the Python scripts and revise them, it all amazed me and I am greatly indebted for his kind help during my short stay in Leiden. In UCD (University College Dublin), Dublin, I had the opportunity to discuss my research with Diane Payne, Alberto Caimo, Nial Friel and Paola Zappa. I enjoyed these discussions and I learned a lot from them. Alberto helped me in designing and carrying out statistical models for coauthorship networks, which have been included in the Chapter 6 of this thesis. My family has always supported me during my long educational journey. I am grateful of their unconditional love and support. During past three years I have enjoyed fruitful discussions with my colleagues in Milan, Brescia, Leiden, Dublin and Berlin, to name a few of them, I am indebted to Federico Bianchi, Dehua Gao, Davide Zampatti, Niccolò Casnici, Simone Gabbriellini, Marco Castellani, Roland Adorjáni, Rouhollah Jalili, Zohreh Zahedi, Bijan Ranjbar-Sahraei, Jochem Zuijderwijk and Paul Donner. From distance I have learned a lot from Hadley Wickham, Yihui Xie, Raffaele Vacca and amazing communities on Twitter i.e. #RStats, #Tidyverse and #AcademicTwitter. Finally, I would like to thank very much the two external reviewers of the PhD thesis. I enjoyed reading their precise, detailed and fair comments and useful suggestions on how to improve the text. 1.3 Summary of the thesis In recent years, higher education institutes have shifted towards managerial organisational models. Some observers see this as a sign of our neoliberal times, with obsession for rankings, performance indicators and resource allocation. The result is that academic work is more competitive nowadays. Rankings and quantitative analysis of research output are more and more crucial for hiring, promotion and funding allocations. Chapter 2 touches upon these themes and suggests the fruitfulness of cross-fertilization between sociology and science studies. To study this hyper-competitive context, we designed a complex research project to answer different questions regarding multi-faceted aspects of the subject. Our main question was to find what factors drive research collaboration and productivity. These factors are helping some researchers be more successful than others in current evaluation based system. We have employed two sets of data to achieve this goal. One national and one international, both considering the case of sociologists. For individual research productivity measurement and to explore correlates of this productivity (Chapter 3) and macro level policy effect analysis (Chapter 4), we reconstructed the full publication list of all currently hired Italian sociologists on available data. We looked into their research productivity and how they have reacted to the ANVUR national policies by taking into account their embeddedness in different academic contexts. Our aim in Chapter 3 was to explain individual research productivity with organisational embeddedness and we found that male scientists, those working more internationally, and those working with a similar group of coauthors were more productive but not necessarily more cited by other members of the community. In Chapter 4, we analysed the effects of the Italian national research assessment exercise (VQR 2004-2010 by ANVUR) on research productivity and publication behavior of sociologists. Results showed that ANVUR had a limited influence on research productivity. Indeed most differences in individual research productivity of Italian sociologists were due to individual characteristics. Academics who experienced a promotion after 2010 were the most prolific authors. To explore the structural and societal effects on research productivity of sociologists in a more competitive arena at the international level, in Chapter 5, we reconstructed gender, background information and coauthorship networks of all published authors in two top sociology journals, i.e., the American Journal of Sociology (AJS) and the American Sociological Review (ASR). We expected that examining the élite of our community could reveal interesting patterns, especially to understand certain implications of the hyper-competitive academic culture. We found that white male authors affiliated to US institutes were over-represented in these journals. We also found that male authors tended to work more in team and found trace of significant gender and ethnicity penalties. In Chapter 6 we looked into research communities formation and evolution through the time among Italian sociologists. We aimed to investigate if being a member of these communities would inspire different patterns of scientific collaboration among Italian sociologists. We used a sophisticated multi-level design by using temporal community detection. We found the two largest and most stable research communities among Italian sociologists who were political and economic sociologists. We further explored the underlying mechanisms and processes of coauthorship tie existence in multi-level exponential random graph models (ERGMs) trying to take individual, community and macro levels into account in one integrated framework. We found that the collaboration ties were mainly driven by research focus while preferential attachment was also at work and highly prolific researchers attracted further coauthorship ties. In Chapter 7, we conclude by emphasizing that academic work has changed drastically in 21st century. Scientific collaboration is a multi-faceted phenomenon and any effort at studying it only with one or two approaches or with one observational unit would yield reductionistic results. That was the main reason behind our effort to investigate this phenomenon from different points of views. Finally, in Appendices Chapter, how to access the data and R and Python scripts developed during this research project is described and an Annotated bibliography on different aspects of academic work is provided. Key Words: Academic work; Quantitative Research Evaluation; Coauthorship networks; Temporal Community Detection; ERGM; Embeddedness; Multi-level Analysis "],
["introchapter.html", "Chapter 2 Introduction 2.1 A hyper-competitive academic landscape 2.2 Sociological theories 2.3 Discussion", " Chapter 2 Introduction 2.1 A hyper-competitive academic landscape Trends show increases towards larger scientific teams (Wuchty, Jones, and Uzzi 2007; E. B. Araújo et al. 2017), higher number of publications (Ioannidis and Klavans 2018; Moed, Bruin, and R. 1991; Kim 2006), growth of citations (Zhou and Bornmann 2015) and increasing expansion of the academic system in terms of students and faculty members (Young 1995; Lomperis 1990). The increase in size and dimensions of the academia (Smith and Adams 2008; Shepherd 2017) has inspired a culture of quantification and numbers (e.g., funding and grants, publications and citations). This hegemony of numbers gives rise to a higher level of competition (Edwards and Roy 2017) in different aspects of academic research. From the early steps of the academic career (e.g., choosing a research subject) to the last (e.g., publishing and disseminating research results), attention is focused on numbers and output (Jonkers and Zacharewicz 2016). The image of a sole scientist spending years in the lab to answer a single question and publishing a book presenting his solitary scientific effort seems out of time now (Leahey 2016). For instance, an anthropologist spending years living and observing the life of a small tribe, taking notes of people’s behaviour and spending years for presenting his/her work and writing an influential monograph is a not so popular academic model, perhaps possible only in prestigious and well-funded scientific departments. Pressures for funds, recurrent evaluations and multiple tasks seem to conspire against academic freedom with rare examples probably of link between quality and efficiency (e.g., Sandström and Van den Besselaar (2018); Mallapaty (2018)). It is worth noting that the dichotomy of quantity versus quality and the hegemony of quantitative research evaluation are leading academics towards salami slicing and myopic projects (e.g., Dupps and Randleman (2012); Smolčić (2013)). Furthermore, the importance of citations and quantifiable recognition increases the importance of building invisible colleges (Crane 1972) and cartels to cite each other as much as possible (Fister Jr, Fister, and Perc 2016). This leads to a goal displacement in that research follows evaluation priorities more than curiousity and genuine interest (Rijcke et al. 2016). In other words, it seems that today evaluation has become a goal in itself (Marginson and Van der Wende 2007). There is evidence suggesting that academics could be inclined to maximize the impact of their research on evaluation, so trying to game the system (Garcia 2018). The so called pathological publishing and CV manipulation (Casal 2014) and increasing number of scientific fraud and mis-behaviour are examples of this (Fang, Steen, and Casadevall 2012). Considering that disciplinary standards of excellence are often quantified, academics could arrange their research and publication strategies to maximize their impact (Lamont 2009). This in turn leads to higher levels of stress, burnout (Gill 2009) and the fear of missing out on newest scientific outcomes and being behind the frontier (Hanlon 2016). This type of over-competitiveness increasingly demotivates scientists (Carson, Bartneck, and Voges 2013). Five years ago, a senior Nobel prize winner, Peter Higgs said he could not make a life and survive in such a competitive academia (Aitkenhead 2013b, 2013a). Only a few of the scientists worldwide could manage to be hyper-prolific to publish an article every five-calendar days and stay above the average in overall publication rates (Ioannidis and Klavans 2018). Even the highest number of publications can not guarantee any impact on the scientific community. Occupying status of an impressive scientist requires that academics publish in diverse substantive areas. It might then draw higher attention from different sub-communities (e.g., Merton is named as an example of a scientist with this status by Hargens (2004)). This applies into funding, promotion and reputation, which have drastically changed in the 21st century. Defining who to hire, fund or promote is a matter of evaluation and metrics (Wilsdon et al. 2015; Edwards and Roy 2017; Nederhof 2006; Leahey, Keith, and Crockett 2010; Long 1992; Grant and Ward 1991). The vicious circle of funding scientific projects based on previous scientific activities (Clauset, Larremore, and Sinatra 2017) often results in lower funds for junior researchers and higher funds for senior renown scientists (Merton 1968). This has increased the tendency of doing publishable research and forgetting interesting, genuine challenges (Wang, Veugelers, and Stephan 2017). These constraints are at work when choosing a subject, selecting collaborators and investing in certain sophisticated research methodologies and tools (Rijcke et al. 2016). This also extends to the writing style, with reports that must have a narrative and a format that are compatible with referees and a journal’s audience. The primacy of quantitative assessments has generated a debate in favour of responsible [use of] metrics (Mejlgaard, Woolley, Bloch, Bührer, et al. 2018; Mejlgaard, Woolley, Bloch, Buehrer, et al. 2018; DORA 2012; Wilsdon et al. 2015; Jonkers and Zacharewicz 2016). Some observers have questioned whether the number of metrics and their use made any sense (Bibliomagician 2018; Marginson and Van der Wende 2007). The importance of responsible use of these metrics has called general attention on research institutions and funding agencies, with the necessity to select appropriate methods that respect the context. The recent discussion about peer review versus bibliometrics, informed peer review, and more recently contextualized scientometrics are signs of a reaction to a self-reinforcing process of irresponsible adoption of evaluation metrics (Baccini and De Nicolao 2016; Ancaiani et al. 2015; Bertocchi et al. 2015). Informed peer review (Hicks et al. 2015; Abramo and D’Angelo 2011a) is a modified version of peer review in which evaluators have access to complementary information on the sample of academics they are evaluating. For instance, they can view bibliomertic measures on authors, e.g., h-index, or they can identify the journals and the impact factor of them in case of previously published works submitted for evaluation, e.g., the practice adopted by ANVUR in VQR in Italy. On the one hand, this information could give referees a more thorough and complete picture of the academic under evaluation. On the other hand, this can affect their judgment, especially if personal clues, such as gender, age and academic affiliation, enter the picture. Supporters of informed peer review believe that indicators should be used to support peer review rather than replicating it. More recently, Waltman and Van Eck (2016) has proposed contextualized scientometrics as a means to integrate informed peer review and citation indicators to favour disciplinary specific evaluation. The concept of contextualized scientometrics is an attempt to accommodate the logics of contexts and emerging quantitative standards. That is a relatively new approach proposed to integrate expert judgment and scientometrics indicators. This is an upgraded version of the informed peer review trying to promote three principles, i.e., the context, simplicity and diversity. First, any indicator must be justified by relying on the context in which it is used. For instance, this includes details on the list of publications under evaluation and the definition of fields (in case field-normalized measures are used). Indicators should be as simple as possible and they need to be described clearly. Finally, a diverse array of indicators should be used to complement each other and support peer review (Waltman and Van Eck 2016). This debate includes also attention to a variety of indicators, which can address also the societal impact of research (Bornmann 2013) and its impact on social media (e.g., see the growing field of “altmetrics” Wouters and Costas (2012)) However, there is still need for more comprehensive qualitative understanding of how academics themselves interpret priorities and practices of their scholarly activity (e.g., ACUMEN (2010)) as well as their scientific career and publication trajectories (Way et al. 2016; Cole and Zuckerman 1987). It is worth noting that without a mixture of qualitative and quantitative approaches to evaluation, evaluators can not do a good job in assessing scientist effort (Shapin 2009). It would be even harder to disentangle mechanisms and processes underlying the working of the academic system at more aggregate level, i.e., national assessment. This is confirmed by recent research in which [dis]agreements between peer review and bibliometrics in different contexts have been found that call for the necessity of mixing and complementing different approaches. For example, in the Italian context, results of a recent national assessment showed contested findings, with certain studies suggesting a good level of agreement between peer review and bibliometric analysis (e.g., Bertocchi et al. (2015)), whereas others found inconsistencies (Baccini and De Nicolao 2016) and concluded that bibliometric indicators are more appropriate in evaluating hard sciences (Abramo, D’Angelo, and Caprasecca 2009a). Findings on the case of the UK’s REF were similarly contested (Harzing 2018), with concerns especially on the size-dependency of indicators used and the normalization applied (e.g., Traag and Waltman (2018)). Main emphasize of these re-evaluations are on the lessons to be learned from evaluation experiences in different contexts to overcome some of the issues raised (Bibliomagician 2018; Sivertsen 2017, 2018). Here, the point is that academic collaboration does not happen in a social, institutional and organizational vacuum. Different academic contexts could inspire and motivate different collaboration attitudes (Sonnenwald 2007). For instance, imagine a university department with many specialized scientists exclusively working on their own research subject without any contact as if they were atoms colliding each other only in some department meetings. Now, imagine another department more interdisciplinary with a number of groups who are directed to complement each other’s work on their shared subject matters. In the former, if any collaboration between two scholars will be, perhaps, they will collaborate due to multiple different variables. Probably mostly due to their personal propensity. In the latter case though, collaboration will be the general practice and, for instance, solo-authored articles will be the exception more than the rule (Leahey 2016). To continue with this thought experiment, a network analysis researcher could not study these two idealized departments assuming that in both collaboration triads will naturally tend to close, e.g., a coauthor of one’s coauthors will write probably together. Even in everyday life, we need to study the interaction context before drawing any conclusion on the phenomenon under investigation (Small 2017 p 154). Depending on the space and possibilities of interaction, even strong ties could never meet to close their forbidden triads (Granovetter 1977). This is where the idea of a contextualized study of science is key to study science and scientific activity more sociologically. It must be noted that the context also includes field and disciplinary practices and social and organizational aspects of academic institutes. In academia, professionalism and managerialism gained momentum today while other ways of coordination of the academic work seem to lose their importance. This is evident when looking at university leaders who previously were hybrid figures half academics half part-time administrators while now are executives (Smith and Adams 2008; Shepherd 2017). This has contributed to the diffusion of managerialism, with universities adopting standards, models and practices similar to private institutions (Musselin 2008; Lamont 2017; Kalfa, Wilkinson, and Gollan 2018). This has implied especially an increasing importance of competitive resource allocation, with “economic” criteria of utility often dominating decisions of academic organisations. However, while academia has changed towards a competitive context, work relations, communication ethics and coordination of scholarly tasks are still traditional. The bottom line is, the competition level in academic system has upgraded to a 21st century degree, while the ethics, coordination and scholarly communication is under pressure. We are focused on the tension between “publish or perish” from one hand and being part of the “scholarly community” on the other. In different chapters, we studied a variety of embeddedness scenarios to see how sociologists reacted to this hyper-competitive academic landscape. 2.2 Sociological theories Sociologists react to new social phenomenon in different ways, depth and speed. Their reaction differs both from other fields and between sociological sub-communities. Even considering team science and group-work (Wuchty, Jones, and Uzzi 2007), sociologists seem to adopt slowly (Babchuk, Keith, and Peters 1999) and their behavior is more similar to humanities, e.g., known as sole-scientists (Leahey 2016). This would explain why scientometrics, bibliometrics and information sciences with a focus on science and technology studies have outgrown science studies in sociology. Indeed, science and technology studies’ centers and institutes are populated more by scientometricians, bibliometricians or even physicists, statisticians and computer scientists (Zeng et al. 2017; Clauset, Larremore, and Sinatra 2017) than sociologists (e.g., Center for Science and Technology Studies (CWTS) and German Center for Higher Education Research and Science Studies (DZHW)). This might be because they were more capable of institutionalizing and systematizing their scholarly activity around these subjects (Blume 1987). While each chapter provides an overview to the most relevant literature, here a brief view to sociological theories is presented. Note that some of these views are relatively far from our quantitative approach causing us to keep this overview brief. Theoretical endeavors in social studies of science (SSS) or with further technological advancements, the renamed version science and technology studies (STS) can be divided in two main groups. First, we have social theorists who study science from specific theoretical schools without making this their only specialisation. For example, the prevalence of the structural functionalism in the American sociology reflected in the works by Merton and his students on institutional norms and rewards in science (Ritzer 2004), who examined the famous Matthew effect (Merton 1968; Frank and Cook 2010). Their studies emphasized that highly prolific scientists attract higher collaborations from other scientists. These scientists access more funds, which in turn increase their recognition, which in turn expand their collaboration networks and research team, thereby giving rise to self-reinforcing processes (Sheltzer and Smith 2014). The idea that academics tend to attach preferably to a few star scientists (Moody 2004) has been tested in many studies using novel methodologies borrowed from network analysis and graph theory (Newman 2001a, 2001b), stimulating studies on coauthorship (e.g., in articles, books, grant proposals; Zhang et al. (2018); Hou, Kretschmer, and Liu (2007)), membership and attendance (e.g., in research groups, conferences, scientific events, editorial boards and in scientific committees and associations; Sciabolazza et al. (2017); Bellotti, Kronegger, and Guadalupi (2016)). The main process at work is considered to be cumulative advantage, which increases the chance that those renowned scientists gain a higher standing. Another stream of research has tried to reconstruct the fragmentation of ideas (Abbott 2000; Moody 2004; Leahey 2016), looking for a small-world structure of disconnected islands (Watts and Strogatz 1998). These studies emphasized idea spaces and divisions, either between sub-fields or among neighboring fields. These idea spaces might borrow concepts, methodologies and analytical techniques from each other. For instance, quantitative methodologies and their experts are those expected to intermediate between fields and scientists due to their membership in multiple research groups and their interdisciplinary publication trajectories. This inter-mediation blurs the borders between fields and creates interstitial sciences (Abbott 2001). Research here has also tried to identify the core of leaders and priphery of followers (Kronegger, Ferligoj, and Doreian 2011; Light and Moody 2011). Studying these collaboration networks requires to apply advanced mathematical and graph theory methods, such as block-modelling (Doreian, Batagelj, and Ferligoj 2005) and community detection (Newman 2006; Mucha et al. 2010; Reda et al. 2011). Interestingly, here these newer methodologies and studies are linked to classic efforts of detecting schools of thoughts and invisible colleges (Solla Price, J., and Beaver 1966; Crane 1972) and their link is similar to sociological efforts to bring-back old concepts in new forms and methodologies (Lizardo et al. 2018). They mainly focused on finding cohesive academic sub-groups which are more tied within themselves than between their group and others. The conceptual machinery has venerable roots in the Durkheimian concepts of social solidarity and cohesion (Durkheim 1893). These groups tend to be connected more to each other and preserve weak ties with others (Granovetter 1977). Note that this is the main underlying hypothesis behind community detection and clustering, i.e., giving lower importance to ties between the communities and rewarding the ties within them. Finally, research has also focused on the embeddedness and organizational ambiguity in academia (Granovetter 1985; Boffo and Moscati 1998). If the reward system of science (Merton 1968; Hargens 2004) is not clearly defined, standards are redundant and there are multiple criteria regulating rewards and sanctions, it is difficult that such a context motivates scientists in being more productive and pursue high-quality research. Second, and farther away from our focus in this research project, there are the efforts solely devoted to knowledge, science and other neighboring concepts. The second group could be divided in two main distinctive theoretical and methodological approaches: Sociology of Scientific Knowledge (SSK) and Actor Network Theory (ANT) that sometimes have been labeled as a constructivist view of scientific knowledge (Ritzer 2004). Our work in following chapters was informed by some of the theoretical views presented above. In each case we tried to present results of confronting the theoretical statement with our empirical results and drive conclusions. 2.3 Discussion Academics today are embedded in a dual context as if they were living a double life. On the one hand, they have to keep up with quantitative evaluation standards. They have to publish as much as possible under the publish or perish imperative. On the other hand, they are evaluated by their disciplinary community and their peers not merely quantitatively. Not only quality matters and this is in the eyes of the beholder. Teaching and mentoring students are an important part of the identity and life of an academic and these are factors that are also visible to the more approximate peers (e.g., department colleagues). Sometimes, colleagues value more an article perhaps published in a less prestigious journal instead of a top publication because the article has raised a major media and public debate. Sometimes, academics are praised for the voluntary scholarly activity they offer to the community (e.g., peer review, journal editorship etc.). They might receive higher recognition from peers because they received a prestigious grant not only due to the quantity of their previous publications but to the novelty of their project. Community values, unwritten rules and peer evaluations are embedded in academic reward systems that can be institutionally ambiguous, differently mediated by academic organisations and interpreted by individuals (Boffo and Moscati 1998). Academics might be remunerated for different activities they are requested to carry on, some of them even not reflected in any quantitative evaluation since these unwritten rules and cultural aspects of academic work is harder to record and study. These are some of the dualities and paradoxes that academics have to face in the 21st century. They need to manage this complex academic life. The limited resources and constrains they face might lead scientists to give up their voluntary activities in favor of the ones that will directly affect their performance in research evaluation (Bianchi et al. 2018). Our dissertation aimed to contribute to understand this puzzle. We focused on different pieces. We tried to reflect on the case of sociologists, both Italian and international, as this is our community. In case of Italian sociologists, we examined their research productivity and the effect of various sources of embeddedness. Furthermore, we focused on the evolution of collaboration and coauthorship networks among Italian sociologists. Finally, we tried to understand the influence of institutional factors, with a particular focus on national research assessments. We concentrated on the effect of VQR 2004-2010 by ANVUR on sociological research in Italy. We focused on the issue of institutional ambiguities as well. The paradoxical and confusing stimuli that Italian sociologists (and other academics in Italy) receive. On the one hand, they are inspired to take part in collective and group research work, e.g., apply for PRIN and national level projects and participate in COST and European level projects. On the other hand, their research work is evaluated in the individual (or department) level, merely based on their publication output with little focus on teaching duties and results of this evaluation then is aggregated in the department level and lead to the university rankings. Academics in Italy are paid to a relatively equal level based on academic status. This pay is not directly dependent on their research productivity. We consider this as a case of institutional ambiguity (Boffo and Moscati 1998) stemmed from the centralized leadership in Italian academia (Whitley 2007) that gives ambiguous signals to academics. Since the academic world, and sociological community as well, has its own type of diversity and inequality, we attempted to look at gender and ivy-league affiliation effects [and biases] in publication behavior of academics in the case of top sociology journals. To see how these types of inequalities affect academics’ success in terms of the research productivity. To fill this gap, we have prepared empirical evidences on different aspects. We refer especially to multi-level modelling which considered the nested and crossed membership structure and organizational embeddedness and policy effect evaluation with repeated measurements. At the same time, we tried to consider the network and community membership and evolution. Our challenge was to evaluate some of these different aspects in a sophisticated multi-level model (Lazega et al. 2008; Bu et al. 2018; Zhang et al. 2018; Zhang, Bu, and Ding 2016; Bellotti, Kronegger, and Guadalupi 2016). We wanted to control the interplay between the factors that each focused on a specific aspect of academic life. This design helped us evaluate different variables including individual scientist’s characteristics, substantive focus of research (e.g., applying text and semantic analysis), community structure and evolution and structural and homophily effect all together while controlling for temporal dimension and changes. Of course, our study suffers from different limitations. In each chapter, we have tried to provide an overview on previous research and discuss our findings by presenting study limitations. We have tried to adopt a step by step approach to overcome some of these, while certain caveats are general and will be discussed in the final chapter. References "],
["the-conundrum-of-research-productivity.html", "Chapter 3 The conundrum of research productivity The conundrum of research productivity: a study on sociologists in Italy1 Abstract 3.1 Introduction 3.2 The conundrum of research productivity 3.3 Method and Data 3.4 Results 3.5 Conclusions and discussion 3.6 Appendix", " Chapter 3 The conundrum of research productivity The conundrum of research productivity: a study on sociologists in Italy1 Abstract This chapter aims to understand the influence of institutional and organisational embeddedness on research productivity of Italian sociologists. We looked at all records published by Italian sociologists in Scopus from 1973 to 2016 and reconstructed their coauthorship patterns. We built an individual productivity index by considering the number and type of records, the impact factor of journals in which these records were published and each record’s citations. We found that sociologists who coauthored more frequently with international authors were more productive and that having a stable group of coauthors had a positive effect on the number of publications but not on citations. We found that organisational embeddedness has a positive effect on productivity at the group level (i.e., sociologists working in the same institute), less at the individual level. We did not find any effect of the scientific disciplinary sectors, which are extremely influential administratively and politically for promotion and career in Italy. With all caveats due to several limitations of our analysis, our findings suggest that internationalisation and certain context-specific organisational settings could promote scientist productivity. Keywords: Sociologists, Italy, Research productivity, Internationalisation, coauthorship 3.1 Introduction Research work of scientists does not happen in a social and institutional vacuum. Certain institutional and structural factors might influence scientist’s work, including research priorities, publication strategies and collaboration (Shapin 2009). Indeed, previous studies suggested that scientist motivations and publication strategies are sensitive to institutional policies, i.e., career incentives, norms and rewards (Katz and Martin 1997; Lamont 2009; Bland, Ruffin, and others 1992). However, understanding institutional embeddedness of scientist work is complicated due to the multi-layered nature of institutions. First, country-specific rules and standards might influence scientist work by providing not only positive or negative incentives but also cognitive frameworks that scientists use to make sense of what they do (Provasi, Squazzoni, and Tosio 2012). For instance, recent research assessments performed by national authorities in the UK, Australia and Italy (e.g., Abramo and D’Angelo 2011b; Beerkens 2013), emphasized the reputational signal of publications in prestigious international journals and the importance of article citations as a (direct or indirect) measure of scientists’ value (e.g., Rijcke et al. 2016), Far from being neutral, these institutional assessments often embody standards that are irrespective of context specificities and typically have a performative function on scientist work (e.g., Timmermans and Epstein 2010; Wilsdon et al. 2015). Indeed, scientists can orient their research or change the outlet of their publication to fit these standards better (e.g., Burrows 2012). In this respect, the recent debate about pros and cons of measuring scientist work by bibliometric indicators and their potential misuses testifies to the widely shared belief that quantitative rankings might have unintended consequences, such as altering scientist publication strategies (e.g., Hicks et al. 2015) and nurturing excessive competitive spirits (e.g., Edwards and Roy 2017). Secondly, specific incentives might operate more locally as academic organisations in which scientists are embedded tend to constrain individual perceptions and strategies even simply as a means to solve organisational uncertainty (Weick 2016). However, sometimes this gives rise to semantic, strategic and operational meanings and actions that are misaligned with broader institutional pressures (e.g. Whitley 2003), such as in recent cases of boycotting rankings (see the case of German sociologists in Berlemann and Haucap 2015; Stergiou and Lessenich 2014). To complicate even more the picture, research suggests that scientific community has its own endogenous drivers, which might even be resilient to exogenous institutional pressures. While scientists tend to collaborate internationally more and more independently of their field (Leydesdorff, Park, and Wagner 2014), however, it is likely that different sub-communities in which the scientific community is stratified have a variety of initial conditions that amplifies certain differences in cultures and attitudes towards research, collaboration and even findings communication (Hakala and Ylijoki 2001). Therefore, institutional incentives could be even interpreted by scientists differently depending on specific standards and norms of their community. This chapter aims to understand if certain institutional and structural factors are associated with differences in individual research output. To do so, we performed an empirical analysis of the institutional and organisational embeddedness of research productivity of sociologists in Italy. The case of Italy is interesting for various reasons. First, in 2006, the Italian government established an independent evaluation agency, i.e., ANVUR2 (ANVUR 2013), with the aim to assess the performance of all research institutes in the country (i.e., 95 universities and public research institutes) (Turri 2014; Geuna and Piolatto 2016). While this assessment was based on different productivity indicators aimed to assess institutes and not scientists, it also explicitly conveyed a strong message about the importance of productivity and quantitative indicators to anyone. Secondly, ANVUR was also involved in developing common standards for the national habilitation of all new associate and full professors, which linked promotion and resources to research productivity. These standards generated a large debate within the scientific community, were contrasted by many academics, especially from the humanities, and in some cases generated contrasting outcomes (e.g., Baccini and De Nicolao 2016). However, they marked the beginning of a cultural change in the institutional settings of Italian academia, with scientists who were unfamiliar with international standards learning for the first time what h-index, WoS (Web of Science) and Scopus meant. Furthermore, the case of sociologists is interesting for two reasons. First, sociologists are part of a community that includes humanities scholars, who are predominantly qualitative, anti-bibliometric and publish preferably in national journals and “hard” scientists, who are quantitative, are familiar with bibliometric indicators and publish preferably in international journals. The co-existence of different epistemic communities among sociologists makes this an interesting case to examine contrasting forces towards internationalisation. Secondly, it is important to note that except for a few noteworthy examples (e.g., Bellotti, Kronegger, and Guadalupi 2016; Bellotti, Guadalupi, and Conaldi 2016) research on scientists’ productivity in Italy have looked mainly at communities of hard scientists (e.g., Abramo, D’Angelo, and Rosati 2016b). Research in humanities and social sciences is hardly examinable quantitatively as either scientists in this field do not publish only WoS or Scopus indexed sources or they value more quality over quantity (Abramo and D’Angelo 2014b; Bellotti, Kronegger, and Guadalupi 2016; Nederhof 2006). Our chapter aimed to fill this gap by providing a quantitative analysis of research productivity of Italian sociologists. The rest of the chapter is organised as follows. Sect 2 discusses certain institutional, organisational and individual factors that might influence scientist research productivity. While previous studies have elaborated models that estimate scientist productivity for assessment, here we tried to complement these models with attention to explanatory variables. Sect 3 presents our data. Although our study included only cross-section data, we considered time dependent variables and found interesting associations between institutional and organisational factors and productivity. Sect 4 presents our results, while Sect 5 summarizes our main findings and discusses certain limitations of our work. 3.2 The conundrum of research productivity Measuring research productivity of scientists and understanding the influence of institutional and organisational factors is complicated (e.g., Pepe and Kurtz 2012). While certain indexes that measure the impact of scientist work, such as the h-index introduced by Hirsch (Hirsch 2005; for an extensive review see Egghe 2010), have become popular also outside academia, research showed that they were not sufficiently robust, general and contemplated extensions (Hirsch 2010) and alternatives (e.g., Batista, Campiteli, and Kinouchi 2006; Pepe and Kurtz 2012). However, these problems are also due to the puzzling nature of scientific productivity: any empirical observation shows that the distribution of productivity among scientists is not normal (e.g., Ellwein, Khachab, and Waldman 1989). Furthermore, research has suggested that productivity might be influenced by a nexus of individual, institutional and organisational factors (e.g., Provasi, Squazzoni, and Tosio 2012). This combination of factors challenges our understanding of the mechanisms that drive productivity differences. For instance, in a review paper on previous studies of research productivity, Fox (1983) found that scientist attitudes, interests and abilities might explain differences in research productivity among scientists. Productive scientists are intrinsically motivated by a kind of inner compulsion that makes them working even if they are not exposed to external rewards. This included ego strength, personal dominance, preference for precision and exactness, strong control of impulse and a sincere preoccupation about ideas more than concrete aspects. It is worth noting that Fox suggested these qualities emerged even in the early stage of a scientist’s career. This was also confirmed by Ramsden (1994) in a survey on 890 academics in 18 Australian higher education institutions. Findings showed that productivity was influenced by a scientist’s early interest in research. More recently, in a survey of 465 full-time faculty members in a medical school at the University of Minnesota-Twin Cities, Bland et al. (2002) and Bland et al. (2005) expanded the analysis towards more complex factors that sustain individual productivity. These not only included the importance of personal motivation, including the development of an idea, autonomy and work habit. A profound socialization process, which aligned individual and organisational objectives, being involved in simultaneous projects (engagement in multiple concurrent projects makes it easier to tolerate if one project stalls or fails) and being involved in organisational and extra-organisational activities had positive effects on scientist productivity. This means that individual characteristics were essential but not sufficient to explain scientist productivity. Their findings suggested that individual characteristics and academic organisation structure and leadership tend to self-reinforce. The fact that productivity does not materialise in a social and institutional vacuum has been recognized by many studies. Indeed, certain institutional policies and some priorities established by research organisations can provide positive or negative incentives to productivity, which may even contribute to orient publication strategies (e.g., Ramsden 1994). As suggested by Fox (1983), “scientific work is very social enterprise, depending a great deal on interactions that are facilitated -or not- by one’s environment”. As suggested by Bland, Ruffin, and others (1992) (see also Nygaard (2015)) the establishment of strategic goals by academic organisations with an explicit focus on research excellence or innovation are key factors to stimulate scientist output by increasing also in-out mobility and talents’ attractiveness (see also Long and McGinnis 1981). In an influential study, based on a national sample of faculty in both four-year colleges (N = 1216) and universities (N = 7484) in USA, Blackburn, Behymer, and Hall (1978) emphasized the role of organisational context in explaining differences in scientist output. They found that scientist hired in more prestigious organisations published considerably more and suggested a complex interplay of scientist excellence and positive environment. For instance, besides the effect of career trajectories, certain department characteristics, such as the size and prestige, were positively interrelated with scientist productivity. Similarly, in a study on two groups of biochemists, Long (1978), found that while scientist productivity did not greatly contribute to the prestige of academic organisations, scientist productivity greatly benefited from the prestige of the academic organisation in which scientists were embedded. More recently, Lazega et al. (2008) in a study on top cancer research in France in the late 1990s, in which interdependencies between organisational and individual levels of scientist performance were investigated, found that the position of an academic organisation in the inter-organisational network was even more important than the scientist position in the top scientist network to explain scientist performance. This would even indicate that selection effects, i.e., more prestigious organisations tend to hire preferably more productive scientists, could be less important than organisational embeddedness effects, i.e., scientists being more productive because they were hired by more prestigious organisations (e.g., Long and McGinnis 1981; Ramsden 1994), although here it is difficult to dissect causal factors. Finally, it is important to note that scientists are also sensitive to implicit or explicit standards that are intrinsic to the type of research they perform (e.g., high-tech lab vs. low-tech individual research (Kronegger et al. 2011)), not to mention the influence of certain practices that emerge via direct or indirect scientific collaboration. In a review on publication, research productivity and citation patterns in the humanities and social sciences, Nederhof (2006) found that natural scientists are more prolific than social scientists and humanities scholars (see also Blackburn, Behymer, and Hall 1978), while these latter tend to cite earlier works more frequently (see also Price 1970). Furthermore, when considering the different size of the communities, which also implies a different number of journals, articles and potential citations, analysing scientist productivity and citation patterns without considering context-specific factors can probably lead to misplaced conclusions. To sum up, the complexity of factors involved in determining scientist productivity makes difficult to develop robust, across-domain valid measures. On the one hand, research productivity measures are applied to complex aggregates so that the effect of contextual factors is not considered. On the other hand, although indicators are aimed at assessment more than explanation, research assessment should try to incorporate these factors to provide more informed and context-specific recommendations. If scientific outputs and research productivity might strongly depend on individual, institutional and contextual factors, understanding these factors is of paramount importance also to reveal existing forces that are largely resilient against institutional policies. 3.3 Method and Data Our dataset was based on a mix of available institutional data from the MIUR (Italian Ministry of University and Research) and publication records collected from Scopus. We, first, gathered from the MIUR website a list of all sociologists currently enrolled in Italian Universities and research centers, including faculty members (1,029 in total) and postdocs (198 in total). This included information about the subject’s current academic position (i.e., assistant, associate or full professor), the “scientific disciplinary sector”3 in which s/he has been formally assigned (e.g., political sociology, economic sociology etc.), gender, affiliation, department, and last and first name. It is important here to note that “scientific disciplinary sectors” in Italy are not only bureaucratic categories with administrative functions; they are key for job competition, recruitment and career. They can also embody implicit research standards that might be different from case to case (e.g., Abramo, D’Angelo, and Rosati 2016a). Furthermore, in order to examine the potential impact of the characteristics of the department in which a scientist works, we classified each of the 200 departments in which at least one sociologist faculty member was present into the following seven coherent areas: “Humanities”, “Social Sciences”, “Engineering”, “Economics”, “Medicine”, “Psychology” and “Other”. This classification was made by checking manually the department faculty composition and teaching courses on departments’ online websites. Finally, as a control variable, we used ANVUR’s ranking of university research performance as a proxy of the quality of the university in which sociologists were working. Following ANVUR (2014), we classified any university in high, medium and low ranking. Finally, given the known disparities of developments between regions in Italy, we considered the geographical distribution of universities in Center, Islands, North and South of Italy. As regards publication records, we collected all available records for all scientists included in the above list from Scopus. We preferred Scopus to Web of Science (WoS) and Google Scholar for the following reasons. First, Scopus covers more social science literature than WoS (e.g., it includes more journals, and monographs from prestigious international publishers) but is more restricted to scientific literature than Google Scholar, which sometimes includes also non-scientific publications. Secondly, unlike WoS, Scopus covers the most prestigious sociology journals in Italy, such as Sociologica, Stato e Mercato and Rassegna Italiana di Sociologia, just to name a few, in which Italian sociologists publish frequently if not exclusively. Finally, Scopus is usable for large-scale data mining more efficiently and less erroneous than WoS and Google Scholar.4 Our data included all the available fields of the Scopus database, including for each scientist’s publication: title, authors’ names, source title, year of publication, number of citations received, permanent link to the publication, authors’ affiliations, abstract, keywords, references. By using Scopus data fields, we also considered the type of documents produced by each scientist (i.e., “Article”, “Review”, “Book Chapter”, “Book”, “Erratum”, “Editorial”, “Note”, “Conference Paper”, “Article in Press”, “Letter”, “Short Survey”), and the publication language (i.e., “Italian”, “English”, “French”, “Dutch”, “Spanish”, “Slovak”, “German”, “Portuguese”, “Croatian”, “Hungarian” were the languages Italian sociologists have been publishing).5 To assess if our data from Scopus covered the most prestigious and known journals in which Italian sociologists typically publish, we checked the publications in our sample, and found that the first 24 percent (786 papers) were published in the following 19 journals: Sociologia, International Review of Sociology, Rassegna Italiana di Sociologia, Salute e Societa, Studi Emigrazione, Stato e Mercato, Quality and Quantity, Italian Sociological Review, European Societies, European Sociological Review, Sociologica, Journal of Modern Italian Studies, Etnografia e Ricerca Qualitativa, European Journal of Social Work, European Journal of Communication, Polis (Italy), Current Sociology, Lecture Notes in Computer Science, South European Society and Politics. This confirmed that the most prestigious Italian journals were represented in the dataset. In order to measure scientist output and examine the effect of certain institutional and structural factors, we first elaborated a “productivity index”, which included the total number of each scientist’s publications \\(P\\) (such as: Ellwein, Khachab, and Waldman 1989; Katz and Martin 1997) and his/her scientific career length \\(t\\) (e.g. \\(Pr = \\frac{P}{t}\\)). Values were then standardized to a scale of 0-1 based on the distribution of publications of all scientists. Then, we compared each scientist with average citations of his/her scientific disciplinary sector (e.g., Abramo, D’Angelo, and Di Costa 2011; Abramo, Cicero, and D’Angelo 2013; Opthof and Leydesdorff 2010) as well as with that of the whole population of sociologists. After testing these options, we followed Abramo and D’angelo (Abramo, D’Angelo, and Di Costa 2011; Abramo and D’Angelo 2011b) and developed a production function by considering a microeconomic point of view. They built an index called FSS (Fractional Scientific Strength), which measured: (a) resources used by scientists, e.g., time, and (b) scientific outputs, e.g., publications, and c) citations, as a measure of the impact of research as follows: \\[FSS_R = \\frac{1}{t}\\sum_{i=1}^N \\frac{c_i}{\\bar{c}}f_i\\] where \\(t\\) was the time window between first publication and the last one for each scientist, e.g. a proxy of time invested for research, \\(N\\) was number of his/her publications, \\(c_i\\) was number of citations that each publication \\(i\\) collected and \\(\\bar{c}\\) was average number of citations that each publication received compared to average citations of all other records published in the same year. This was to control for cumulative time effects in citations and avoid comparing citations received by an article published in 2015 by scientist A with citations received by an article published in 2000 by scientist B. In case of postdocs, given that MIUR did not assign them to any specific scientific disciplinary sector, when calculating their \\(FSS\\), we compared their citations with those of all other postdocs in the same year. Finally, \\(f_i\\) is the inverse of the number of authors (fractional contribution of each author to paper). We also looked at each scientists level of international collaborations (see, Katz and Martin 1997; Leydesdorff, Park, and Wagner 2014) and built an “internationalisation index”, which considered the coauthors’ affiliation and country (e.g., Leydesdorff, Park, and Wagner 2014) and calculated the number of authors with non-Italian affiliations \\(a_f\\) on the total number of authors of each paper \\(a\\). We aggregated this value by averaging the internationalisation scores of all publications, \\(N\\) as follows: \\[IntScore = \\frac{1}{N}\\sum_{i=1}^N \\frac{a_f}{a}\\] Finally, we looked at the coauthorship composition. First, we measured the mean number of coauthors with dividing sum of number of authors of each paper \\(a_i\\) over number of all papers \\(N\\), as follows: \\[AverageCoauthors = \\frac{1}{N}\\sum_{i=1}^N a_i\\] Then, we calculated a “coauthor variety index”, which measured the extent to which scientists collaborate with the same coauthors or tended to change coauthors over time. Here, we wanted to verify, first, whether the tendency of social scientists and sociologists to perform research individually, which was found in previous studies (e.g., Becher and Trowler 2001, 125; Smith 1958), could be also found among Italian sociologists. Secondly, we wanted to understand if this attitude could have implications on productivity. Indeed, previous research suggested that scientists who collaborate with a variety of coauthors tend to publish more (e.g., Rumsey 2006; Kuzhabekova 2011). To measure this, we built a matrix that included each scientist’s coauthors and used inverse log-weighted similarity (Csardi and Nepusz 2006) to measure the propensity of each scientist to work preferably with different or stable coauthors through his/her scientific career (note that also here we standardized this value to a scale of 0-1). 3.3.1 Crossed membership multi-level modeling In order to examine the importance of institutional embeddedness, we assumed that each scientist in our database was nested in different clusters, possibly having an influence on his/her productivity. We considered three clustering levels: (1) the department, as the first level of organisational embedddness, probably the most important one, as promotion and careers are eventually decided locally, (2) the scientific disciplinary sector, which is important both for power, careers and strategic relations, sometimes also for research and collaboration, and (3) the university, as the second level of organisational embedddness, which became especially important in Italy after the last reform of the national university system in 2010 with important prerogatives given to university governance for incentivising and measuring scientist productivity, e.g., by establishing rewards for research excellence and allocating internal resources on productivity indicators. Sociologists in similar department could belong to different scientific disciplinary sectors and sociologists in similar departments in different universities could be exposed to similar cultural contexts. In order to accommodate this complexity, we used crossed membership random effects structure(Baayen, Davidson, and Bates 2008). In order to model this nestedness and crossed membership, we followed previous studies (Snijders and Bosker 1999; Faraway 2005; Zuur et al. 2009), and used hierarchical linear models. This allowed us to examine the effect of these levels in a more robust manner. For instance, an assistant professor of political sociology (i.e., this is the scientific disciplinary sector) who was enrolled in a department of social sciences in a given university could have different intercept (starting point) and slope (growth rate) in a regression model compared to a full professor of economic sociology in the same university and department. However, given the complex structure of random effects in the model and the number of control variables, e.g., gender, academic status and coauthor variety, we could not add all possible fixed effects simultaneously. Rather, we followed a step-wise approach by checking the differences from a baseline model (with full random effects structure) and examined each of our fixed effects step-by-step while keeping the same random structure and control variables (gender, stability of coauthors, and academic level). 3.4 Results It is first important to note that only 63.81% of 1,227 Italian sociologists had at least one publication indexed in Scopus. The remaining 36.19 % of Italian sociologists either did not publish a single record (see Hâncean and Perc 2016) or more probably published research in non-indexed sources, such as some national journals or monographs and books. Coherently with previous research in Italy (e.g., Abramo, D’Angelo, and Caprasecca 2009b) even by simply looking at the probability of having a Scopus profile, we found a gender effect although not so strong. The percentage of male and female scientists who had a Scopus profile (i.e having at least one paper, book or book chapter in outlets that are indexed by Scopus) is 10.09 % different from each other (male = 55.04%, female = 44.96%). We also found that sociologists working in northern Italy or highly ranked universities had a higher probability of having a publication in Scopus (high rank universities 59.39 % of total; northern universities 53.13 % of total). Table 3.1 presents a descriptive view (mean and median) of total number of publications and FSS of sociologists compared over geographical regions, universities of different ranks, sectors and departments. Table 3.1: Descriptive statistics of the total number of publications (count) and FSS (scaled to 0-1) Main Sub-Category Mean FSS Median FSS Mean # Pub Median # Pub Geo Region center 0.0330 0.0003 3.3166 2.0 Geo Region isolated 0.0181 0.0000 2.2826 1.0 Geo Region north 0.0479 0.0153 5.6851 3.0 Geo Region south 0.0232 0.0004 3.1557 2.0 University Rank high 0.0331 0.0061 4.2989 3.0 University Rank low 0.0572 0.0000 4.1875 2.0 University Rank medium 0.0448 0.0075 4.8704 2.0 Sector postdoc 0.0682 0.0000 2.7593 2.0 Sector SPS/07 0.0319 0.0029 4.7023 3.0 Sector SPS/08 0.0317 0.0066 4.7463 2.0 Sector SPS/09 0.0429 0.0136 5.6078 3.0 Sector SPS/10 0.0350 0.0098 4.4419 2.0 Sector SPS/11 0.0480 0.0227 4.0667 2.5 Sector SPS/12 0.0124 0.0007 3.8485 2.0 Department Economics 0.0378 0.0000 4.3333 2.0 Department Engineering 0.0277 0.0028 3.4375 2.5 Department Humanities 0.0362 0.0055 4.4657 2.0 Department Medicine 0.0063 0.0015 3.5556 3.0 Department Other 0.0160 0.0016 3.0000 3.0 Department Psychology 0.0351 0.0188 3.7778 2.0 Department Social Sciences 0.0414 0.0089 4.6528 3.0 As expected, the distribution of publications was highly skewed (see Figure 3.1 below) with a few sociologists publishing a considerable fraction of the total number of publications. which is in line with previous studies (Nygaard 2015; Ramsden 1994; Coile 1977; Ellwein, Khachab, and Waldman 1989). Figure 3.1: Distribution of the total number of publications (Scopus data); (black line is the median) Our model confirmed a skewed distribution with a concentration of scientists close to null values (Figure 3.2). The same was found when looking at citations (e.g., Bornmann 2010): there were sociologists having up to nine records without a single citation. While recognition of scientific contributions can be often delayed in time (e.g., Garfield 1980 as cited in @abramo2011evaluating), our results show a considerable number of records published before 2000 without any citation (see Figure 3.3). Figure 3.2: Distribution of FSS in subset of population with at least one publication (Scopus data), X = FSS (from 0-1 with 1 as maximum), Y = Frequencies Figure 3.3: Distribution of articles never cited over time (Scopus data). X = years, Y = frequencies Following Abramo, Cicero, and D’Angelo (2013), we restricted our analysis only to sociologists with FSS values higher than 0. We also added the impact factor of journals (e.g., Abramo, D’Angelo, and Di Costa 2008; Ellwein, Khachab, and Waldman 1989), by considering, for the sake of simplicity, the 2015 impact factor (\\(IF\\)) as: \\(FSS_R = \\frac{1}{t}\\sum_{i=1}^N \\frac{IF.c_i}{\\bar{c}}f_i\\), where \\(IF\\) was the impact factor of the journal that paper was published. This was to capture not only citations but also the prestige of journals in which articles were published. We run our nested layered model to examine the effect of organisational and institutional embeddedness on the FSS value of each single scientist. Given the size of certain variables, e.g., 78 universities, here (in Table ??) we presented only the most interesting results. Table ?? shows that sociologists who collaborated more with international coauthors have higher research productivity, i.e., more publications and higher citations. This confirms previous findings by F. Narin, Stevens, and Whitlow (1991) and Francis Narin and Whitlow (1991) and Khor and Yu (2016): internationally coauthored articles attract more citations and this makes scientists’ research investments more valuable. Secondly, we found that gender matters: male are more productive than female sociologists. This confirms previous findings on gender gap in publications in a variety of national contexts (e.g., Blackburn, Behymer, and Hall 1978; Prpić 2002; Hancock and Baum 2010; Abramo, D’Angelo, and Caprasecca 2009b). Previous research suggested many explanations of this gap, including the negative impact of maternity leave and higher involvement in family obligations (e.g., Stack 2004; Prpić 2002). We also found an effect of academic status. Indeed when considering the fractional contribution of each coauthor to each publication, full professors were less productive than younger scholars. This would indicate that younger scholars are more propense to publish in prestigious journals probably due to stronger competitive pressures that make productivity signals more important than in the past6. Interestingly, contextual factors were not significantly associated with productivity. Lower and medium ranked universities seem to include sociologists with similar productivity to top-ranked ones. This would indicate that excellence in research in sociology is not concentrated in top universities but spread in peripheral institutes or equally low in all regions and more driven with other variables discussed (see Table ?? and ?? in the Appendix).7 Comparative table of multilevel regression models log(FSS) Total Publications Constant -4.03 (0.22)*** 0.02 (0.01) Internationalisation 0.91 (0.34)** 0.10 (0.02)*** Coauthors Stability 0.12 (0.69) 0.46 (0.05)*** Gender (male) 0.39 (0.14)** 0.03 (0.01)** Associate professor -0.27 (0.16) 0.02 (0.01) Full professor -0.38 (0.19)* 0.03 (0.01)* Postdoc 0.99 (0.43)* 0.10 (0.02)*** AIC 1652.31 -702.13 BIC 1697.66 -656.38 Log Likelihood -815.15 362.07 Num. obs. 456 473 Num. groups: university 60 61 Num. groups: sector 7 7 Num. groups: department 7 7 Var: university (Intercept) 0.29 0.00 Var: sector (Intercept) 0.11 0.00 Var: department (Intercept) 0.00 0.00 Var: Residual 1.89 0.01 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 We also looked at the effect of the variety of coauthors (see coauthors stability in Table ??). Research suggested that more productive scientists tend to follow two types of coauthorship strategies, i.e., working with cohesive groups of coauthors or bridging between distant and disconnected groups of coauthors (Burt 2005; Bellotti, Guadalupi, and Conaldi 2016; Rumsey 2006; Kuzhabekova 2011). It is probable that the second strategy is more feasible in hard sciences in which more generous grants and high-tech lab research stimulate more collaboration (Becher and Trowler 2001; Smith 1958). Our results showed that working in a more stable group of coauthors was positively associated with the number of publications (see model 2 in Table ??) but not with research productivity, i.e., FSS (see model 1 in Table ??). This means that if we consider also the impact of research in terms of citations, collaborating with the same coauthors seems not to give any advantage. This is reasonable as working with larger groups of coauthors from different countries and so connecting different communities could yield higher citations (F. Narin, Stevens, and Whitlow 1991; Francis Narin and Whitlow 1991; Khor and Yu 2016) Comparative table of LNAM (Linear Network Autocorrelation Models) Model 1: FSS Model 2: Total Publications Internationalisation 0.06 (0.02)*** 0.09 (0.02)*** Gender 0.01 (0.00)* 0.00 (0.00) Academic level 0.01 (0.00)* 0.02 (0.00)*** Rho 0.19 (0.02)*** 0.16 (0.02)*** R^2 0.03 0.07 Adj. R^2 0.02 0.07 AIC -1590.10 -1335.57 BIC -1567.06 -1312.34 Log Likelihood 800.05 672.78 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 In order to check for autocorrelation, we followed Leenders (2002) and Bellotti, Guadalupi, and Conaldi (2016) and run a network disturbance model. By using LNAM (Linear Network Autocorrelation Moldels) (Butts 2016) (see Table ??), we looked at coauthorship networks in order to examine the potential effect of direct and indirect coauthorship. Results showed that internationalisation, gender and academic status have significant effects, with the case of gender becoming statistically not significant when the total number of publications was our dependent variable. However, it is important to note that in both models, the Rho was significant. This would indicate that coauthors had similar internationalisation, number of publications and FSS values. This suggests that at least part of our results could be due more to similarities between scientists who were connected to each other than to our independent variables and these models tend to explain only 2-7% of the variance (R2). As discussed in the closing section, further investigation would be necessary to disentangle non-linear effects of collaborations on productivity. Comparative table of Macro level regression models Research productivity as dependent variable FSS Total Publications (1) (2) Internationalisation 0.247*** (0.021) 0.189*** (0.022) Coauthors Stability 0.093 (0.070) 0.631*** (0.076) Gender (male) 0.005 (0.004) 0.005 (0.004) Associate professor -0.008* (0.004) -0.001 (0.005) Full professor -0.006 (0.005) 0.004 (0.005) Postdoc 0.008 (0.007) 0.020*** (0.007) Constant 0.016*** (0.005) 0.023*** (0.005) Observations 477 477 R2 0.251 0.267 Adjusted R2 0.242 0.257 Residual Std. Error (df = 470) 0.040 0.043 F Statistic (df = 6; 470) 26.307*** 28.470*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 To look at the association between productivity and organisational embeddedness in more detail, we assumed that sociologists working in the same university could be exposed to incentives or local standards more as a group rather than as “separate” individuals. This means the association could be different when considering groups of scientists locally sharing practices and norms rather than scientists as singular individuals (e.g., (Lazega et al. 2008)). For each individual, we assigned the university average score in variables such as international collaborations, the total number of publications and their FSS to rule out differences between sociologists working in the same university (see Table ??). We found confirmation of the fact that collaborating internationally is associated with higher number of publications (model 2) and higher research productivity (model 1). When considering scientists as groups, we found that universities with more internationalized scientists have both higher number of publications and higher level of research productivity. We did not find any statistically significant association between productivity and disciplinary sectors, which seem less important in establishing scientific standards of research, probably being only a “nexus” of academic power (see Table ?? and ?? in the Appendix). Interestingly, we found that groups of sociologists working in economics departments were in general more productive than those working in engineering or humanities departments. This could be due to the higher exposure to robust research, competitive and international standards, which characterize the community of economists. Furthermore, it is worth noting that sociologists rarely work in computer science and electronic departments, in which publication standards are influenced by physics and hard sciences. They often work in departments of civil engineering and architecture, which have publication standards closer to the humanities (e.g., monographs in Italian and priorities to national journals). We also found that group of sociologists in low and medium ranked universities were in general more productive than those working in highly ranked universities. The South-North divide in productivity was also confirmed when looking at the group level (see Table ?? in the Appendix). Finally, we looked at the association between productivity and the variety of coauthors by aggregating group variables. As before, working with more stable coauthors was positively associated with the number of publications (model 2), whereas this was not associated with differences in research productivity also at a group level (model 1). 3.5 Conclusions and discussion This chapter aimed to study Italian sociologists in their contexts by looking at the influence of certain individual, institutional and contextual factors on productivity. While recent national assessments indicated that productivity of sociologists in Italy is unequally distributed, understanding the sources of these differences required to enlarge the perspective to contextual factors. Looking at institutional and organisational embeddedness could also enrich national assessment exercises, which typically compare scientists irrespective of contextual positive or negative factors (e.g Wilsdon et al. 2015). First, our findings suggest that internationalisation is key to productivity (F. Narin, Stevens, and Whitlow 1991; Francis Narin and Whitlow 1991; Khor and Yu 2016). By collaborating with colleagues who work in abroad institutions, Italian sociologists are probably more exposed to international standards of research, have higher probability to publish in prestigious journals and are recognized by an international audience (e.g., see the case of Chinese scientists in Jonkers and Tijssen (2008)). However, understanding causal mechanisms that determine the link between internationalisation and productivity would require more in-depth data and analysis, which are out of the scope of this work. On the one hand, internationalisation is not an exogenous factor as it can be determined by education, pre-established connections, productivity signals and the type of research (Chatzimichael, Kalaitzidakis, and Tzouvelekas 2016). In addition, these factors could also reflect individual propensity and differential investments in international networking, often simply due to inner compulsion or job satisfaction (e.g., (Ramsden 1994; Jung, Bozeman, and Gaughan 2017)). On the other hand, productivity can influence internationalisation in complex ways, such as ensuring access to more funds, which in turn stimulate international contacts, so reflecting non-linear, self-reinforcing complex dynamics (Azoulay, Ganguli, and Zivin 2017). Here, more in-depth data on education, career and institutional ties as well as considering the type of dominant research performed individually could help us provide a more precise understanding of the specific causal mechanisms presiding over the positive link between internationalisation and productivity (Abramo, D’Angelo, and Di Costa 2017). Secondly, our results suggest that scientific disciplinary sectors seem not to have any implications on scientist productivity. This is interesting as these sectors are extremely influential in the Italian academy for job promotion and career. Scientific associations have been built following their hierarchical structure in which sectorial experts regularly meet and coordinate. Our findings suggest that these sectors seem less relevant to define research standards. They are probably a political and administrative “ontology” rather than an institutional scaffold that establishes research standards and promotes excellence and innovation. This could bring us to re-discuss the importance of disciplinary sectors-dominated hiring or assessment committees, which were also used in national research assessments. Finally, we found that organisational embeddedness has positive implications on productivity, especially when looking at group level. This would suggest that practices, standards and norms could emerge locally that could influence scientist publication strategies (e.g., Provasi, Squazzoni, and Tosio 2012). However, without considering the differential exposure to more stimulating reward policies locally and the presence of network and learning effects at the organisational level, as well as mobility and career patterns of scientists, it is difficult to understand what characteristics of organisational embeddedness might have a specific effect on productivity. For example, recent research suggested that the presence of particularly brilliant scientists, a higher mobility of scientists and the presence of internationalized educational and research programs could explain higher productivity of groups (Agrawal, McHale, and Oettl 2017). Here, only more in depth analysis of organisational aspects of scientists groups in Italy could help to assess robust effects on productivity. For example, looking at multi-level network effects could help us understanding whether collaboration networks and embeddedness self-reinforce each other in generating effects on productivity. In conclusion, it is important to highlight that our work has certain limitations, besides those one already mentioned. First, while including the most prestigious Italian journals, Scopus ignores important research that is published in books and monographs by Italian publishers and so is biased towards English language journals and books (near 80 percent of publications here). Unfortunately, we could not compensate by collecting data on Google Scholar (Khabsa and Giles 2014; Meho and Yang 2007), as only a few sociologists in Italy have activated a Google Scholar profile (19.7 %) and these were mostly also those one more extensively covered by Scopus. While extending our findings to Google Scholar would be probably even more relevant to measure sociologists’ productivity (Halevi, Moed, and Bar-Ilan 2017), there are technical difficulties that still make this endeavor extremely costly (e.g., data collection of scientists without Google Scholar profile is hardly automatable on a large scale). However, it is important to note that using different indexes and databases is never neutral as a particular dataset could probably reveal patterns that the other could lead to underestimate (De Stefano et al. 2013). This means that only an integrated analysis could help us to corroborate our findings. Secondly, while time effects were controlled on citations, our analysis did not consider important temporal aspects, such as the changing academic status of scientists over their career, which could have relevant implications on productivity and important cumulative effects. Unfortunately, the cross-sectional nature of our data did not allow us to fully control for possible endogeneity bias. Further steps of our research will attempt at solving these problems in order to deepen our understanding of the institutional and organisational sources of productivity. 3.6 Appendix This appendix includes further data and results that complement the analysis shown in the article. In particular, it provides details on our multilevel and macro level models. 3.6.1 Regression models comparision Table ?? compares different multilevel models that we run with the same random effects structure as those presented in the Table ??. These versions included our institutional embeddedness variables as fixed effects. Results confirmed the importance of academic status (i.e., younger scientists are more productive), certain gender effects and stable coauthorship patterns on the number of publications. Comparative table of multilevel regression models log(FSS) (5 models) and Total Publications (5 models) Model 1 Model 2 Model 3 Model 4 Model 5 Model 6 Model 7 Model 8 Model 9 Model 10 Constant -4.03 (0.22)*** -4.99 (0.67)*** -4.41 (0.60)*** -4.10 (0.26)*** -4.04 (0.28)*** 0.02 (0.01) -0.01 (0.06) 0.03 (0.03) 0.01 (0.02) 0.01 (0.02) Internationalisation 0.91 (0.34)** 0.89 (0.34)** 0.89 (0.34)** 0.88 (0.34)** 0.91 (0.33)** 0.10 (0.02)*** 0.10 (0.03)*** 0.10 (0.03)*** 0.10 (0.03)*** 0.10 (0.02)*** Coauthors Stability 0.12 (0.69) 0.12 (0.69) 0.13 (0.69) 0.08 (0.70) 0.22 (0.70) 0.46 (0.05)*** 0.46 (0.05)*** 0.46 (0.05)*** 0.46 (0.05)*** 0.47 (0.05)*** Gender (male) 0.39 (0.14)** 0.39 (0.14)** 0.40 (0.14)** 0.40 (0.14)** 0.39 (0.14)** 0.03 (0.01)** 0.04 (0.01)*** 0.03 (0.01)** 0.03 (0.01)** 0.03 (0.01)** Associate professor -0.27 (0.16) -0.28 (0.16) -0.25 (0.16) -0.26 (0.16) -0.29 (0.16) 0.02 (0.01) 0.01 (0.01) 0.02 (0.01) 0.02 (0.01) 0.01 (0.01) Full professor -0.38 (0.19)* -0.39 (0.19)* -0.37 (0.19)* -0.39 (0.19)* -0.41 (0.19)* 0.03 (0.01)* 0.03 (0.01)* 0.04 (0.01)** 0.03 (0.01)* 0.03 (0.01)* Postdoc 0.99 (0.43)* 1.95 (0.83)* 1.01 (0.44)* 0.99 (0.43)* 0.93 (0.44)* 0.10 (0.02)*** 0.12 (0.09) 0.10 (0.02)*** 0.10 (0.02)*** 0.10 (0.02)*** Sector SPS/07 0.62 (0.81) 0.02 (0.08) Sector SPS/08 1.15 (0.81) 0.03 (0.08) Sector SPS/09 1.25 (0.82) 0.04 (0.08) Sector SPS/10 0.95 (0.85) 0.02 (0.09) Sector SPS/11 1.56 (0.87) 0.01 (0.09) Engineering dept. 0.26 (0.89) -0.05 (0.05) Humanities dept. 0.43 (0.72) -0.00 (0.03) Medicine dept. -0.49 (1.01) -0.02 (0.06) Other dept. -0.29 (0.87) -0.02 (0.05) Psychology dept. 1.18 (0.97) -0.00 (0.06) Social Sciences dept. 0.43 (0.71) -0.02 (0.03) Low rank univ. 0.33 (0.39) -0.01 (0.03) Medium rank univ. 0.08 (0.23) 0.01 (0.02) Isolated region univ. -0.13 (0.44) -0.02 (0.03) Northern region univ. 0.25 (0.26) 0.03 (0.02) Southern region univ. -0.46 (0.32) -0.03 (0.02) AIC 1652.31 1653.76 1656.34 1656.84 1653.60 -702.13 -664.89 -663.83 -687.22 -688.63 BIC 1697.66 1719.72 1726.43 1710.43 1711.32 -656.38 -598.34 -593.12 -633.15 -630.40 Log Likelihood -815.15 -810.88 -811.17 -815.42 -812.80 362.07 348.44 348.91 356.61 358.31 Num. obs. 456 456 456 456 456 473 473 473 473 473 Num. groups: university 60 60 60 60 60 61 61 61 61 61 Num. groups: sector 7 7 7 7 7 7 7 7 7 7 Num. groups: department 7 7 7 7 7 7 7 7 7 7 Var: university (Intercept) 0.29 0.29 0.31 0.30 0.24 0.00 0.00 0.00 0.00 0.00 Var: sector (Intercept) 0.11 0.21 0.11 0.11 0.11 0.00 0.00 0.00 0.00 0.00 Var: department (Intercept) 0.00 0.00 0.18 0.00 0.00 0.00 0.00 0.00 0.00 0.00 Var: Residual 1.89 1.89 1.89 1.90 1.90 0.01 0.01 0.01 0.01 0.01 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 Table ?? (extensions to models presented in Table ??) compares macro level models that ruled out the potential difference between sociologists working in the same universities to see the results between universities. Given that we had a considerable number of these association (78), we wanted to check if this could have biased our analysis. Results suggest that the findings presented in the article were statistically robust. Comparative table of Macro level regression models Types of research productivity as dependent variable FSS (5 models) Total Publications (5 models) (1) (2) (3) (4) (5) (6) (7) (8) (9) (10) Internationalisation 0.247*** (0.021) 0.247*** (0.021) 0.256*** (0.021) 0.227*** (0.021) 0.243*** (0.021) 0.189*** (0.022) 0.187*** (0.022) 0.195*** (0.023) 0.186*** (0.023) 0.156*** (0.020) Gender (male) 0.005 (0.004) 0.005 (0.004) 0.005 (0.004) 0.005 (0.004) 0.006 (0.004) 0.005 (0.004) 0.005 (0.004) 0.005 (0.004) 0.004 (0.004) 0.003 (0.004) Associate professor -0.008* (0.004) -0.008* (0.005) -0.007 (0.005) -0.005 (0.004) -0.009** (0.004) -0.001 (0.005) -0.002 (0.005) -0.001 (0.005) 0.0004 (0.005) -0.004 (0.004) Full professor -0.006 (0.005) -0.006 (0.005) -0.005 (0.005) -0.005 (0.005) -0.008 (0.005) 0.004 (0.005) 0.003 (0.006) 0.004 (0.006) 0.004 (0.005) -0.001 (0.005) Postdoc 0.008 (0.007) 0.011 (0.012) 0.009 (0.006) 0.008 (0.006) 0.005 (0.006) 0.020*** (0.007) 0.026* (0.013) 0.020*** (0.007) 0.020*** (0.007) 0.011* (0.006) Sector SPS/07 0.005 (0.011) 0.008 (0.012) Sector SPS/08 -0.002 (0.011) 0.003 (0.012) Sector SPS/09 0.007 (0.011) 0.014 (0.012) Sector SPS/10 0.003 (0.013) 0.004 (0.014) Sector SPS/11 0.004 (0.014) -0.009 (0.015) Sector SPS/12 Engineering dept. -0.036** (0.016) -0.036** (0.018) Humanities dept. -0.019* (0.010) -0.024** (0.011) Medicine dept. -0.024 (0.022) -0.023 (0.024) Other dept. -0.016 (0.016) -0.021 (0.018) Psychology dept. -0.008 (0.020) -0.005 (0.022) Social Sciences dept. -0.012 (0.010) -0.021** (0.011) Low rank univ. 0.031*** (0.009) -0.001 (0.010) Medium rank univ. 0.019*** (0.004) 0.013*** (0.004) Isolated region univ. -0.008 (0.010) -0.010 (0.009) Northern region univ. 0.004 (0.005) 0.035*** (0.004) Southern region univ. -0.020*** (0.006) -0.015** (0.006) Coauthors Stability 0.093 (0.070) 0.101 (0.071) 0.095 (0.070) 0.096 (0.068) 0.089 (0.071) 0.631*** (0.076) 0.636*** (0.076) 0.616*** (0.076) 0.641*** (0.075) 0.583*** (0.068) Constant 0.016*** (0.005) 0.013 (0.011) 0.029*** (0.011) 0.009* (0.005) 0.019*** (0.006) 0.023*** (0.005) 0.017 (0.012) 0.044*** (0.012) 0.018*** (0.005) 0.013** (0.005) Observations 477 477 473 477 477 477 477 473 477 477 R2 0.251 0.256 0.272 0.300 0.281 0.267 0.276 0.277 0.281 0.426 Adjusted R2 0.242 0.238 0.253 0.288 0.267 0.257 0.259 0.258 0.269 0.415 Residual Std. Error 0.040 0.040 0.040 0.039 0.039 0.043 0.043 0.043 0.043 0.038 F Statistic 26.307*** 14.507*** 14.348*** 25.039*** 20.268*** 28.470*** 16.135*** 14.662*** 22.908*** 38.530*** Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 3.6.2 Negative Binomial models In order to control robustness of our results with alternative modelling strategies, we ran negative binomial models on the total publication as dependent variable which has a count nature and highly skewed distribution (see Table ??). Results were in line with our crossed membership multi-level models presented in Tables ?? and ?? that were using total publication scaled to 0-1 (we kept the same random effects structure as presented before). Only postdocs when counted the number of publications (instead of scaled version used in previous models) show lower total publications compare to assistant professors which is natural. Because the scaling was based on the distributions of all publications of postdocs. Interestingly, university membership has the highest share of variance split by groups in the random effects table (see rows below the table starting with Var). Comparative table of negative binomial models of Total Publications Model 1 Model 2 Model 3 Model 4 Model 5 Constant 1.13 (0.10)*** 0.96 (0.22)*** 1.25 (0.22)*** 1.09 (0.13)*** 1.08 (0.13)*** Internationalisation 0.98 (0.18)*** 0.98 (0.18)*** 0.98 (0.18)*** 0.98 (0.18)*** 1.00 (0.18)*** Coauthors Stability 3.31 (0.43)*** 3.35 (0.43)*** 3.29 (0.42)*** 3.32 (0.42)*** 3.33 (0.42)*** Gender (male) 0.22 (0.07)** 0.23 (0.07)** 0.22 (0.07)** 0.22 (0.07)** 0.21 (0.07)** Associate professor 0.17 (0.09)* 0.17 (0.09) 0.18 (0.09)* 0.17 (0.09)* 0.16 (0.08) Full professor 0.36 (0.09)*** 0.34 (0.09)*** 0.37 (0.09)*** 0.36 (0.09)*** 0.33 (0.09)*** Postdoc -0.54 (0.13)*** -0.38 (0.23) -0.54 (0.13)*** -0.54 (0.13)*** -0.58 (0.13)*** Sector SPS/07 0.13 (0.20) Sector SPS/08 0.21 (0.20) Sector SPS/09 0.28 (0.21) Sector SPS/10 0.04 (0.24) Sector SPS/11 -0.05 (0.26) Engineering dept. -0.41 (0.38) Humanities dept. -0.04 (0.21) Medicine dept. -0.11 (0.43) Other dept. -0.41 (0.37) Psychology dept. -0.00 (0.41) Social Sciences dept. -0.16 (0.21) Low rank univ. -0.07 (0.23) Medium rank univ. 0.09 (0.14) Isolated region univ. -0.24 (0.24) Northern region univ. 0.31 (0.13)* Southern region univ. -0.30 (0.17) AIC 2535.10 2539.91 2543.52 2538.41 2524.80 BIC 2580.85 2606.45 2614.23 2592.48 2583.02 Log Likelihood -1256.55 -1253.95 -1254.76 -1256.21 -1248.40 Num. obs. 473 473 473 473 473 Num. groups: university 61 61 61 61 61 Num. groups: sector 7 7 7 7 7 Num. groups: department 7 7 7 7 7 Var: university (Intercept) 0.13 0.12 0.12 0.13 0.07 Var: sector (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: department (Intercept) 0.00 0.00 0.00 0.00 0.00 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 References "],
["only-good-intentions.html", "Chapter 4 Only good intentions? Only good intentions? The impact of a national research assessment on the productivity of sociologists in Italy8 Abstract 4.1 Introduction 4.2 Background 4.3 Data and measures 4.4 Results 4.5 Discussion and conclusions 4.6 Appendix", " Chapter 4 Only good intentions? Only good intentions? The impact of a national research assessment on the productivity of sociologists in Italy8 Abstract This chapter investigates the impact of a national research assessment (VQR 2004-2010) on sociological publications in Italy. We reconstructed all publications from Italian sociologists in Scopus between 2006 and 2015, i.e., before and after the assessment. We also checked academic tenures and promotions during the assessment. Our results showed that the effect of institutional signals on productivity was minimal, while certain individual patterns were more important. Our findings suggest that by opting for informed peer review rather than bibliometric indicators, and by not providing strict signals on the importance of prestigious publications, the assessment did not stimulate a virtuous rational adaptive response. Keywords: Research Assessment; ANVUR; Sociologists, Italy, VQR 2004-2010 4.1 Introduction The dominant “publish or perish” culture in academia is often associated with regular and pervasive quantitative research assessments of productivity, which are now performed worldwide. This is because the “meritocratic culture” of academia requires systematic and impartial assessment as a means to legitimize funding allocation on a competitive basis (Jappelli, Nappi, and Torrini 2017; Abramo and D’Angelo 2015). Outcomes of these assessments often even define individual promotion and careers (Edwards and Roy 2017; Nederhof 2006; Abramo, D’Angelo, and Rosati 2014). Previous research suggests that these assessments can have serious implications, though it is difficult to measure the effect of institutional impulses on scientists’ behaviour (Rijcke et al. 2016). Here, context matters and developing comprehensive and robust indicators of evaluation is always difficult, also considering that research is rarely pursued individually or in complete isolation (Waltman 2018). Furthermore, once introduced, the performance nature of quantitative evaluation may trigger gamification, which in turn risks distorting academic freedom, encouraging short-termism of research investment and portfolios (e.g., Rijcke et al. (2016), Hicks et al. (2015)), even nurturing an excessively competitive environment (e.g., Edwards and Roy (2017)). In this respect, Rijcke et al. (2016) suggest that metrics-based evaluation has four negative implications. First, metrics could affect scientists’ strategic behavior, leading to switching goals with means and stimulating gamification. This occurs when evaluation itself becomes scientists’ goal, and research activity is planned so as to produce publishable outcomes and maximize numbers. This would increase scientists’ risk aversion and dis-incentivize long-term, challenging research projects (e.g., Butler (2003); see also a recent re-examination by Besselaar, Heyman, and Sandström (2017) which cast some doubt on her results and conclusions). Secondly, metrics could embody bias against interdisciplinary, cutting edge research, especially when combined with peer review. Furthermore, indicators could stimulate scientists to reduce task complexity and standardize collaboration (Whitley 2007), thus reducing diversity of approaches, methods and standards, including imposing rigid constraints on publication formats. Finally, metrics could have effects on academic and research institutions, by increasing resource allocation towards more productive institutions capable of creating cumulative advantages (e.g., Abramo and D’Angelo (2015)). There is need for empirical analyses of research assessments especially in contexts where productivity, quantification and indicators are not intrinsic to the pre-existing reward and incentive structure of academia. This chapter aims to analyze the impact of a recent assessment on an interesting subset of Italian academics. The chapter is organized as follows: Section 2 presents our research background and the motivation of our study. Section 3 presents the methodology and data, while Section 4 presents the results. Finally, Section 5 summarizes the main findings and discusses certain limitations of the study. 4.2 Background Among European countries (Jonkers and Zacharewicz 2016), recently Italy has also made progress towards national research evaluation. After some preliminary examples (i.e., VTR9), in October 2006, the Italian government established a public independent agency, called the “Italian National Agency for the Evaluation of University and Research Institutes” (henceforth ANVUR) (ANVUR 2006) but the institutive Law was published only four year later with DPR 76/2010, and the agency started to operate only in February, 2011 with the nomination of its Board of Directors. ANVUR was directed to assess research productivity of universities and research institutes. Its mandate was to establish more competitive criteria in order to allocate university budgets and link promotion and careers to research productivity and scientific merit. Besides assessing research output, it also evaluates teaching, administrative performance, social impact and student competence, by covering all areas of sciences, from hard sciences to musical conservatories (Benedetto et al. 2017b). ANVUR members include well-known Italian scientists from different scientific fields appointed by MIUR (Italian Ministry of University and Research) (ANVUR 2013; Ancaiani et al. 2015; Benedetto et al. 2017b). The first National assessment by ANVUR was the VQR 2004-2010, which started by a call for participation published on 7th November 2011 (basically overlapping with the introduction of the National Scientific Habilitation (ASN) as a requirement for promotion and career of all academics (Abramo and D’Angelo 2015; Marzolla 2016)). About 185,000 research products were evaluated in 14 research areas. In STEM10 and hard sciences, nearly 90% of products were journal articles. In the humanities and social sciences, journal articles covered only 26% of the total number of products, the rest being mostly books and book chapters. Academics working in research institutes were required to submit six research products, while those working in universities, having also teaching duties, were required to submit three products for evaluation. An exception for younger researchers was considered based on the time of their employment in academia (ANVUR 2013; Ancaiani et al. 2015). ANVUR selected 450 experts as part of a number of GEVs (“Groups of experts in evaluation”), which mapped the structure of disciplinary sectors that dominate the organization of Italian academia. They were asked to define details and methodology of evaluation, including deciding either to use a combination of peer review and bibliometric analysis or exclusively peer review to assess scientists’ production. Under pressure from GEVs and many academics in the humanities11, ANVUR decided to follow a mix of quantitative metrics, such as the number of publications, citations and h-index in hard sciences and qualitative metrics, such as peer review in the humanities and social sciences. In regards to the latter, VQR 2004-2010 fully complied with the so-called informed peer review. Scientist under evaluation were required to pre-select and submit their best published research products while VQR peer reviewers could identify each author and the impact of journal or the prestige of book series in which products were published via online sources. This also occurred when products were articles previously published in peer-reviewed, authoritative journals. They were peer-reviewed by GEV experts after publication. Each product was categorized as: Excellent, Good, Acceptable or Limited (ANVUR 2013; Ancaiani et al. 2015; Bertocchi et al. 2015). ANVUR’s decision to use a mixture of peer review and bibliometrics raised a heated debate in the press and media. After the publication of evaluation results, members of ANVUR found a certain degree of agreement between peer review and bibliometric analysis (e.g., Bertocchi et al. (2015)). However, other studies re-examined the situation and found inconsistencies (Baccini and De Nicolao 2016), while some concluded that “bibliometric indicators could be used only to assess hard sciences” (Abramo, D’Angelo, and Caprasecca 2009a). Furthermore, supporters of bibliometric evaluations outlined the excessive cost of peer review, insisting on the subjective bias of peer reviewers and argued the higher fidelity of quantitative exercises that measured each scientist’s productivity without adding selection distortion (Abramo and D’Angelo 2011a). Indeed, VQR 2004-2010 was extremely costly and time consuming. It had a total cost of € 70,654,852, with € 5,940,000 for peer review and € 250,000 spent for bibliometric data, which informed the peer review evaluation in a subset of 14 scientific areas (see Geuna and Piolatto (2016) for further detail)12. It is worth noting that UK’s REF which is the reference point of VQR, in 2014 had a total cost of 106 million euros (€17,712,000 added to the cost of RAE), which is one of the reasons behind criticism of it (Harzing 2018). Note that the total cost of VQR 2004-2010 was approximately the entire budget of PRIN13 funds in 2015 (i.e., the only funding scheme by MIUR for public research in Italy), which was about €90,000,000, for which all academics and researchers in Italy competed. In a study, Bertocchi et al. (2015), who were members of the panel who evaluated research outputs of scientists in scientific area 13 (Economics, Management and Statistics), selected 590 random papers among 5,681 which were reviewed by VQR 2004-2010 experts. GEV in this field opted for informed peer review while peer reviewers used bibliometric indicators and journal impact indices to assess the quality of research products. They found substantial agreement between bibliometrics and peer review. However, they suggested there was potential ambiguity of these non-blind processes as it is impossible to disentangle whether close agreement was due to reviewers’ opinion or to the prestige of the outlet where articles were published. Besides the interesting mixture of metrics and criteria, the case of Italy is interesting also for other reasons. Firstly, while ANVUR assessment aimed to evaluate academic and research structures, rather than individual scientists, the Minister, the agency and the press also explicitly conveyed a strong message regarding the importance of productivity and quantitative indicators (Turri 2014). Secondly, ANVUR was also involved in developing common standards for the national habilitation of all new associate and full professors, which linked promotion and resources to research productivity. These standards generated widespread debate within the scientific community, were contrasted by many academics, especially from the humanities, and in some cases generated contrasting outcomes (e.g., Baccini and De Nicolao (2016)). However, all these initiatives marked the beginning of a cultural shift in the institutional setting of Italian academia, with scientists who were unfamiliar with international standards learning for the first time about h-index, WoS (Web of Science) and Scopus (Akbaritabar, Casnici, and Squazzoni 2018). In addition, looking at the case of sociologists is also an important insight. While the impact of ANVUR assessment has been extensively examined for the hard sciences and economics, management and statistics (Bertocchi et al. 2015; Abramo, D’Angelo, and Caprasecca 2009a), the case of sociologists has not yet been considered. On the one hand, ANVUR followed the dominant opinion of academics when considering bibliometric indicators as unreliable for assessing the productivity of social scientists (Benedetto et al. 2017a). On the other hand, sociologists are part of a community that includes not only humanities academics, who are predominantly qualitative, anti-bibliometric and preferably publish in national journals, but also quantitative social scientists, whose research standards are closer to hard scientists, are familiar with bibliometric indicators and publish preferably in international journals. This co-existence of different epistemic communities in the same discipline could make research assessment even more problematic and its impact even more worth investigating (Akbaritabar, Casnici, and Squazzoni 2018). Another point was that the decision by ANVUR, under pressure from GEVs, allowed the same experts being evaluated to classify the quality of journals in their field, independent of the internationally recognized prestige of these outlets, added a further layer of ambiguity to the policy signal. It is worth noting here that most Italian journals with a national academic readership were categorized on a level with highly prestigious international ones, though rigorous internal peer review, impact factor and citation rates were not comparable. This may have led rational, adaptive scientists to minimize the risk of delaying publication by targeting national outlets, which were less competitive than international ones. It is also worth considering that rewards and penalties of assessment were addressed to universities and departments rather than to teams or individual scientists. This may have created incentives for less intrinsically motivated, productive scientists towards minimizing their effort. 4.3 Data and measures Data were collected from Scopus in September 2016 and included all records published by Italian sociologists between 2006 and 2015 (compared to data used in Chapter 3 here we excluded postdocs whose majority did not have any publications at 2006). This period covered five full years before and after ANVUR, whose call for participation was originally published on 7th November 2011. Looking at five years before and after the call allowed us to trace pre-existing behavior and examine scientists’ reactions to institutional policies without compromising our analysis with other exogenous factors (Jonkers and Zacharewicz 2016; Hicks 2012; Benedetto et al. 2017b). We started from available institutional data on the MIUR website and gathered a list of all sociologists currently registered in Italian Universities and research institutes, i.e., a total of 1,029 scholars. We reconstructed each academic’s level (i.e., assistant, associate or full professor), the “scientific disciplinary sector”14 in which they were formally assigned to, gender, affiliation, department and finally their first and last names. Promotion and careers were reconstructed by comparing data from 2010 to 2016. This was coded as a dichotomous variable in dataset: “academic level changed” or “unchanged”. As regards publication records, Scopus includes approximately 8,698 journals in social sciences (Scopus 2017). These include all the most prestigious sociology journals published by Italian publishers or edited by Italian sociologists, such as Sociologica, Sociologia, Rassegna Italiana di Sociologia, Salute e Societa, Studi Emigrazione, Stato e Mercato, Italian Sociological Review, Journal of Modern Italian Studies, Etnografia e Ricerca Qualitativa and Polis. This confirmed that the most prestigious Italian journals were represented in the dataset.15 However in VQR 2004-2010, ANVUR categorized the more prestigious Italian journals (including a total of 50 journals from which 50% were indexed in Scopus (last checked on 1st August 2018) under the title of “Fascia journals” considering three levels, Fascia A, Fascia B, and Fascia C (ANVUR 2012). To complete our dataset, we then coded all articles in the sample as Fascia (either A, B, or C) or non-Fascia journals. Following Akbaritabar, Casnici, and Squazzoni (2018), in order to measure scientist output and examine the effect of certain institutional and structural factors, we used a productivity indicator developed by Abramo and D’Angelo (2011b) by considering a microeconomic stance. This function takes time as input of academic work and publications and impact of publications as output. This index was called FSS (Fractional Scientific Strength) as Eq 1 shows: \\(FSS = \\frac{1}{t}\\sum_{i=1}^N \\frac{c_i}{\\bar{c}}f_i\\) (1) \\(t\\): The time window between first publication and the last one for each researcher divided into two time periods before and after ANVUR16 \\(N\\): Number of sociologist’s publications \\(i\\): Each sociologist’s publication \\(c_i\\): Number of citations that each publication \\(i\\) collected \\(\\bar{c}\\): Average number of citations of all other records published in the same year17 \\(f_i\\): Inverse of the number of authors (fractional contribution of each author to paper) To measure scientists’ level of international collaborations (Katz and Martin 1997; Akbaritabar, Casnici, and Squazzoni 2018) we used an “internationalization index”, which considered the co-authors’ affiliation and country (e.g., Leydesdorff, Park, and Wagner (2014)) and calculated the number of authors with non-Italian affiliations \\(a_{fi}\\) on the total number of authors of each paper \\(a_i\\). We aggregated this value by averaging the internationalization scores of all publications, \\(N\\) as follows in Eq 2: \\(IntScore = \\frac{1}{N}\\sum_{i=1}^N \\frac{a_{fi}}{a_i}\\) (2) It is worth noting that in order to control for the possible confounding factor of career promotion, or academics promoted between 2010 and 2016, we added two categorical variables, which indicated the FSS level of everyone in 2010 and the number of papers published up to 2010. We then categorized FSS and number of papers in 2010 as “low”, “medium” and “high” to import it into statistical models and see whether this had a significant association with sociologists’ status in other variables. This was to check if recently promoted sociologists followed different publication patterns and reacted differently to ANVUR assessment. 4.3.1 Crossed membership repeated measurement model In order to examine the importance of institutional embeddedness and compare individuals at different institutional levels before and after ANVUR, we followed Akbaritabar, Casnici, and Squazzoni (2018) in assuming that each scientist in our database was nested into different clusters, possibly having influencing their productivity. We considered two cluster levels: (1) the department, as the first level of organizational embeddedness, and (2) the university, which were relevant for power, career and strategic relationships, sometimes also for research and collaboration (e.g., Abramo, D’Angelo, and Rosati (2016b)). This was to understand whether differences in these levels could be associated with different reactions to institutional policies. Sociologists in similar departments in different universities could be exposed to similar cultural contexts and sociologists in different departments of the same university could be exposed to similar organizational facilities and constraints. In order to accommodate this complexity, we used crossed membership random effects structure(Baayen, Davidson, and Bates 2008). In order to model ANVUR impact among different departments and universities, we followed previous research (Snjiders and Bosker 1999; Faraway 2005; Zuur et al. 2009) and used repeated measurements mixed effect model with crossed membership structure in departments and universities. This was to create “between” (different individuals in each of the conditions) and “within” (same individuals before and after ANVUR) group measures that could help us understand any possible heterogeneity in individual responses. We then kept the same random effects structure for each model so that important variables were compared without excessive complications or computational inefficiencies.18 In case of total number of publications due to count nature of this variable and to control robustness of our results, we ran separate models with negative binomial distribution (while keeping the random effects structure similar to our other models). 4.4 Results It is important to first note that despite the vast coverage of publications in Scopus (Scopus 2017), our dataset only covered a fraction of the productivity of Italian sociologists (which is limited even more when focusing only on five years before and after ANVUR). Indeed, only 57.53% of the 1,029 sociologists had at least one publication record indexed in Scopus. Most missing records were probably published in less prestigious national outlets, including book series by national publishers (Akbaritabar, Casnici, and Squazzoni 2018). Figure 4.1 shows that the distribution of publications was highly skewed with a few sociologists publishing a considerable amount of the total number of publications. This was in line with previous studies, which showed that productivity is cumulative and non-linear (e.g., Nygaard (2015); Ramsden (1994); Coile (1977)). Table 4.1 presents a descriptive view (mean and median) of total number of publications and FSS of sociologists compared over geographical regions, universities of different ranks, sectors and departments. Figure 4.1: Distribution of the total number of publications 2006-2015 (Scopus data) (X = number of publications, Y = percentage of authors with that much publications) Table 4.1: Descriptive statistics of the total number of publications (count) and FSS (scaled to 0-1), A = Average, M = Median, BF = Before ANVUR, AF = After ANVUR Main Cat Sub Cat A FSS BF M FSS BF A Pub BF M Pub BF A FSS AF M FSS AF A Pub AF M Pub AF Geo Region center 0.048 0.001 1.729 1.0 0.006 0.000 2.466 1.0 Geo Region isolated 0.011 0.013 1.364 1.0 0.003 0.000 2.259 1.0 Geo Region north 0.097 0.013 2.312 1.5 0.023 0.002 4.350 3.0 Geo Region south 0.033 0.000 1.605 1.0 0.004 0.000 2.405 2.0 University Rank high 0.043 0.007 1.940 1.0 0.009 0.001 3.278 2.0 University Rank low 0.099 0.003 2.100 1.0 0.011 0.000 3.294 2.0 University Rank medium 0.112 0.007 2.163 1.0 0.026 0.001 3.874 2.0 Sector SPS/07 0.048 0.003 1.977 1.0 0.013 0.001 3.284 2.0 Sector SPS/08 0.071 0.006 1.915 1.0 0.016 0.000 3.552 2.0 Sector SPS/09 0.123 0.012 2.308 1.0 0.019 0.002 4.186 2.5 Sector SPS/10 0.100 0.025 2.133 2.0 0.018 0.000 3.235 2.0 Sector SPS/11 0.152 0.023 2.625 1.5 0.010 0.004 2.800 2.0 Sector SPS/12 0.022 0.000 1.812 1.5 0.010 0.000 3.100 2.0 Department Economics 0.131 0.004 2.538 1.0 0.034 0.000 3.913 2.0 Department Engineering 0.068 0.006 1.333 1.0 0.006 0.001 3.300 2.0 Department Humanities 0.074 0.005 2.121 1.0 0.013 0.001 3.528 2.0 Department Medicine 0.003 0.000 1.667 1.0 0.001 0.000 3.333 3.0 Department Other 0.000 0.000 1.250 1.0 0.002 0.000 2.500 2.0 Department Psychology 0.012 0.014 1.667 1.0 0.008 0.003 4.000 2.0 Department Social Sciences 0.071 0.010 2.020 1.0 0.016 0.001 3.465 2.0 Following Abramo, Cicero, and D’Angelo (2013), we restricted our analysis to sociologists with FSS values higher than 0. We considered multilevel repeated measures with nested structure for each relevant variable such as: the FSS, internationalization, number of coauthors, number of papers and overall citations. Results showed that the FSS decreased significantly after ANVUR (-0.053***, CI = [-0.068, -0.038]).19 We controlled whether this was merely the effect of lower citations for newer papers published after ANVUR. Here, we found that there were lower citations after ANVUR, but results were not statistically significant (-0.009, CI = [-0.025, 0.007]). Unlike previous studies, which suggested that internationalization of scientific collaborations has recently increased (e.g., Leydesdorff, Park, and Wagner (2014); Akbaritabar, Casnici, and Squazzoni (2018)), we found that the internationalization of Italian sociologists actually decreased after ANVUR (-0.039***, CI = [-0.052, -0.025]) as did the number of coauthors (-0.013**, CI = [-0.025, -0.00004]). Only the number of articles published by Italian sociologists increased (0.780***, CI = [0.670, 0.890]). Note that these are baseline (NULL) models which had the same random structure as those described in the Methods section, but they did not include any fixed effects. In this way, we tried to explore the general trends after ANVUR (see Table ?? in the Appendix Section for further detail). We then looked at the effect of “within” and “between” groups on FSS and the number of papers, including the academic level and its change from 2010 to 2016 and each subject’s scientific disciplinary sector. Table ?? shows the results with FSS as a dependent variable20. In general, the FSS of sociologists did not increase after ANVUR. When considering between group effects (see rows without × post-ANVUR), we found certain specific differences, such as SPS/09 and SPS/11 have higher FSS than SPS/07, associate and full professors having significantly higher FSS than assistant professors. However, more importantly, sociologists with a higher FSS in 2010, were the same as those who were more productive in 2016. Similarly, sociologists who had a high or medium number of papers published in 2010 were more prolific even between 2010 and 2016. Moreover, we found that sociologists who had been promoted between 2010 and 2016 were not significantly more productive than those who were not. When considering within group effects (see × post-ANVUR rows), we did not find any significant positive impact of ANVUR but a few significant negative impact. The average gap of FSS of sociologists who had a higher FSS in 2010 and those who had low FSS in 2010 significantly decreased after ANVUR. The same for sociologists who were more prolific in terms of publications compared to low prolific ones in 2010. These results contradict previous research, showing that more prolific authors tended to have more recognition in terms of citations (Hâncean and Perc 2016). &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Comparative table of Repeated measures mixed effect analysis to check overall ANVUR effect on research productivity (Dependent variable FSS) Model 1 Model 2 Model 3 Model 4 Model 5 Constant 0.04 (0.01)*** 0.03 (0.01)* 0.07 (0.01)*** 0.00 (0.01) 0.01 (0.01) SPS/08 0.02 (0.02) SPS/09 0.08 (0.02)*** SPS/10 0.04 (0.03) SPS/11 0.10 (0.04)** SPS/12 -0.02 (0.03) Post-ANVUR -0.03 (0.01)** -0.01 (0.01) -0.05 (0.01)*** 0.00 (0.01) -0.00 (0.01) SPS/08 × post-ANVUR -0.01 (0.02) SPS/09 × post-ANVUR -0.07 (0.02)** SPS/10 × post-ANVUR -0.04 (0.03) SPS/11 × post-ANVUR -0.10 (0.04)* SPS/12 × post-ANVUR 0.02 (0.04) Associate professors 0.06 (0.02)*** Full professors 0.07 (0.02)*** Associate prof. × post-ANVUR -0.05 (0.02)** Full prof. × post-ANVUR -0.07 (0.02)*** Level changed from 2010 -0.00 (0.01) Level changed × post-ANVUR -0.00 (0.02) Medium FSS in 2010 0.03 (0.01)* High FSS in 2010 0.53 (0.02)*** Medium FSS in 2010 × post-ANVUR -0.01 (0.02) High FSS in 2010 × post-ANVUR -0.40 (0.02)*** Medium n.o papers in 2010 0.11 (0.02)*** High n.o papers in 2010 0.39 (0.03)*** Medium n.o papers in 2010 × post-ANVUR -0.08 (0.02)*** High n.o papers in 2010 × post-ANVUR -0.26 (0.04)*** AIC -1150.73 -1192.83 -1189.58 -877.86 -544.48 BIC -1076.36 -1146.35 -1152.40 -837.48 -504.10 Log Likelihood 591.36 606.42 602.79 448.93 282.24 Num. obs. 771 771 771 419 419 Num. groups: id 587 587 587 235 235 Num. groups: university 66 66 66 49 49 Num. groups: department 7 7 7 7 7 Var: id (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: university (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: department (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: Residual 0.01 0.01 0.01 0.00 0.01 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 We then considered the total number of publications as a dependent variable rather than the FSS. Considering between group effects (rows of Table ?? without × post-ANVUR), we found no significant differences in the total number of articles between sociologists from different disciplinary sectors. Those who were promoted did not publish any more. Sociologists with high FSS in 2010 had more papers in 2016. Confirming previous research on productivity persistence (Hâncean and Perc 2016), we found that sociologists with a medium and high number of papers in 2010 were the same with more articles published in 2016. When considering within group effects (rows of Table ?? where × post-ANVUR is indicated), we found some traces of strategic signaling: sociologists who were promoted between 2010 and 2016, were the same as those publishing more after ANVUR but it was not statistically significant (Leahey, Keith, and Crockett 2010; Long 1992; Grant and Ward 1991). We found that those with high FSS in 2010 kept a positive gap with lower prolific group even in 2016 while the gap between those with medium and high number of papers in 2010 decreased in 2016. Since total number of publications has a count nature and to control the robustness of resutls presented here (which is based on scaled version of total number of publications to 0-1), we ran negative binomial models using count data (see Table ?? in the Appendix Section)). In case of sociologists with medium and high number of papers in 2010 the results were reverse to what is reported here, meaning the gap of productivity between them and those with low number of papers in 2010 has decreased in 2016, which calls further probes. &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Comparative table of Repeated measures mixed effect analysis to check overall ANVUR effect on research productivity (Dependent variable number of papers published) Model 1 Model 2 Model 3 Model 4 Model 5 Constant 0.05 (0.01)*** 0.02 (0.01) 0.05 (0.01)*** 0.03 (0.01)* 0.00 (0.01) SPS/08 -0.02 (0.01) SPS/09 0.01 (0.02) SPS/10 -0.01 (0.02) SPS/11 0.04 (0.03) SPS/12 -0.01 (0.02) Post-ANVUR -0.00 (0.01) 0.02 (0.01)* -0.00 (0.01) 0.01 (0.01) 0.06 (0.01)*** SPS/08 × post-ANVUR 0.03 (0.01) SPS/09 × post-ANVUR 0.01 (0.02) SPS/10 × post-ANVUR 0.01 (0.03) SPS/11 × post-ANVUR -0.05 (0.03) SPS/12 × post-ANVUR 0.00 (0.03) Associate professors 0.05 (0.01)*** Full professors 0.05 (0.01)*** Associate prof. × post-ANVUR -0.03 (0.01)* Full prof. × post-ANVUR -0.02 (0.01) Level changed from 2010 -0.02 (0.01) Level changed × post-ANVUR 0.02 (0.01) Medium FSS in 2010 0.03 (0.01) High FSS in 2010 0.25 (0.02)*** Medium FSS in 2010 × post-ANVUR 0.03 (0.02) High FSS in 2010 × post-ANVUR -0.02 (0.03) Medium n.o papers in 2010 0.12 (0.01)*** High n.o papers in 2010 0.42 (0.02)*** Medium n.o papers in 2010 × post-ANVUR -0.04 (0.01)*** High n.o papers in 2010 × post-ANVUR -0.20 (0.02)*** AIC -1390.24 -1445.51 -1447.63 -724.55 -870.19 BIC -1315.88 -1399.03 -1410.44 -684.17 -829.81 Log Likelihood 711.12 732.75 731.81 372.28 445.09 Num. obs. 771 771 771 419 419 Num. groups: id 587 587 587 235 235 Num. groups: university 66 66 66 49 49 Num. groups: department 7 7 7 7 7 Var: id (Intercept) 0.00 0.00 0.00 0.01 0.00 Var: university (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: department (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: Residual 0.00 0.00 0.00 0.00 0.00 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 As previously mentioned, ANVUR ranked Italian journals, and assigned categories such as Fascia (whether Fascia A, B, or C) and non-Fascia (ANVUR 2012). From a total of 2,607 papers in our sample, Fascia articles were 409 (15.69 %) while non-Fascia articles were 2,198 (84.31 %). By adding these categories to a separate set of models, we attempted to verify whether sociologists published differently in these journals. We hypothesized that under assessment, sociologists could be induced to target more national journals given that these were considered influential in evaluation (by being Fascia) but were less competitive targets for easier publications. However, Table ??21 shows that Italian sociologists preferably published in non-Fascia journals even after ANVUR, although the statistical effect was not significant (0.01, CI = [-0.01; 0.02]). Furthermore, we found that Italian sociologists published less in journals categorized as Fascia by VQR 2004-2010 after ANVUR (-0.09, CI = [-0.13, -0.04]) (For more elaborated analysis on Fascia and non-Fascia journals, see Table ?? and ?? in the Appendix Section). Considering that our sample covered only journals and book series of the highest quality (i.e., international and national journals indexed in Scopus including 50% of Fascia journals), it is reasonable to suppose that other scientists either targeted even lower quality journals and book series not indexed in Scopus or did not publish at all. &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Models comparing trend of number of publications in Fascia and non-Fascia journals after ANVUR Model 1 Model 2 Constant 0.13 (0.02)*** 0.05 (0.01)*** Pub in Fascia journals post-ANVUR -0.09 (0.02)*** Pub in non-Fascia journals post-ANVUR 0.01 (0.01) AIC -236.60 -1277.24 BIC -215.84 -1250.24 Log Likelihood 124.30 644.62 Num. obs. 235 665 Num. groups: id 214 508 Num. groups: university 49 64 Num. groups: department 7 7 Var: id (Intercept) 0.01 0.00 Var: university (Intercept) 0.00 0.00 Var: department (Intercept) 0.00 0.00 Var: Residual 0.01 0.00 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 4.5 Discussion and conclusions This chapter aims to provide a quantitative analysis of the impact of ANVUR and VQR 2004-2010 research assessment on Italian sociologists’ publication strategies. We considered sociologists an interesting case as this community is characterized by the co-existence of different sub-communities, some closer to the humanities, while others are more aligned to international standards of hard sciences. Considering that the assessment followed informed peer review in a context that did not have any consensual evaluation standards and was not familiar with these assessments, it was interesting to examine scientists’ reactions (Abramo and D’Angelo 2011a). Indeed, besides the pros and cons of this assessment (e.g., Franceschini and Maisano (2017); Baccini and De Nicolao (2016); Abramo and D’Angelo (2017)), evaluating the research output of scientists in similar periods can provide a picture of the interplay between institutional pressure and endogenous patterns of behavior. This is why, independent of the details and specifics, the VQR assessment by ANVUR could be considered the first policy experiment on “nudging” Italian scientists towards international standards of research (e.g., Ancaiani et al. (2015); Bertocchi et al. (2015); Benedetto et al. (2017b); Benedetto et al. (2017a)). However, it is also worth noting that VQR assessment embodied a certain level of institutional ambiguity (Boffo and Moscati 1998). The methods and procedures used by ANVUR for sociologists included redundant signals, sometimes even contradictory, e.g., discriminating publication outlets according to their quality in principle, at the same time restricting the Fascia list (top quality) only to certain prestigious national journals. This would suggest that certain endogenous properties of the Italian academic system, such as the presence of a well-established system of national and local publication outlets, perhaps controlled by close colleagues, could have discouraged international research without penalizing promotion and careers (e.g., Abramo, D’Angelo, and Murgia (2017)). Furthermore, considering that scientists have their own personal career agenda, also influenced by local contexts (e.g., department or university hiring programs) and that there are fixed costs and endogenous forces that constrain productivity, it is not surprising that institutional pressures were individually interpreted differently. This lack of coherence between performance evaluation and promotion and career advancement (Abramo, D’Angelo, and Rosati 2014) has led some observer even to question whether the Italian academic system is prepared to reward any “performance based” scheme (Bertocchi et al. 2015). Although the assessment had certainly positive implications, i.e., establishing a competitive resource allocation scheme for university structures, its signaling function on the importance of high-quality research on social scientists was limited, with adaptive responses that probably reflected the rigidities and constraints of short-term adjustments. Our findings suggest that ANVUR and specifically VQR 2004-2010 research assessment did not stimulate the quantity or quality of research output among Italian sociologists. All observed differences were mainly due to promotion and individual strategies and motivation, only partially malleable by institutional stimuli. Those who were more productive before were also more productive later. It is probable that to the ambiguity of institutional signals of the quality of publication outlets, the artificial definition of Fascia journals, which was often irrespective of the “objective” prestige of outlets and the mismatch between VQR 2004-2010 and the overlapping national habilitation procedures were used strategically by academics (Jonkers and Zacharewicz 2016). Secondly, it is worth noting that while attempts at using VQR 2004-2010 to link research assessment to resource allocation at the university level have been successfully pursued by MIUR, positive and negative rewards have not affected individual academics or groups. Here, universities exploit their relative degree of autonomy in promotion, careers and funding allocations. Thus, comparative research on similar research assessments in different EU contexts (e.g., Sandström and Van den Besselaar (2018)), in which universities and departments are embedded in different institutional regimes (e.g., more or less autonomy and centralized/decentralized university systems) could improve our understanding of the complex interplay between institutional policies and individual behavior (Provasi, Squazzoni, and Tosio 2012). In this respect, it is worth noting that initiatives aligning assessment and promotions at different academic organizational levels and based on more transparent evaluation procedures could help reduce such institutional ambiguity. Systematic research comparing trajectories and adaptations in different fields could be used to understand the interplay of pre-existing endogenous forces and the different malleability of specific communities in more detail, possibly trying to contextualize evaluation methods (e.g., bibliometrics, informed peer review and the time scale of evaluations) on context-specific if not on individual characteristics (see the case of gender in Marini and Meschitti (2018); see also Abramo, D’Angelo, and Rosati (2014); Jonkers and Zacharewicz (2016); Abramo, D’Angelo, and Rosati (2015)). Finally, our work has certain limitations that should be considered. First, while Scopus covers all the most prestigious international and national outlets, including international book series, most Italian sociologists seem to address their work to plenty of local outlets that were not included in our sample (Bertocchi et al. 2015). By including datasets that cover national publications in more detail (e.g., Google Scholar or MIUR database), we could verify whether Italian sociologists reacted to the institutional pressure of ANVUR by increasing publications in these outlets, also considering that most of them do not follow strict peer review policies and accept/elicit submissions by their editorial boards. However, considering that our findings looked at (low-profile) adaptive responses by the most productive sociologists, it would not be surprising to find whether our findings could also be generalizable to sociologists’ productivity not covered here. Furthermore, it is worth mentioning that Scopus is increasing its coverage step-by-step with implications on the number and type of products, which in turn affects the observed level of scientist production as reflected in our and similar samples. Secondly, our analysis on the effects of competition for promotion and career on publication patterns is incomplete. Indeed, we were only able to reconstruct those who were eventually promoted during the assessment (Abramo, D’Angelo, and Rosati 2014), while we did not have any data on candidates who applied for the same positions but were not eventually promoted. This means that the effect of competition for promotion and career may be over-estimated in our analysis. To understand the truth of this assertion, we could record all candidates for all positions as traceable on the MIUR website. However, this would require extensive work which is significantly time consuming, as data collection in this case could not be automatized. Finally, we used crossed membership random effects structure which enabled studying organizational context along with other fixed effects while ruling out individual subjects’ random noise (see Baayen, Davidson, and Bates (2008) for a discussion), but there are other methodological possibilities to study effect of policy changes in scientist’s behavior, specifically Dif in Dif and Regression Discontinuity Design (e.g. see Seeber et al. (2017) for an example) which we haven’t used here. Those analytical strategies might help give more insights into ANVUR’s effects. 4.6 Appendix This appendix includes further data and analysis that complement findings presented in the article. In particular, it provides details on repeated measurement mixed effect models with nested structures, which were our baseline, and models which considered publications in Fascia and non-Fascia journals as dependent variable. 4.6.1 Appendix A: Baseline models Table ?? shows the results of our baseline models which were ran to detect certain general trends in our sample. These models included the same random effects (random intercepts) structure as other models, while they did not include any fixed effects (independent variables). In other words, these models only present the trend and significance of change in dependent variable before and after ANVUR. &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Comparative table of baseline Repeated measures mixed effect analysis to check overall ANVUR effect on research productivity (Different dependent variables presented) Model 1 Model 2 Model 3 Model 4 Model 5 Constant 0.07 (0.01)*** 0.05 (0.01)*** 0.06 (0.01)*** 0.05 (0.01)*** 0.20 (0.07)** FSS Post-ANVUR -0.05 (0.01)*** Citations Post-ANVUR -0.01 (0.01) Internationalization Post-ANVUR -0.04 (0.01)*** N.O. authors Post-ANVUR -0.01 (0.01)* N.O. of papers Post-ANVUR 0.78 (0.06)*** AIC -1207.65 -1143.31 -1295.47 -1438.08 3171.07 BIC -1179.76 -1115.42 -1267.59 -1410.19 3198.95 Log Likelihood 609.82 577.65 653.74 725.04 -1579.53 Num. obs. 771 771 771 771 771 Num. groups: id 587 587 587 587 587 Num. groups: university 66 66 66 66 66 Num. groups: department 7 7 7 7 7 Var: id (Intercept) 0.00 0.00 0.00 0.00 0.33 Var: university (Intercept) 0.00 0.00 0.00 0.00 0.07 Var: department (Intercept) 0.00 0.00 0.00 0.00 0.00 Var: Residual 0.01 0.01 0.01 0.01 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 4.6.2 Appendix B: papers published in Fascia journals Table ?? shows results of models that considered the number of publications in Fascia journals as dependent variable against various independent variables, e.g., academic level, change in academic level, FSS and number of papers in 2010. Results show that after ANVUR number of papers in Fascia journals increased significantly only in the case of sociologists who were more prolific and notified by community in 2010 (with medium and high FSS). For those who have been promoted from 2010 to 2016, the number of papers published in Fascia journals has increased, but only minimally and not statistically significant (-0.037, CI = [-0.033, 0.107]). &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Comparative table of Repeated measures mixed effect analysis to check overall ANVUR effect on research productivity (Dependent variable number of papers published in Fascia journals) Model 1 Model 2 Model 3 Constant 0.03 (0.03) 0.16 (0.03)*** -0.00 (0.03) Associate professors 0.15 (0.05)** Full professors 0.21 (0.05)*** Post-ANVUR -0.01 (0.03) -0.12 (0.03)*** 0.04 (0.03) Associate prof. × post-ANVUR -0.14 (0.05)* Full prof. × post-ANVUR -0.14 (0.05)** Level changed from 2010 -0.08 (0.04) Level changed × post-ANVUR 0.08 (0.05) Medium n.o papers in 2010 0.15 (0.04)*** High n.o papers in 2010 0.95 (0.07)*** Medium n.o papers in 2010 × post-ANVUR -0.13 (0.05)** High n.o papers in 2010 × post-ANVUR -0.75 (0.08)*** AIC -232.55 -225.53 -129.11 BIC -197.96 -197.85 -101.57 Log Likelihood 126.28 120.76 74.55 Num. obs. 235 235 116 Num. groups: id 214 214 95 Num. groups: university 49 49 33 Num. groups: department 7 7 6 Var: id (Intercept) 0.00 0.01 0.00 Var: university (Intercept) 0.00 0.00 0.00 Var: department (Intercept) 0.00 0.00 0.00 Var: Residual 0.01 0.01 0.01 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 4.6.3 Appendix C: papers published in non-Fascia journals Table ?? shows the results of models that considered the number of publications in non-Fascia journals as dependent variable against various independent variables, e.g., scientific disciplinary sector, academic level, change in academic level, FSS and number of papers in 2010. Results showed that in the case of prolific authors with a high number of papers in 2010, for associate professors and those belonging to sector SPS/11 the number of papers published in non-Fascia journals after AVNUR decreased significantly. &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Comparative table of Repeated measures mixed effect analysis to check overall ANVUR effect on research productivity (Dependent variable number of papers published in non-Fascia journals) Model 1 Model 2 Model 3 Constant 0.02 (0.01) 0.05 (0.01)*** 0.00 (0.01) Associate professors 0.04 (0.02)** Full professors 0.04 (0.01)** Post-ANVUR 0.02 (0.01)* -0.00 (0.01) 0.05 (0.01)*** Associate prof. × post-ANVUR -0.03 (0.02) Full prof. × post-ANVUR -0.02 (0.02) Level changed from 2010 -0.02 (0.01) Level changed × post-ANVUR 0.02 (0.01) Medium n.o papers in 2010 0.12 (0.01)*** High n.o papers in 2010 0.39 (0.03)*** Medium n.o papers in 2010 × post-ANVUR -0.04 (0.01)** High n.o papers in 2010 × post-ANVUR -0.17 (0.03)*** AIC -1252.14 -1261.22 -738.08 BIC -1207.14 -1225.22 -699.03 Log Likelihood 636.07 638.61 379.04 Num. obs. 665 665 367 Num. groups: id 508 508 210 Num. groups: university 64 64 47 Num. groups: department 7 7 7 Var: id (Intercept) 0.00 0.00 0.00 Var: university (Intercept) 0.00 0.00 0.00 Var: department (Intercept) 0.00 0.00 0.00 Var: Residual 0.00 0.00 0.00 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 4.6.4 Appendix D: Negative Binomial models In order to control robustness of our results with alternative modelling strategies, we ran negative binomial models on the total number of publication as dependent variable which has a count nature and highly skewed distribution (see Table ??). In case of sociologists with medium and high number of papers in 2010 the results were reverse to what is reported in Table ??, meaning the gap of productivity between them and those with low number of papers in 2010 has decreased in 2016, which calls further probes. &lt;!DOCTYPE HTML PUBLIC “-//W3C//DTD HTML 4.01 Transitional//EN” “http://www.w3.org/TR/html4/loose.dtd”&gt; Comparative table of Repeated measures Negative Binomial models to check overall ANVUR effect on research productivity (Dependent variable count of total papers published) Model 1 Model 2 Model 3 Model 4 Model 5 Constant 0.28 (0.11)** 0.00 (0.12) 0.23 (0.09)** 0.24 (0.12)* -0.06 (0.09) SPS/08 -0.22 (0.14) SPS/09 -0.02 (0.16) SPS/10 -0.11 (0.24) SPS/11 0.21 (0.30) SPS/12 -0.02 (0.25) Post-ANVUR 0.65 (0.09)*** 0.83 (0.11)*** 0.70 (0.07)*** 0.67 (0.14)*** 1.22 (0.10)*** SPS/08 × post-ANVUR 0.30 (0.14)* SPS/09 × post-ANVUR 0.18 (0.16) SPS/10 × post-ANVUR 0.12 (0.24) SPS/11 × post-ANVUR -0.30 (0.29) SPS/12 × post-ANVUR 0.01 (0.26) Associate professors 0.31 (0.14)* Full professors 0.38 (0.14)** Associate prof. × post-ANVUR -0.08 (0.14) Full prof. × post-ANVUR -0.02 (0.14) Level changed from 2010 -0.09 (0.12) Level changed × post-ANVUR 0.19 (0.11) Medium FSS in 2010 0.24 (0.14) High FSS in 2010 1.28 (0.18)*** Medium FSS in 2010 × post-ANVUR 0.36 (0.16)* High FSS in 2010 × post-ANVUR 0.22 (0.18) Medium n.o papers in 2010 1.01 (0.12)*** High n.o papers in 2010 1.93 (0.17)*** Medium n.o papers in 2010 × post-ANVUR -0.34 (0.13)** High n.o papers in 2010 × post-ANVUR -0.63 (0.16)*** AIC 3181.54 3160.01 3171.43 1691.15 1630.59 BIC 3255.90 3206.48 3208.61 1731.53 1670.97 Log Likelihood -1574.77 -1570.00 -1577.71 -835.58 -805.30 Num. obs. 771 771 771 419 419 Num. groups: id 587 587 587 235 235 Num. groups: university 66 66 66 49 49 Num. groups: department 7 7 7 7 7 Var: id (Intercept) 0.33 0.31 0.33 0.21 0.14 Var: university (Intercept) 0.07 0.07 0.07 0.00 0.01 Var: department (Intercept) 0.00 0.00 0.00 0.00 0.00 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 References "],
["genderdiversitychapter.html", "Chapter 5 Gender patterns of publication in top sociology journals22 Abstract 5.1 Introduction 5.2 Dataset 5.3 Descriptive Results 5.4 Article content analysis 5.5 Statistical models 5.6 Conclusions", " Chapter 5 Gender patterns of publication in top sociology journals22 Abstract This article examines publication patterns over the last 70 years from the American Sociological Review and American Journal of Sociology, the two most prominent journals in sociology. We reconstructed gender of all published authors, identified article contents and collected data on citations. We reconstructed each author’s academic pedigree. Results suggested that these prestigious journals especially considered male authors and their exclusive co-authorship ties. These gender penalties persist even when looking at citations and after controlling for the influence of academic affiliation. Keywords: “Sociology, Journals, Gender, Co-authorship, Inequality” 5.1 Introduction The construction of academic reputation is a complex organizational process in which the publishing system has a major role (Clemens et al. 1995). Although academic careers depend on complex factors, publications are key for tenure and promotion (Leahey, Keith, and Crockett 2010; Long 1992; Grant and Ward 1991). In an era of “publish or perish” hyper-competition, even funding agencies heavily rely on bibliometric indicators, such as the number of publications and citations, to allocate grants (Edwards and Roy 2017; Nederhof 2006). As such, understanding publication patterns in prestigious journals can help reveal possible sources of inequality in academic credit allocation. Indeed, previous research showed that while prestigious journals determine stratification processes, which shape standards of performance and identity of a discipline, in a context of excessive competition, their elitism could penalize innovation, reduce academic diversity and favor inertia. For instance, in a study on top sociology journals in 1987-88, Clemens et al. (1995) found that women rarely appeared among the rank of most prolific authors and productivity and reputation could be even orthogonal to one another (see also Karides et al. (2001)). In a recent study on publications in 2000-2015, Teele and Thelen (2017) found that women are disproportionately under-published in top political science journals. They found that the largest percentage of publications were dominated by all-male teams, with women less involved in co-authorship networks. They suggested that this could be due to a self-selection process. Given that women may be attracted more by qualitative research, also due to structural discrimination in higher education and considering that these journals are predominantly quantitative, they would therefore submit less to these top journals. The fact that there are gender differences in academic success despite the rise of women in science is well-known (Cole and Zuckerman 1984, 1987; Young 1995). Research suggested that women are penalized especially in STEM research (Cain and Leahey 2014; Lomperis 1990; Kahn 1993; Sheltzer and Smith 2014), are paid less (Prpić 2002) and are preferably hired in lower level academic positions and in less prestigious institutes (Lomperis 1990; Heijstra, Bjarnason, and Rafnsdóttir 2015). They publish fewer papers and are cited less (e.g., Xie and Shauman (1998); Young (1995); Maliniak, Powers, and Walter (2013)). On the one hand, this may be due to gender differences in scientific collaboration patterns and attitudes. Firstly, research suggests that women tend to establish more homogeneous and smaller collaboration networks (Grant and Ward 1991; Renzulli, Aldrich, and Moody 2000). This would decrease their chance to be part of the core network of star scientists (Moody 2004). Secondly, they prefer more diversified research programs and so their research is less specialized, penalizing their visibility and success (Leahey 2006, 2007). This could decrease their access to relevant resources for funding and promotion (Xie and Shauman 1998; Weisshaar 2017) and make their academic career less stable or rewarding (Hancock and Baum 2010; Preston 1994), also due to distortion from hiring committees due to family obligations (Rivera 2017). On the other hand, there are reflexive constructive processes in which gendered patterns could be internalized by women (e.g., Ridgeway (2009); MacPhee, Farro, and Canetto (2013); Brink and Benschop (2014)). For instance, even when women are motivated to pursue an academic career, they have lower expectations of success (Prpić 2002; Fox and Stephan 2001; Leslie et al. 2015). This can be due to what Cech et al. (2011) p 642 called “professional role confidence”, i.e., “individuals’ confidence in their ability to fulfill the expected roles, competences, and identity features of a successful member of their profession”. Not only can these socially shared beliefs contribute to gendered persistence in male-dominated professions; they build-in gender penalties via self-reinforcing processes. This was confirmed even by a recent lab experiment, where subjects were asked to evaluate a sample of comparable academic articles in terms of quality, clarity, significance and methodological rigor. Articles published by women receive lower evaluations even by female evaluators (Krawczyk and Smyk 2016). It is important to note that these aspects have important implications. While the under-representativeness of women calls for a response for equity, research on natural and cultural evolution has indicated that diversity is key for adaptation, learning and resilience in any complex system (e.g., Page (2010)). Given that science is a self-organized and decentralized complex system, gender penalties could create an institutional context that reduces cultural and epistemic heterogeneity and diversity (Belle, Smith-Doerr, and O’Brien 2014). This could have negative implications on collective learning and experimentation. This is even more so in sociology, which does not have a consensual epistemological or methodological standard (Dogan and Pahre 1989). It is therefore not surprising that in a recent review on diversity in working teams of scientists, Nielsen et al. (2017) found that more gender, ethnically or culturally diverse teams performed better. Misra et al. (2017) suggested that active inclusion of minorities tend to promote innovation, creativity, and positive reputational effects especially when teams are integrated. In this chapter, we wanted to provide an overview of gender publication patterns in top journals in sociology, i.e., the American Sociological Review (hereafter ASR) and the American Journal of Sociology (hereafter AJS) (Leahey 2007; Light 2013). Not only do these two journals constitute the elite of our discipline, in a stratified publication market where competition, control and boundaries are strong (some critics have even considered these journals as “alleged cartels”, see Platt (2016)); they also are different in their historical origins, which trace back to the schism among ASA members in 1935, with AJS becoming the journal of an independent, prestigious department (Chicago) and ASR embedded in a representative association (e.g., Lengermann (1979); Abbott (1999)). While previous research suggests that sociology is probably less gender biased than other disciplines, due to more women graduates (Lutter and Schröder 2016), it is probable that tenure tracks and promotion in the academic élite is more competitive (Light 2009), due to the influence of symbolic capital in academic success (Bourdieu 1988). This would suggest that looking at the top could reveal gender patterns of inequality, which weak competitiveness in lower academic layers could obscure. Furthermore, given that competitive pressure for publication is higher in these top journals, looking at the top could reveal general trends in hyper-competitive science today. To do so, we followed a recent study by Teele and Thelen (2017) on a sample of political science journals in the data collection strategy, while paying attention to academic affiliations over a longer time scale. In addition, we applied advanced machine learning techniques on article contents and integrated data on publications with available web data on authors’ academic pedigree to understand whether academic affiliation or research contents could contribute to inequalities in publishing. The rest of the chapter is organized as follows: Sect 2 presents our data, while Sect 3 presents our descriptive results. Sect 4 presents an analysis of article contents, while Sect 5 presents some more advanced statistical models. Finally, Sect 6 summarizes our main findings and discusses limitations and further developments of our work. 5.2 Dataset Data on all AJS and ASR publications were extracted from Scopus on 20th January 2017, and included article title, authors’ names and affiliation, and number of citations received. Table 5.1 shows the time range of publications in each of these journals. Table 5.1: Number of papers and time range of publications in each journal Journal name # papers Sample Starts Sample Ends American Journal of Sociology 1,153 1946 2016 American Sociological Review 1,440 1965 2016 Total number of papers 2,593 In order to check for authors’ gender, we used authors’ first names to send automatic requests with R scripts to a database of numerous names extracted from social media profiles (Wais 2016). Simultaneously a research assistant (hereafter RA) hand-coded author gender. In any conflicting attribution case, the RA researched the online profile of authors, whenever available. We then matched the gender extracted from API23 with the hand-coded one. In any cases of differences (41 out of 2,897 authors), we used the hand-coded gender. In cases of missing data in the hand-coded procedure (22 out of 2,897 authors), we used the automatic gender extracted from API, which was based on accuracy percentages (note that we had only 17 out of 2,897 missing genders). As suggested by Young (1995), Maliniak, Powers, and Walter (2013) and Teele and Thelen (2017) we coded any article as written by Solo male, Solo female, All male team, All female team, and Cross gender collaboration. Furthermore, following Karides et al. (2001) and Teele and Thelen (2017), we used the American Sociological Association (hereafter ASA) annual membership as a proxy of the gender composition of the community24. In order to add some control variables, we also checked the CV and online information of each author. This allowed us to identify the academic institution that awarded each scientist’s PhD title. We also looked at the current gender composition of the first 12 top ranked Ivy-League sociology departments in the Shanghai ranking, by extracting data from the official websites25. These variables were used to estimate whether women could potentially benefit differently from an Ivy-League effect in the publication process. 5.3 Descriptive Results Figure 5.1 shows the historical trend of the percentage of women who authored an article in AJS and ASR and in both journals, compared to the percentage of women who were ASA members (continuous line). Considering only the last year of our sample, 2016, while women were more among ASA members (53%), the gender balance among authors in AJS and ASR approximated a 70(men)/30(women) ratio. Although the two journals showed different dynamics and since 2000 the gender gap has been reducing, it would take more than ten years to reach a fair gender balance (if perhaps unstable) at the current rate. Although the number of authors has increased over time (e.g., Wuchty, Jones, and Uzzi (2007)), which could be simply due to the increased number of articles published in these journals yearly, Figure 2 shows that the number of women who published in AJS and ASR tended to increase less than men. Figure 5.1: Percentage of women among authors in AJS and ASR (dashed lines) compared to percentage of ASA female members over time (continuous lines). At the top, the aggregate trend, at the bottom the trend per journal. Data are based on a t-test of the distributions. The grey zone indicates the confidence interval of the two lines. When considering co-authorship patterns, we found that while 84% of articles published in AJS and ASR had at least one (or more) male author(s), only 40% of these had at least one (or more) female author(s). In general, the picture approximates a 70/30 ratio, which is slightly better than what suggested by Young (1995)’s study in political science but similar to what found more recently by Teele and Thelen (2017) (see Table 5.2). Although norms and practices of collaboration might be context-specific, it seems that fields such as sociology and political science do not dramatically differ in terms of gender collaboration patterns. Figure 5.2: Gender trend of authorship in AJS and ASR Table 5.2: The share of male and female authors (Note that there are more “authorships” than individual authors as we count individual scientists more than once if they write more than one paper in the journals. This explains why the total number of authors was 4709) Journal Name # All Papers # All Authors # Men % Men # Women % Women AJS 1,153 2,023 1,469 72.61 547 27.04 ASR 1,440 2,686 1,860 69.25 813 30.27 Total number 2,593 4,709 3,329 1,360 More specifically, Figure 5.3 shows that in both journals, only 11% of articles were published exclusively by solo women against 37% in AJS and 29.5% in ASR of solo male. Furthermore, only 5.4% of articles in ASR and 3.2% in AJS were published by all-female coauthor teams. However, Figure 5.4 shows that cross-gender co-authorship increased at least recently. Figure 5.3: Gender co-authorship in AJS and ASR Figure 5.4: Gender co-authorship dynamics in AJS and ASR Figure 5.5 shows that women are first authors of these articles less frequently than men and that inequalities in author positions did not significantly change over time. The trend is similar in the case of cross-gender collaboration (see the bottom panel). Indeed, the first authors of mixed-gender teams were predominately men, with only a few exceptions for certain years in ASR in which first authorships were more gender balanced. Figure 6 shows the co-authorship networks in these two journals. While results indicate the co-existence of different clusters of more or less influential connections, it is rare that women are in central positions in these networks. Table 5.3 shows that the network of co-authorships was fragmented (i.e., high number of disconnected, small sized clusters) and included half of edges formed exclusively between men (48.15%), 35.41% cross-gender and only 15% exclusively between women. Figure 5.5: Gender difference in first authorship in in AJS and ASR. At the top, the aggregate trend of all publications, at the bottom the specific trend of cross-gender coauthored articles. Table 5.3: Co-authorship network statistics Metric Value Number of nodes 2897 number of edges 2787 Number of female authors 936 Number of male authors 1944 Men to men edges 48.15 Men to women edges 35.41 Women to women edges 15.5 Density 0.0007 Diameter 46 Number of clusters 1084 Cluster size (avg) 2.67 Cluster size (std) 19.72 Figure 5.6: Gendered co-authorship networks (nodes are authors, ties are authoring articles together). Black indicates males, white indicates females. Solid ties are cross-gender, dotted within males and longdashed within females. Node size indicates an author’s importance, i.e., his/her degree centrality. The higher the importance is, the bigger the nodes are. We then looked at more sophisticated network characteristics, such as betweenness, triangles, and network degree. One of the main centrality measures used in network analysis, betweenness reflects the importance of a node to mediate a network’s structure (i.e., it represents the number of times a node is positioned on the shortest paths between any pairs of nodes in a network) (Wasserman and Faust 1994 p 189). As regards to triangles, it is important to note that an important aspect of any social network compared to random networks is the tendency of actors to close their mutual connections. In our cases, triangles represent the tendency of scientists to write articles with collaborators of their coauthors more than with other potential collaborators (Luke 2015 p 16). Finally, network degree represents another measure of the importance of an actor in a network. In our cases, we considered the number of coauthorship ties any author had (Wasserman and Faust 1994 p 178). By looking at these network metrics, we found that top women had higher degrees (6 out of top 10 authors) and more inclined to building triangles among authors (i.e., they co-authored more frequently with co-authors of their previous co-authors). However, this gave women neither an advantage in terms of number of publications nor more recognition and citations (see Table 5.4). This confirms research on the misalignment between co-authorship network positions of scientists and prolificacy and success (Grimaldo, Marušić, and Squazzoni 2018). Table 5.4: The rank of better connected authors (Gender: M = men, W= women) Betweenness More prolific More cited Triangles Degree Roscigno (M) Bearman (M) Uzzi (M) Kelly (W) Moen (W) Baumer (M) Massey (M) Sampson (M) Moen (W) Kelly (W) Qian (M) Gove (M) Portes (M) Kossek (W) Land (M) Jacobs (M) Rao (W) Massey (M) Casper (W) England (W) O’brien (M) Crowder (M) Meyer (M) Okechukwu (W) Logan (M) King (M) Tolnay (M) Emirbayer (M) Mierzwa (M) Kossek (W) Martin (M) Logan (M) Thomas (M) Hanson (W) DiPrete (M) Dixon (M) DiPrete (M) Boli (M) Davis (W) Pescosolido (W) Messner (M) Jacobs (M) Ramirez (M) Hammer (W) McCammon (W) Carroll (M) Firebaugh (M) Podolny (M) Oakes (M) Hannan (M) Figure 5.7 shows that women had only a 21.5% premium in terms of higher probability of publishing in AJS and ASR when they were a member of a prestigious sociology department, against a 62% premium for men. Interestingly, cross-gender collaboration was more frequent among members of less prestigious departments (20.8% vs. 16.5%). Furthermore, the number of all-female teams of authors was higher when they included only females working in non-Ivy-League departments (4.5% vs. 2.7%). Figure 5.7: Gender co-authorship dynamics between Ivy and non Ivy-League authors in AJS and ASR In order to qualitatively control for hiring inequalities, we checked for the gender composition of a sample of Ivy-League sociology departments in 2017. Figure 5.8 shows that these departments hired men dis-proportionally, with the exception of New York University (46.88% of female among faculty members). This is a picture similar to what Sheltzer and Smith (2014) found in the life sciences. Figure 5.9 shows the gender distribution of department members among the top 100 universities, according to the Shanghai ranking. With only a few exceptions, in which women are hired more than men, the gender balance was more favorable to men. This would confirm that in most top universities, hiring and academic success are significantly gendered. Figure 5.8: Percentage of female faculty members in Ivy-League sociology departments in 2017 (Note that the y-axis lists departments according to the Shanghai ranking with the highest ranked at the bottom) (source: University websites) Figure 5.9: Share of females of current faculty of sociology in top 100 universities (Shanghai ranking, data on 2017) 5.4 Article content analysis In order to examine whether women and men have different attitudes of research and so write different articles, we first applied machine learning techniques to article contents, i.e., title, abstract, and keywords. By applying structural topic GLM models, we identified probability distributions of recurrent words in each article with the emergence of certain dominant topics that were shared by similar articles. We detected the top 10 most prominent topics, to map the most important characteristics of the research field. Table 5.5 shows the most important topics identified by the model and the words having the highest probability to recur in all the content of all articles. Table 5.6 shows certain exclusive words that appeared only in one specific topic, e.g., homophily was a word used only among articles that focused on networks. Table 5.7 shows all the concepts most frequently used by solo male authors in articles in each of the ten topics, while Table 5.8 shows the same for solo female authors. Results show that men and women seem to look at different aspects even when doing research on similar issues. Table 5.5: Highest probability words in each Topic Topic Word_1 Word_2 Word_3 Word_4 Word_5 Word_6 Word_7 1 racial black ethnic segregation white race population 2 class crime law legal rights race cultural 3 organizational work practices organization organizations management process 4 public religious social violence community religion school 5 human social article states united male female 6 family effects educational education life data children 7 gender labor market women employment men womens 8 economic income inequality countries growth welfare development 9 political social state movement organizations politics movements 10 social network networks cultural theory status model Table 5.6: Most exclusive words in each Topic Topic Word_1 Word_2 Word_3 Word_4 Word_5 Word_6 Word_7 1 ethnic segregation whites residential immigrants hispanic assimilation 2 homicide offenders classification interviewers law tolerance citizenship 3 accountability lawyers leaders conversation rational cohesion formalization 4 religious church pluralism schools religiosity conservative violence 5 delinquency socioeconomics disorders male human govt juvenile 6 cohort cohorts adulthood childhood children birth college 7 jobs wage wages career workers markets market 8 welfare foreign poverty investment growth economic countries 9 movements protest mobilization polity voting movement protests 10 homophily network networks trust exchange generalized scientific ## A topic model with 10 topics, 2586 documents and a 8126 word dictionary. ## A topic model with 10 topics, 2586 documents and a 8126 word dictionary. Table 5.7: Words most frequently used by solo male authors Word_1 Word_2 Word_3 Word_4 Word_5 Word_6 Word_7 topic_1 factions japan treaty revolution capitalist modernist modernists topic_2 law sector cohesion recipient grievances discourse agricultural topic_3 mismatched lottery fatherhood premarital layer mortality mental topic_4 concern aged camping ireland historiography obsolescence senescence topic_5 libidinal charismatic scientific dilemmas concept literary theorem topic_6 embeddedness workplace trade homophily mississippi strike unfree topic_7 skin tone business enterprises deindustrialization ties arisen topic_8 subcultural desegregation radius attendance urbanism animal curriculum topic_9 crisis ethnology hospitalization moral miscellaneous aids care topic_10 congregations happiness brazilian deficits felt recidivism mto ## A topic model with 10 topics, 2586 documents and a 8126 word dictionary. ## A topic model with 10 topics, 2586 documents and a 8126 word dictionary. Table 5.8: Words most frequently used by solo female authors Word_1 Word_2 Word_3 Word_4 Word_5 Word_6 Word_7 topic_1 commemorating modernist passive food schema imprinting doctrine topic_2 microfinance concessions micromobilization spatial protest marriage localities topic_3 desegregation intent illegally eeo legal establishments laws topic_4 labeling realism patrimonial frontier illness invisible commercialization topic_5 peer delinquency china relief layer micromobilization tie topic_6 sharecropping tuscany tongue downsize tuscan honor aviation topic_7 injustice polarization computerization renewal ussr combat intracohort topic_8 dictator unpaid draft reciprocity token heterosexuality apartheid topic_9 bodily breadwinning science substitutes queer musical nuns topic_10 compulsory merchants epistemology customer ethic merchant insurance Figure 5.10 shows an example of difference between solo male and solo female authors when considering articles on segregation and inequality (Topic 7). This indicates that gender could influence authors’ sensitivity towards specific concepts or issues even among specialists working in the same field. Therefore, gender penalties could also orient the attention of the community towards specific issues, so biasing exploration. Figure 5.10: Gender differences in articles on segregation and inequality (Topic 7) 5.5 Statistical models In order to test our descriptive findings more robustly, we run a negative binomial model (specifically due to count nature of our data) (Snijders and Bosker 1999; Faraway 2005; Zuur et al. 2009), in which publishing in top journals was first examined as associated with gender. We controlled the effect of Ivy-League departments by embedding each scientist in a crossed membership structure, which included the institution in which the scientist originally received his/her PhD and his/her latest academic affiliation (e.g., Akbaritabar, Casnici, and Squazzoni (2018)). This allowed us to control for the Ivy-League effect in two important stages of each scientist’s academic career. Furthermore, we checked whether the gender penalties were less pronounced over the last decades (pre-post 2000), in which gender inequalities have been under the spotlight in the public debate, also informing institutional policies. Tables ??, ?? and ?? show that differences are related to individual characteristics (i.e., see fixed effects in our models). When considering group variances (i.e., between the institution which awarded the author’s PhD title and his/her latest academic affiliation), we found minimal effects. The factor having the more robust effect was authors’ accumulated citations. Indeed, Table ?? presents another variant of our multi-level models in which we estimated the influence of gender on accumulated citations of each author. Results confirmed that citations went more preferably to articles in which men were authors. Multilevel negative binomial models Total Publications Publications before 2000 Publications after 2000 Constant 0.26 (0.04)*** 0.29 (0.05)*** 0.28 (0.04)*** Gender Male 0.20 (0.04)*** 0.12 (0.06)* 0.17 (0.04)*** AIC 7743.00 2976.32 4787.59 BIC 7772.04 3001.27 4814.65 Log Likelihood -3866.50 -1483.16 -2388.80 Num. obs. 2463 1086 1655 Num. groups: latest_uni 444 256 336 Num. groups: phd_awarded_university 329 195 250 Var: latest_uni (Intercept) 0.02 0.00 0.01 Var: phd_awarded_university (Intercept) 0.03 0.00 0.01 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 The influence of author’s gender on article citations Total Publications Total Citations Constant 0.26 (0.04)*** 4.37 (0.08)*** Gender Male 0.20 (0.04)*** 0.18 (0.06)** AIC 7743.00 28818.42 BIC 7772.04 28847.47 Log Likelihood -3866.50 -14404.21 Num. obs. 2463 2463 Num. groups: latest_uni 444 444 Num. groups: phd_awarded_university 329 329 Var: latest_uni (Intercept) 0.02 0.19 Var: phd_awarded_university (Intercept) 0.03 0.08 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 Finally, we looked at a restricted sample of more prolific, star authors, i.e., those one publishing more frequently in both journals. Among authors who published in both journals, 360 were men, 126 were women. Table ?? shows that publishing more in both journals is positively associated with higher recognition by the community but also that being a man is still significant in terms of prolificacy though not significant when considering recognition (i.e., citations). Multilevel regression models on star sociologists Total Publications Publications before 2000 Publications after 2000 Total Citations Constant 0.12 (0.03)*** 0.04 (0.05) 0.12 (0.04)*** 4.20 (0.07)*** Gender Male 0.09 (0.03)** 0.10 (0.05) 0.06 (0.04) 0.04 (0.06) Star sociologist 1.16 (0.03)*** 0.79 (0.05)*** 0.91 (0.04)*** 1.35 (0.07)*** AIC 6610.52 2751.34 4310.07 28380.56 BIC 6645.37 2781.28 4342.54 28415.42 Log Likelihood -3299.26 -1369.67 -2149.03 -14184.28 Num. obs. 2463 1086 1655 2463 Num. groups: latest_uni 444 256 336 444 Num. groups: phd_awarded_university 329 195 250 329 Var: latest_uni (Intercept) 0.00 0.00 0.00 0.16 Var: phd_awarded_university (Intercept) 0.00 0.00 0.00 0.05 p &lt; 0.001; p &lt; 0.01; p &lt; 0.05 5.6 Conclusions Mapping all publications in top sociology journals, i.e., AJS and ASR, allowed us to reveal a gender pattern. These prestigious journals seemed to especially favor men and their exclusive co-authorship ties: close to 60% of articles in both journals have been authored exclusively by male authors, alone or in male teams. We did not find relevant differences between the two outlets. Although the situation has improved since 2000, these gender inequalities seem to be persistent even after considering the influence of academic affiliation: again the ‘Ivy-League’ effect greatly benefits only male authors. As in Teele and Thelen (2017)’s study on publication patterns in political science journals, we found that the conventional standard of collaboration is the solo-male author or all-male teams, whereas women are less involved in co-authorships (Renzulli, Aldrich, and Moody 2000; Moody 2004). However, top journals in sociology seem at least more favorable to cross-gender collaborations than political science journals. Interestingly, we found that women are sometimes in important positions in the co-authorship networks but this does not provide significant advantages when looking at the top more prolific or cited authors, who are almost all men. If we consider only la crème de la crème, i.e., authors publishing more frequently on both journals, we found that gender is less significant at least on recognition (i.e., citations). In any case, this would testify to the fact that gender penalties on publications could reflect a more complex context of institutional stratification, which traces back to unequal admission to elite institutions. Obviously, estimating whether these unequal achievements are due to certain implicit discriminative practices among the academic élite or the mere consequence of a competitive, “winner takes all” academic market would require more in-depth data and analysis on journal submissions, referees and editors (Østby et al. 2013; Siler and Strang 2014). As suggested by Hancock and Baum (2010) and Sheltzer and Smith (2014), it is also difficult to understand whether these outcomes incorporate endogenous self-selection bias tracing back to education, type of research, funding and career (e.g., González-Álvarez and Cervera-Crespo (2017); Hancock and Baum (2010); Sheltzer and Smith (2014)). Here, disentangling inequalities in publications from endogenous academic excellence formation mechanisms, which typically include nonlinear complex dynamics with potential institutional Matthew effects, would be necessary to assess editorial processes in more detail (Lamont 2009). Examining these differences is also key to discuss the role of diversity in academia (Smith-Doerr, Alegria, and Sacco 2017). Encouraging diversity is beneficial to avoid group thinking and mainstream attitudes (Nielsen et al. 2017), detrimental especially in periods of uncertainty as they reduce epistemological and methodological pluralism. Our study has certain limitations that need to be considered. First, our data do not cover the entirety of the academic domain, from education to funding and promotion. For instance, as said before, looking only at publications does not help to understand even the gate-keeping role of journal editors, editorial boards and referees (Siler and Strang 2014). Therefore, our results cannot help understand editorial measures that might counterbalance these patterns. Secondly, though here we attempted at providing an explorative analysis on topics, a more in-depth attention to methods could help reveal vicious circles and self-reinforcing distortions in intellectual capital investment, which could point to education and training more than publications (Kahn 1993). In short, women may have fewer chances to be published in these top journals because they do not perform the type of research that these journals prefer and in the specific way they prefer it (Teele and Thelen 2017). Furthermore, the changing demographics of the community and certain cohort effects could also bias our findings (Abbott 2016). Finally, it is possible that these patterns are less pronounced in average and less competitive journals. In general, the proliferation of journals, the high specialization of certain outlets and the increasing number of online tools and platforms to share and communicate scientific articles have now formed a complex scholarly journal ecology. The richness and diversity of this ecology could help counterbalance these patterns. However, given the hyper-competition that characterizes the current situation of academia and the overproduction of scholarly articles, it is likely that the reputational signal of elite publications will be still important due to collective constraints of selective attention and even by hiring committees at the lower layers of the academic system. References "],
["coauthornetworkchapter.html", "Chapter 6 Italian sociology: A community of disconnected groups26 Abstract 6.1 Introduction 6.2 Data &amp; Method 6.3 Results 6.4 Conclusions and discussion 6.5 Appendix", " Chapter 6 Italian sociology: A community of disconnected groups26 Abstract Examining coauthorship networks is key to study scientist collaboration patterns and structural characteristics of scientific communities. This requires temporal and multi-level quantitative analysis. Here, we focus on coauthorship networks of sociologists in Italy, which were under-studied so far. By looking at publications indexed in Scopus, we detect the largest and most stable research communities in Italian sociology. We found that Italian sociologists are fractured in many disconnected groups, but two prominent communities are formed by economic and political sociologists around certain research topics. By applying an exponential random graph model, we found that collaboration ties were mainly driven by the research focus. However, other factors, such as preferential attachment, gender and affiliation homophily were also important. Our findings show that political sociologists tend to be more international. Our research shows the advantages of multi-level and temporal network analysis in revealing the complexity of scientific collaboration patterns. Keywords: Italian sociologists; Coauthorship networks evolution; Temporal community detection; Preferential attachment; ERGM 6.1 Introduction Connections between scientists are key to scientific progress (Garvey 1979; Zhang et al. 2018). Teamwork is instrumental to science today more than ever and this is true in both hard and social sciences (Wuchty, Jones, and Uzzi 2007). Larger collaboration networks increase the number of publications and citations, which are key for tenure and promotion in academia (Leahey, Keith, and Crockett 2010; Long 1992; Grant and Ward 1991), not to mention the probability of receiving grants from funding agencies (Edwards and Roy 2017; Nederhof 2006). In addition, collaboration is also key to recognition and academic reputation (Merton 1968). Quantitative analysis of coauthorship ties from scientific publications has been one of the most important means to study scientific collaboration (Katz and Martin 1997; Batagelj, Ferligoj, and Squazzoni 2017). This type of study reveals conditions and effects of collaboration across a wide spectrum of scientific activities, ranging from grant proposal to funding (Sciabolazza et al. 2017; Bellotti, Kronegger, and Guadalupi 2016). Studying coauthorship networks can also reveal the structure of scientific community, the evolution of its epistemic field, the degree of cohesiveness or fragmentation and the co-existence of competing paradigms and communities. In an influential article Moody (2004) questioned whether sociology became more socially integrated in the last decades. He examined coauthorship networks of sociologists using all sociological abstracts in English language from 1963 to 1999, amounting to 197,976 abstracts. He evaluated three competing hypotheses on the nature of scientific collaborations in sociology: 1) Collaboration represents a small world of distant communities of sociologists focusing on their substantive research areas, while scholars are connected through short paths; 2) A large periphery of scholars gathered around a core of a few star scientists; or 3) A structurally cohesive network, based on Abbott (2001), with wide-ranging collaboration between different specialists. He argued that the peculiar position of sociology, which has always been surrounded by adjacent disciplines and idea spaces, could make it permeable to external theories, methods and concepts, making wide-ranging collaborations especially around quantitative research probable. Moody (2004) found that sociology was characterized by a structurally cohesive core, which has grown steadily over the time. Collaboration depended on research specialization with quantitative researchers engaging more in collaboration. Finally, Moody suggested that a scientist’s probability of being embedded in the core network depended more on collaboration trajectories than on his or her specialty. Sciabolazza et al. (2017) used a modularity algorithm (Newman and Girvan 2004) to examine coauthorship networks between scholars at the University of Florida in 2013-2015. They used an exponential random graph model (ERGM) and found that similar institutional affiliation, spatial proximity, transitivity effects, and use of similar research services provided by the university predicted higher collaboration. Zhang et al. (2018) recently proposed an interesting ERGM specification that is relevant for studying coauthorship networks. They analyzed different factors influencing coauthorship tie formation, including homophily, transitivity and preferential attachment by looking at 633 prolific authors in computer science. Tie formation was found to be a complex process, which is often dominated by transitivity (the tendency of authors to collaborate with their coauthors’ collaborators is strong) and preferential attachment (the more coauthors one has, the more new collaborators (s)he will attract). These factors contribute to the so-called “Matthew effect”, leading to non-linear, cumulative processes of academic recognition and prestige (Merton 1968). The case of sociology is interesting. While sociologists collaborate more than humanities scholars and less than physicists (Babchuk, Keith, and Peters 1999), they are fragmented in small groups with weak epistemic and methodological coherence and with a contested subject (Abbott (2000), Abbott (2001); Turner (2006)). The lack of prominent and paradigmatic figures in the field (Wallerstein (2000); Hargens (2004)) and the competition with other specialists, such as economists and political scientists (Wallerstein 2000), could lead to complex collaboration patterns. Furthermore, the case of Italian sociologists is of special interest, considering the limited size of the community and its fracture between more internationalized and more local scholars (Akbaritabar, Casnici, and Squazzoni 2018). We first construct the coauthorship network based on publications indexed in Scopus with a “complete” or “sociocentric” (Marsden 2002) network approach. Uncovering patterns in these coauthorship networks requires advanced quantitative analysis. Here, we followed Sciabolazza et al. (2017) to detect research communities and Zhang et al. (2018) in using an ERGM (Lusher, Koskinen, and Robins 2013). We build on previous research on Italian sociologists Akbaritabar, Casnici, and Squazzoni (2018); Bellotti, Kronegger, and Guadalupi (2016)), and use a multi-level approach (Lazega et al. 2008). We used a sophisticated model to check interaction between different factors in our findings and that allows us to control for individual scientist attributes, along with covariate attributes, communities and network level characteristics. With this multi-level design, we analyze whether Italian sociologists tended to collaborate preferably with well-known and more prolific colleagues (preferential attachment), with colleagues of their same gender (gender homophily), and with their same affiliation country (affiliation homophily). Furthermore, we analyzed whether they were inclined to collaborate more preferably with colleagues with the same research productivity level and working on the same substantive focus. The structure of the chapter is as follows: In Section 2, we present our data and methods. In Section 3 we present our findings, while we discuss our main results in Section 4. 6.2 Data &amp; Method We gathered data from the website of the Italian Ministry of Education, Universities and Research (MIUR) for all currently hired sociologists in Italian universities and research centers. This included information about the subject’s current academic position (i.e., assistant, associate or full professor), the “scientific disciplinary sector”27 in which s/he has been formally assigned (e.g., political sociology, economic sociology etc.), gender, affiliation, department, and last and first name (Akbaritabar, Casnici, and Squazzoni 2018). We then extracted all publications by Italian sociologists (3,168 papers) from Scopus in September 201628. Data included articles’ title, keywords, abstract, publication year, authors’ names and affiliations, and number of citations received. Figure 6.1 shows the growth in number of publications in all journals over time. Figure 6.1: Distribution of the total number of publications 1973-2015 (Scopus data) The x-axis denotes the years, the y-axis denotes the number of publications For authors whose gender was missing from the website, we searched for an online profile and photo. After careful checking, only 15 cases with missing gender remained. We also aggregated each author’s country of affiliation at the continental level. We constructed a coauthorship network from articles as undirected ties with equal weights for any coauthorships, even those repeated later in the data (Newman 2001a, 2001b). This is the projection of the bipartite network of the ties between authors and papers. We used Scopus’s author identification numbers29 to treat name disambiguation (De Stefano et al. 2013). We looked at all publications of sociologists in the list, extracted from MIUR website. We collected their collaborations with scientists outside Italy or in other fields of science. However, we did not collect the full publication list for each of their collaborators. This implies that these collaborators existed in the coauthorship network only because they coauthored an article (or more) with an Italian sociologist. 6.2.1 Temporal Community Detection In order to detect coauthor communities, we used a temporal community detection (Mucha et al. 2010) as implemented in the louvain-igraph (Traag 2015) library in Python (see here for how-to-use and technical descriptions). This library allows to apply different community detection methods on network graphs as elaborated in Traag (2014). We specifically used Constant Potts model (CPM) (Traag, Van Dooren, and Nesterov 2011), which is a specific version of the more general Potts model suggested by Reichardt and Bornholdt (2004). CPM was proposed by Traag, Van Dooren, and Nesterov (2011) as a resolution-limit-free method to overcome the resolution limit in modularity (Newman and Girvan 2004) and other methods for community detection. This limit impedes the detection of small communities in large networks and affects the efficiency of the community detection. The idea of community detection principally emphasizes the importance of links “within” communities rather than those “between” them. CPM introduces a \\(\\gamma\\) parameter, i.e. the “constant” in the name, leading to communities such that the link density between the communities (external density) is lower than \\(\\gamma\\) and the link density within communities (internal density) is higher than \\(\\gamma\\) (Traag, Van Dooren, and Nesterov 2011). Note that \\(\\gamma\\) is the resolution parameter helping CPM to be a resolution-limit-free method. This allows us to detect communities with a particular density and size through the time using the parameters described in Table 6.1. We divided the cross-sectional graph of all coauthorship ties by each year between 1973 and 2017, for a total of 44 yearly graphs. Each author was included in the yearly co-authorship networks from the year of the first until the year of the last personal publication. This means that authors can appear in a the community even though they had not published in that specific year. This allowed us to consider all active authors and prevents someone being intermittently included and excluded from the network due to lack of publications in a specific year. Each node representing an author in year t was connected to itself with an inter-slice tie. Finally, the whole graph was is the aggregation of all these intra-slice ties (i.e., coauthorships occurring in any particular year) and inter-slice ties (i.e., ties connecting the same author across years). We then applied temporal community detection to this full graph (Mucha et al. 2010). Table 6.1 presents the two main parameters affecting the temporal community detection, the resolution parameter and the inter-slice weight. Varying these parameters allowed us to detect communities of different size and different stability over time. After checking, we set the resolution (i.e., \\(\\gamma\\), the density of communities in CPM) to \\(2 \\times 10^{-2}\\) and inter-slice weight to 1. Note that the inter-slice weight controls the level of dynamics between the communities, i.e., how much authors’ movement is allowed. This means that authors could leave a community and join another one in this 44 years period. This particular configuration gave us the two largest and most stable communities in the giant component over time. Table 6.1: The effect of two main parameters on temporal community detection Inter-slice Weight High Low Resolution Parameter High Smaller Communities - More stable Smaller Communities - Less stable Low Bigger Communities - More stable Bigger Communities - Less stable 6.2.2 Visualization techniques: Alluvial plots and substantive focus with term maps Alluvial plots are one of the most expressive visualization methods to represent change in large temporal networks (Rosvall and Bergstrom 2010). It uses ribbons over a bar plot of time (e.g., years) to represent the flow of information, nodes, resources and the like among different groups over time. Here, we presented communities as blocks of authors with different colors. The height of each block shows the size of the community. Whenever authors change their membership and join another coauthorship community, their color changes in the plot and they join another block which is presented with mergers and splits in the ribbons linking blocks at different years. Vice versa, following an author’s individual ribbon shows their inter-community movement. This allowed us to see the flow of authors among coauthorship communities. Ribbons connecting to the author in each year from previous years (being still present in the stacked bar) which does not follow into subsequent years would indicate inactivity in publication, i.e. due to retirement from academia, or publications in sources which are not indexed in Scopus. In order to study the substantive focus of publications, we used VOSviewer, a software tool developed by Van Eck and Waltman (2010). This allowed us to parse corpora of text, detect terms, i.e., noun-phrases, using natural language processing and obtain a term map visualization based on the VOS layout algorithm (Eck et al. 2010). The distance between terms in this map reflects co-occurrence of such terms in documents: more frequently co-occurring terms tend to appear close to each other. Additionally, this tool clusters terms together. In our case, we also considered author level characteristics (e.g., coauthorship communities’ membership, country of affiliation, first and last publication dates as proxy of academic career trajectories) to understand substantive focus of research. For example, we overlaid the coauthorship communities found by the temporal community detection method on top of the substantive term maps to see if they corresponded to research specialization. 6.2.3 Exponential Random Graph Model Finally, we used Exponential Random Graph Models (ERGMs) to simulate networks based on the giant component of Italian sociologists and their coauthors network, i.e. our observed network (Lusher, Koskinen, and Robins 2013). This provided a baseline to estimate if our coauthorship network was reflecting unique characteristics compared to what we would expect from a distribution of random networks. Furthermore, ERGMs allowed us to consider different types of attributes while modelling the probability of tie existence in the network. Node attributes included certain authors properties such as academic seniority, gender and continental region of affiliation. Covariate attributes allowed us to control and compare two nodes on the two ends of an edge for similarity or differences of attributes. This allowed us to control for homophily effects in our network (e.g., Bianchi, Casnici, and Squazzoni (2018)). Furthermore, ERGMs enabled us to check structural effects such as preferential attachment (by degree distribution), thereby considering possible Matthew effects (Merton 1968), i.e., cumulative advantage in collaborations. This mix of nodal and structural attributes in one integrated model was of paramount importance to map tie existence more effectively. 6.3 Results Figure 6.2 shows the coauthorship network of all Italian sociologists and their coauthors with affiliation of authors indicated by node colors. Ties are colored based on being within or between the affiliation groups. we found that Italian sociologists (1,641 out of 2,747 total) are mostly connected by intermediation of coauthors affiliated elsewhere (see gray nodes on Figure 6.2; see below for detail on this). Table 6.2 shows the main features of this network. The sparse coauthorship relations (Average degree = 5.5) with relatively high number of connected components (512) indicate the level of disconnectedness of the network. The connected components greatly vary in size: the largest connected component had 712 members, while the second largest component had 184 members (Mean = 5.37, SD = 32.72). The large number of small connected components indicate there are quite some authors who published either alone, or with few coauthors, in isolation from the rest of the authors. As indicated in Table 6.2 (Rows indicated by (G-comp)), the giant component only contains 26% of the nodes in the full network, with 29% of the ties. This is a relatively low percentage compared to random networks simulated with similar degree distribution as observed one (i.e. scale-free, preferential attachemnt and random networks). The average degree of the giant component was relatively low (6.24, SD = 6.61), and only slightly higher than the average degree of the full network (5.55, SD = 6.74). Table 6.2: The main characteristics of the coauthorship network of Italian sociologists and their collaborators and its giant component Metric Value Number of nodes 2747 Number of ties 7618 Mean degree 5.55 Number of communities 512 Community size (mean) 5.37 Community size (SD) 32.72 Number of nodes (G-comp) 712 Number of ties (G-comp) 2221 % nodes in (G-comp) 25.92 % ties in (G-comp) 29.15 Number of female authors (G-comp) 314 Number of male authors (G-comp) 383 Density (G-comp) 0.0088 Diameter (G-comp) 32 Figure 6.2: The coauthorship network of all Italian sociologists and their coauthors (Colors: Affiliated to Italy = Red, Affiliated elsewhere = Gray, Ties within Italians = Blue, Other ties = Gray, Node size = Betweenness centrality) (Scopus data) Figure 6.3 provides a different visualization of the coauthorship network and shows the temporal evolution of the authors. Following Palla, Barabási, and Vicsek (2007), who suggested to use this type of visualization to examine the movement of individuals between communities, we distinguished four groups of authors: 1) Those who published at least two years before a given year and continued to publish for at least two years later (old members/staying, see lightest color, bottom stack of bars in plot), 2) Those who published at least two years before a given year with the last publication in the given year (old members/leaving, see darker color than first group, second stack of bars from bottom in plot), 3) Those who first published in the given year, and published for at least two more years (new members/staying, darker than the two first groups, third stack of bars from bottom in plot), and 4) Those who first published in the given year and did not publish from then (new members/leaving, darkest colors, fourth stack of bars on plot). Note that most authors in the sample were newcomers who immediately left and disappeared from Scopus the following year (darkest stack of bars in Fig 6.3). However, some newcomers joined the core of more senior authors of the sample (second stack of bars from the top). Figure 6.3: The temporal evolution of all authors in sample the x-axis denotes the years, the y-axis denotes the individual authors (Scopus data) Figure 6.4 shows the two communities detected from the giant component, with a total of 712 authors. We found many isolated authors (244 in the whole network, see Figure 6.2 for a visualization of full graph) or connected components (total of 512) formed between Italian sociologists working with their own group of contacts. Figure 6.4 shows that there was only one tie between the two communities detected in the giant component (in the center of graph, where circles meet squares). Figure 6.4: The giant component of Italian sociologists and their coauthors network with two communities (Node colors: Males = blue, Females = red, Tie colors: Within Italians = green, Within non-Italians = purple, Between Italians and non-Italians = gray, Node shapes: Square = Community 0 (left side of graph), Circle = Community 1 (right side of graph), Node size = Betweenness centrality) (Scopus data) Figure 6.5 shows the temporal evolution of the members of the two communities detected in the giant component. Unlike the case of the whole network, in which there was systematic turnover of newcomers (see height of darkest color stacked bars relative to height of lightest color bars on Figure 6.3), these two communities have a much more stable core (see height of the bar of the lightest color compared to the height of the bar of the darkest color), which does not change while including new members (see third stack of bars on plot). Certain members of the giant component disappeared from the sample because there were no other publications of them indexed in Scopus (see fourth stack of bars, newcomers who left and old members who left, second stack of bars on plot from bottom). Figure 6.5: The temporal evolution of communities of the giant component. The x-axis denotes the years, the y-axis denotes the count of individual authors (Scopus data) Figure 6.6 shows that community 0 (darker color on top part of plot on the left) is the bigger community of the giant component with 454 members, while community 1 (lighter color on the bottom of plot on the left) is the second community in size, including 258 members. The right panel of Figure 6.6 shows the gender distribution in these two detected communities (see details on overall percentages below in Table 6.3). This Figure presents further detail on the temporal activity of authors within each of the communities detected from the giant component and should be compared to Figure 6.5. Consider the share of newcomers who leave in each year, i.e., those on the stack of bars without a ribbon connecting to them from previous years and without a ribbon going out of them to next years, which are ordered and positioned on the top parts of the bars within each community. The majority of people in a community in 2015 and later years are leaving newcomers. In both communities the share of male authors was higher among the staying members , whereas females were more present among the newcomers leaving (For a gender based comparison, see the ribbons connecting authors in each group of stacked bars on right panel of Figure 6.6 or Figure 6.11 in the Appendix section). Figure 6.6: Communities 0 and 1 found with Temporal Community detection (left) and gender composition (right) the x-axis denotes the years, the y-axis denotes the individual authors, each author is connected to him/herself with a ribbon over the years) (Scopus data) Table 6.3 shows the share of these two communities considering author attributes (i.e. gender and country of affiliation). It is worth noting that we did not find any significant gender differences in the two communities, at least in terms of overall share of members (see the plot on the right panel of Figure 6.6). However, as described above, we found gender differences in the share of newcomers leaving and old members staying (For a gender based comparison, see Figure 6.11 in the Appendix). Regarding the country of affiliation, we found that community 0 was composed of sociologists working in Italy while community 1 had a higher share of international authors, from either Europe or other countries. Table 6.3: Gender composition and internationality of members of the two communities detected from the giant component (Percentages are calculated by rows separately for gender and country) Community Female Male Missing gender Europe Italy Other Missing country 0 45% 54% 2% 37% 53% 6% 5% 1 43% 54% 3% 53% 30% 11% 5% Table 6.4 shows the percentage of ties within and between the two communities. We found the lowest possible ties among the two communities (0.05% equal to one tie out of 2,221 total) and the highest ties within each community. To understand the possible underlying mechanisms of community membership in more detail, we considered other author attributes. Table 6.5 shows the percentage of ties within and between authors of different gender. The highest percentage of ties between authors of the giant component (43.18%) were cross-gender collaborations, while 33.72% of all ties formed in the giant component were within male authors. In line with previous findings, female-to-female coauthorship ties were rarer (e.g., Teele and Thelen (2017)). However, it is worth noting that the total number of females (44.1%) were lower than male authors (53.79%). This means that these findings could be due to the lower number of potential female collaborators to choose among. Table 6.6 shows the percentage of ties within and between two specific groups of authors: 1) Those who were currently hired Italian sociologists and 2) those who could be affiliated either in an Italian institution or abroad, either sociologist or not, either active or retired, but in any case, not included in the administrative list. Note that the highest percentage of ties (46.2%) were within those not currently employed in an Italian institution. Only 25.35% of ties were within Italian sociologists. Table 6.4: The percentage of ties within and between the two communities detected from the giant component Within community 0 Within community 1 Between communities 0 and 1 46.15 53.8 0.05 Table 6.5: The percentage of ties between male and female authors in the giant component Within males Within females Between males and females 33.72 18.87 43.18 Table 6.6: The percentage of ties between Italian scientists who were member of our administrative list and other scientists not-in-our-list in the giant component Within Italians Within non-Italians Between Italians and non-Italians 25.35 28.46 46.2 Table 6.7 shows the most popular and prolific authors in the giant component and their gender. Confirming previous findings (Abramo, D’Angelo, and Caprasecca 2009b; Cole and Zuckerman 1984; Leahey 2006), male authors dominate the picture, being the most prolific and having the highest betweenness, triangle counts and degree. Table 6.7: Comparing ranking of top 10 authors last name and gender in some of the main network characteristics Betweenness Most Prolific Triangles Degree Bosi (Male) Fortunati (Female) D’Ambrosi (Female) Fortunati (Female) Mattoni (Female) Pavolini (Male) Splendore (Male) Neresini (Male) Della Porta (Female) Diani (Male) Harro-Loit (Female) D’Ambrosi (Female) Pavolini (Male) Boccagni (Male) Eberwein (Male) Splendore (Male) Treré (Male) Bucchi (Male) Groenhart (Male) Harro-Loit (Female) Farinosi (Female) Brighenti (Male) Porlezza (Male) Diani (Male) Boccagni (Male) Ambrosini (Male) Fengler (Female) Eberwein (Male) Giugni (Male) Ballarino (Male) Alsius (Male) Groenhart (Male) Pilati (Female) Ruzza (Male) Baisnée (Male) Porlezza (Male) Diani (Male) Mazzoleni (Male) Bichler (Male) Pavolini (Male) 6.3.1 Substantive focus of research In order to understand the border between the two communities of the giant component better, we considered the type of research. We developed term maps based on titles, keywords and abstracts of all papers included in the sample. By overlaying the community membership (i.e. communities 0 and 1 of the giant component) on top of the substantive term maps, we tested the hypothesis that membership in communities was based on similarity in research focus between members. As shown in Figures 6.7, 6.8 and 6.9 (see the focus of research of each group on the yellow part of the term map), community 0 mainly consisted of economic sociologists doing research, for instance, on labour market, employment, migration, and inequality, while community 1 mainly consisted of political sociologists studying public opinion, Internet, news, journalist, and elections, to name a few topics. Figure 6.9 shows the substantive focus of all other authors who were not a member of the giant component. While their focus was clearly different from communities 0 and 1, they obviously do not overlap because they focus on different topics. Figure 6.7: The substantive focus of members of community 0 of coauthorship network overlaid on terms extracted from all publications visualized with VOS viewer (Yellow parts on plot show the highest substantive focus e.g., higher frequency of those terms in the corpus) Figure 6.8: The substantive focus of members of community 1 of coauthorship network overlaid on terms extracted from all publications visualized with VOS viewer (Yellow parts on plot show the highest substantive focus e.g., higher frequency of those terms in the corpus) Figure 6.9: The substantive focus of those not member of the giant component of coauthorship network overlaid on terms extracted from all publications visualized with VOS viewer (Yellow parts on plot show the highest substantive focus e.g., higher frequency of those terms in the corpus) In order to examine mechanisms that can explain these patterns, we built four ERGMs, including structural and individual factors. Table ?? shows results of the four ERGMs. Model 1 included only structural effects (i.e. ties and preferential attachment). It shows that there was a strong effect of preferential attachment in coauthorship ties existence. This indicates that authors who were already famous scholars with higher number of collaborations were the ones with higher probability of forming coauthorship ties. Note, given that the coauthorship network is a one-mode projection of bipartite ties, i.e. paper-author ties, higher rates of cliquish structures can be simply due to articles with high number of authors, as this typically generates a maximal clique. This can determine a high preferential attachment effect. To control for this, we included temporal community detection membership by considering cross-sectional networks of coauthorship yearly. This is expected to reduce the artificial importance of cliquish structures because the communities are detected over all years not a single year. Consider that unlike in the hard sciences, multiple coauthorship ties in the same year are rare among sociologists. Note also that this yearly view on the whole network helped us to reduce the effect caused by bipartite to one-mode projection. Furthermore, we added other author attributes to see if the preferential attachment effect will hold. Model 2 included only author attributes (e.g., gender, continental region of affiliation, similarity in first and last publication dates which would indicate seniority and experience and the total number of publications). ERGMs model the probabilty of tie existence, since our community detection configuration is rewarding ties within a community than between two communities, therefore naturally membership in those communities would have an endogeneity effect leading to high effect of community membership on tie existense in ERGM. Thus, in Model 2 we have excluded temporal community membership which is added in Model 3. The main effects between the two models stayed the same with Model 3 having better BIC and AIC. We found that being member of one of the two temporal communities (i.e., having substantive research focus similar to economic or political sociologists) had the highest effect in increasing the tie existence probability. Tie existence was also influenced in descendent order of probability by working in other countries (e.g., North America, Australia and New Zealand, South America and Asia), European countries, institutions in Italy, having close or similar date of latest publication (e.g., publishing until recently)30 , being male, having close or similar date of earliest publication or having different number of total publications31. Being female did not have any significant effect on tie existence. Finally, Model 4 shows the mix of effects in Models 1, 2 and 3. We found that including author attributes and temporal community detection significantly decreased the structural effect of preferential attachment on tie existence (from a coefficient equal to 15.095 in Model 1 down to 4.063 in Model 332). Effect of other variables had the same order and quite similar rates as in Model 2 and 3. To sum up, the results show that having a similar substantive research focus and working in specific countries had an effect on the way Italian sociologists collaborated and their international exposure. Secondly, we found that the general rule of the “rich gets richer” was highly affected by the interplay between these variables. Note that the mixture of node attributes and community level effects model specification in Model 4 was a better fit than Models 1, 2 and 3 (see AIC and BIC measures in the last rows of the table, the smaller, the better). ERGMs results explaining effect of author attributes and structural variables on coauthorship tie existence The Giant component of Italian sociologists and their coauthors ERGM Models (1) (2) (3) (4) Ties -4.549*** (0.022) -4.354*** (0.050) -11.348*** (0.997) -11.254*** (1.012) Preferential attachment 15.095*** (4.421) 4.063*** (0.976) Homophily Females 0.002 (0.059) 0.049 (0.060) 0.067 (0.060) Homophily Males 0.281*** (0.049) 0.267*** (0.049) 0.258*** (0.054) Community 0 7.207*** (0.996) 7.136*** (1.015) Community 1 8.318*** (0.996) 8.216*** (1.015) Europe 1.226*** (0.051) 1.099*** (0.053) 1.113*** (0.059) Italy 0.600*** (0.057) 0.718*** (0.059) 0.716*** (0.067) Other countries 1.546*** (0.170) 1.188*** (0.177) 1.170*** (0.216) Homophily Total Pubs 0.060*** (0.002) 0.063*** (0.002) 0.063*** (0.003) Homophily First Pub -0.092*** (0.006) -0.095*** (0.006) -0.095*** (0.007) Homophily Last Pub -0.372*** (0.014) -0.367*** (0.014) -0.369*** (0.016) Akaike Inf. Crit. 25,237.220 22,732.670 19,277.840 19,154.370 Bayesian Inf. Crit. 25,268.540 22,826.640 19,392.700 19,290.110 Note: p&lt;0.1; p&lt;0.05; p&lt;0.01 6.4 Conclusions and discussion Our study provided an empirical overview of collaboration within and between sociologists in Italy and their collaborators worldwide. We constructed a coauthorship network based on the publications indexed in Scopus and used temporal community detection to detect the two largest and most stable communities of the giant component. Although the communities are gender balanced, male newcomers are more likely to continue in academia than females. The communities differ in their research focus and international exposure. We ran ERGMs to control the effect of certain author attributes (i.e. gender, country of affiliation and scientific career), local structural configurations and community memberships (i.e. substantive focus) on coauthorship tie. In general, we found that Italian sociology is a collection of isolated islands. The coauthorship pattern was mainly driven by preferential attachment and research focus. When we considered other author attributes, the preferential attachment effect was reduced. Our findings showed that adopting a multi-level approach while considering temporal dimensions in the study of scientific collaboration is key to reveal the interplay between factors of different levels (e.g., individual, community, covariate attributes and network structure levels). Our results revealed two communities of sociologists that are relatively well connected among each other. First, we found a community of economic sociologists studying labour market, employment, migration, and inequality. The second community included political sociologists studying public opinion, Internet, news, journalist, and elections. These two communities form the giant component of the coauthorship network of sociologists in Italy. We also found many (511) other connected components of authors publishing either alone or with few authors (Babchuk, Keith, and Peters 1999). The community of political sociologists is more international than the community of economic sociologists. Both communities have been growing in size in recent years. It seems our results are more in line with first hypothesis of Moody (2004)’s study (a small world of distant communities) since we found many distant communities and in case of the two main communities in the giant component they had specific research focuses with lowest possible ties with the other community. Whether these communities are influenced by the scientific disciplinary sectors or by the specific department environments in which scientists are embedded could be subject of further inquiry. This would also require a more extensive sample coverage. Indeed, despite the fact that Scopus has the highest coverage among bibliographic data sources (especially in Italian language as shown in Mongeon and Paul-Hus (2016)), Italian sociologists publish many articles, book chapters and monographs that are not indexed in Scopus. Previous research showed that only 63.81% of Italian sociologists have at least one publication record indexed in Scopus and it could be due to lower coverage of Italian language or local publication outlets (Akbaritabar, Casnici, and Squazzoni 2018). This could have limited the completeness of the coauthorship networks. Further research using sources such as Google Scholar, which covers more Italian publishers, could help to complete this type of analysis. Secondly, our analysis did not provide a robust explanation of the underlying mechanisms that account for these observed patterns. For instance, strategic decisions about collaboration could be constrained by certain factors, such as joint collaboration in research proposals, PhD programs, and scientific associations or academic mobility across institutions, which we did not consider here. Furthermore, collaboration could be inhibited by the institutional separation between different disciplines in Italy, which have a strong influence on grants, hiring and promotions. Finally, coauthorship patterns could also reflect the capacity of certain scientists to build international ties. Not only do international collaborations increase recognition and prestige of the most productive scientists; they in turn tend to stimulate network expansion leading to self-reinforcing processes (Leydesdorff, Park, and Wagner 2014). 6.5 Appendix Figure 6.10 presents the goodness of fit analysis for our ERGM model (It is only shown for the most extended one, Model 4 in Table ??). It considers the model specification and estimates to what extent our model was able to detect the observed network’s behavior. Considering that in order to control for preferential attachment our attention was on the degree distribution, the first panel in top left side of Figure 6.10 indicates that our model predicted considerably well our observed network. However, it must be said that in other goodness of fit measures, which are based on edgewise shared partners (that we didn’t include in the model do to degeneracy issue) on top right, and the minimum geodesic distance (on which normally most ERGMs are not good) left bottom, our model did relatively bad. On the Goodness of fit evaluation based on covarriates (bottom right of Figure 6.10) our model did well. Figure 6.10: Goodness of fit analysis of ERGM results (black solid line represents the observed network) Figure 6.11 presents an elaborated version of Figure 6.5 and adds details on the temporal movement differences of gender in the communities detected in the giant component. Figure 6.11: Temporal evolution of communities of the giant component, comparison among different gender the x-axis denotes the years, the y-axis denotes the individual authors) (Scopus data) References "],
["finalconclusionschapter.html", "Chapter 7 Discussion and conclusions", " Chapter 7 Discussion and conclusions This dissertation aimed to provide a quantitative look at academic work in 21st century. We tried to investigate this multi-faceted phenomenon from different points of view. Although considering different datasets and contexts, our research design included different observational units from individual, meso (community), macro to multi-level ones. Our ambition was to shed light on individual efforts of scientists at publishing their research results (Chapter 3). On the one hand, we considered bottom-up efforts of academics while trying to compete and survive in a hyper-competitive context. We tried to consider the nested structure and organizational embeddedness in our hierarchical linear models while we kept in mind that being embedded in different institutional context could have a crossed membership nature meaning sociologists working in similar departments in different universities be exposed to similar unwritten rules while being affiliated to similar university might bring about similar constraints, facilities or limitations to sociologists in different departments (e.g., those working in economics department compared to the ones in medical sciences departments). Afterwards, we looked at the top-down processes, with a particular interest on certain national policies and their capacity (or failure) in inspiring higher research productivity (Chapter 4). Here, we did not want to limit the scope of our research only to individual or macro levels as research collaboration is a social process (Garvey 1979; Zhang et al. 2018). At the individual level, we found that academics working more internationally and with a specific group of collaborators had higher productivity, whereas at the macro level, we found that higher productivity was not solely inspired by macro-level policy changes. Cultural changes in academia cannot occur overnight or simply reflect policy initiatives (Melin 2000). When considering macro aspects, we found that certain ambiguities in the reward system of academia (Merton 1968; Boffo and Moscati 1998) can generate confusion for individual researchers, depending on their visions, interests and goals. For instance, if policy signals are not univocally addressed to stimulate high quality research and reward systems are not directly linked to assessment, it is reasonable to expect a variety of responses by scientists. This lack of coherence between performance evaluation and promotion and career advancement (Abramo, D’Angelo, and Rosati 2014) has led certain observers even to question whether the Italian academic system is prepared to reward any performance based scheme (Bertocchi et al. 2015). Here, the fact that there is no unified and standard evaluation procedure for assessment and promotion creates ambiguities (e.g., case of national habilitation reports in Marzolla (2016)). We used crossed membership random effects structure which enabled studying organizational context along with other fixed effects while ruling out individual subjects’ random noise (see Baayen, Davidson, and Bates (2008) for a discussion), but we need to emphasize again that there are other methodological possibilities to study effect of policy changes in scientist’s behavior, specifically Dif in Dif and Regression Discontinuity Design (e.g. see Seeber et al. (2017) for an example) which we haven’t used here. Those analytical strategies might help give more insights into policy effects. Furthermore, we looked at the diversity of the sociological community. We wanted to see if considering embeddedness of academics in different hierarchies (Granovetter 1985) would help us understand scientist’s performance. In Chapter 5, we discussed certain unwritten rules characterizing the academic system that can explain the different success of academics. For instance, graduating or working in Ivy-league institutions can have different effect depending on different groups of authors, e.g., male versus female academics. Here, our findings would support feminist narratives (e.g., Teele and Thelen (2017); Maliniak, Powers, and Walter (2013); González-Álvarez and Cervera-Crespo (2017)), which suggested that the current winner takes all academic system (Frank and Cook 2010) penalizes females by offering them less attractive and more unstable careers (Lomperis 1990; Hancock and Baum 2010). Furthermore, there is a structural process leading females to prefer specific fields of science (non-STEM), acquire specific skills and qualifications (non-quantitative) and perform more qualitative research (Kretschmer et al. 2012), which is less appreciated by prestigious journals. Recent research suggests that females are treated unfairly in peer review (Hengel and others 2017) and even when published their research is less valued (Krawczyk and Smyk 2016) and cited (Maliniak, Powers, and Walter 2013; Beaudry and Larivière 2016). It is worth noting here that this type of studies, including ours, cannot draw clear causal effects. We cannot evaluate to what extent these causal mechanisms were at work and which ones. In our case, we only observed that these distortions, probably due to structural effects, were detectable also in our sociological community. For instance, while we found gender differences in the substantive research focus between sociologists, it is difficult to trace these differences back to single causal mechanisms more in depth analysis is required to disentangle the processes underlying these complex outcomes. In Chapter 6, we explored research groups’ formation and evolution. We aimed to investigate the temporal dimension of scientific activities by using a rather sophisticated temporal community detection configuration (Mucha et al. 2010). We found that individual researchers join certain research communities and stay or leave these communities over time. We found that this process affected the existence of coauthorship ties (i.e., number of publications). Our aim was to present the usefulness of multi-level approach in looking at coauthorship evolution. Note that reducing scientific collaboration to a cross-sectional image by removing temporal changes would lead to neglect important factors. Accordingly, we concluded that the cross-sectional view would be reductionist and any study on research activity should seriously consider these diverse dimensions. While we are aware of more advanced multi-level network models that model ties formation and existence between individual (micro), community (meso) and organizations (macro) entities and our approach has limitations compared to these more advanced views. The dynamics of citation and the heavy reliance of academic reward system over citing previous work is one of the aspects of academic work that we haven’t studied sufficiently. Explanation models taking into account complex factors from seniority of researcher and article’s age, research potential and subjective rigor to connections and embeddedness in coauthorship, departmental and affiliation networks can drive what has been named as citation cartels (Fister Jr, Fister, and Perc 2016), we did not build models like this and we did not take citation networks into account. This is a rather large limitation since there are not many studies on sociologists focusing on citations. There are extensive studies on CV data and fine-grained analysis of academic pedigree that is rarely focused on sociological community (with the most recent exception being Warren (2019)’s study). We gathered background information on international community of sociologists but it has a higher potential for further analysis than what we presented in Chapter 5. In Chapter 5 and Chapter 6, we examined research focus and content of sociological articles. Indeed, scientific collaboration is as much substantially oriented as it is socially constructed. Scientists choose their collaborators not merely on social, substantive or scientific ground but probably due to a mixture of all these factors. Here, we are at the beginning of a line of research that requires further advancements to draw any comprehensive conclusions. Among these steps, more robust and detailed analysis on the quantitative and qualitative divide in sociology and certain gendered attitudes would be important. At the end of each chapter, we discussed certain limitations that penalized our work. Here, we want to emphasize that even the mere process of tie formation (either friendship, scientific collaboration or coauthorship) is a complex process whose study requires mixed methods research designs. This also includes qualitative understanding of trajectories and experiences. For instance, this is the type of study that Small (2017) did on early career researchers and postgraduate students, in which he focused on how they coped with hardships of their academic life. This type of mixed methods research would better represent the process of individual decision-making by revealing certain motivations behind scientists’ collaboration, which here were left on the background. We only briefly discussed the fact that academics face dualities in their everyday work such as contributing to the community by accepting peer review tasks that is not directly reflected in academic reward system versus being focused on one’s research and publication activity. There are new developments i.e. Publons (see Sammour (2016) for a description) which gives promise of tracing voluntary scholarly activity that might enable future researchers to look into bibliometric information on scientists publication and their Publons records on peer review activities to see how scientists are coping with the above mentioned duality. This type of new data might enable researchers and evaluators to refrain from being criticized on the prevalence of quantitative view in research evaluation and promise a more fine-grained quantitative and qualitative mixture in research assessment. Furthermore, this might help going some steps closer toward the ideal image of giving voice to those under evaluation (i.e. researchers) to take part and help in their own evaluation (see Cole and Zuckerman (1987) for a classic example of mixing demographic, bibliometric and interview data in research productivity measurement). In our work, we could not reconstruct why and how scientists decided to collaborate with one another. We merely observed the outcome of these collaborations, i.e., the digital traces left by publications. We could neither reconstruct collaboration failures nor explore potential pool and the role of redundancy (e.g., gap in potential offer between academics of different institutes). We believe that a deeper look into these factors that revolve around collaboration is a necessary step towards a serious study of the social dimension of science. References "],
["appendiceschapter.html", "Chapter 8 Apendices 8.1 R and Python scripts 8.2 Timeline of PhD, research visits, schools and presentations 8.3 Annotated bibliography on social aspect of science", " Chapter 8 Apendices 8.1 R and Python scripts All R and Python scripts written during this research project is maintained and updated as a Git repository which is hosted on Gitlab. This repository is a bookdown project which includes text of chapters, data, analysis scripts and report scripts of figures and plots. It is fully reproducible and to request access to code and data to replicate the results, one can contact the author at: https://akbaritabar.netlify.com/ 8.2 Timeline of PhD, research visits, schools and presentations Figure 8.1 shows the timeline of this PhD project including short spring and summer schools, research visits, presentations in conferences and publication dates (designated by lines below x axis). Figure 8.1: Timeline of PhD research project between November 2015 and September 2018 8.3 Annotated bibliography on social aspect of science Articles, books, book chapters and online resources we have reviewed (either cited in previous chapters or not) are presented here under specific subjects related to academic work. Author(s) name and year of publication (APA style) is written in Bold in the beginning of each annotation. Parts of the articles we have directly quoted in this annotated bibliography are presented with indentation of paragraphs. 8.3.1 Gender There are three streams of literature on the issue of lower productivity of females compared to males in science, which is coined as productivity puzzle (Cole and Zuckerman 1984). See also Abramo, D’Angelo, and Caprasecca (2009b)’s note in their review: Literature suggesting smaller number of females entering the field (so a self-selection bias like in Sheltzer and Smith (2014) and Hancock and Baum (2010)) Literature with a feminist tendency suggesting unequal opportunity and sexual discrimination (like case of political sciences in Teele and Thelen (2017)) Literature with a focus on productivity measurement and explanation mentioning that females perform less than males (based on bibliometric evidences, e.g., case of Italy in Abramo, D’Angelo, and Caprasecca (2009b)) Teele and Thelen (2017) They look at the publications in 10 prominent political science journals, searching for gender bias and under-representation of females in the pages of these journals. They differentiate between team of authors in paper level analysis, based on gender to all-male, all-female teams, solo male and female authors and cross collaborations. They were not the first in literature to do this gender composition differentiation, there were studies doing so before e.g., Young (1995), Maliniak, Powers, and Walter (2013). They controlled for share of females in the profession (by APSA association membership) and they observed that the low percentage of female authors (in published papers) does not follow the trend in APSA members. Coauthorships were more happening among all male teams and when they controlled for research methods, these journals had a tendency to publish more quantitative work rather than qualitative. They claim that is the type of research females are more likely to do (which this tendency has been discussed as a probable self-selection bias or an unconscious structural effect leading females to first take qualitative educational fields and then end up doing this type of research and then lead to have a leakier academic career pipeline (Hancock and Baum 2010)). Kretschmer et al. (2012) Authors in this article have tried to test the general notion stating gender bias in science is related to the subject of research. They have studied some of the main gender studies journals to see whether female authors were still under-represented in these journals. They found a strikingly high share of female authors which was not comparable to other journals (e.g., PNAS). Maliniak, Powers, and Walter (2013) They claim that after studying journals in political science, while controlling for other variables, articles written by female authors received less citations than articles by males. They have done a network analysis and found that female authors’ articles were less central in the network of papers citing each other, as a proxy of papers interaction through impact. Male authors tended to cite male authors more, female authors tended to cite female authors less. This is a cause for concern, If women in IR are systematically cited less than men in ways that do not appear to be associated with observable differences in their scholarship, and if citation counts continue to be used as a key measure of research impact, then women will be disadvantaged in tenure, promotion, and salary decisions. Young (1995) She started her narrative by figures of increase in number of females in classrooms in different levels of universities. After she discussed how and where females were publishing their papers in political sciences. Interestingly she looked at these elements in paper level analysis: How frequently females publish? How frequently they are single, lead and secondary authors? Are percentages consistent across journals and over time? Length of text and topics of articles by females are compared to those by male authors. It is also used as a potential explanation of the differences in trends of publishing, as working on different subjects. Order of names of authors is studied further in each paper controlling whether it is in or out of alphabetical order. Membership in national association implies commitment to the profession. The sad conclusion is, because women publish less frequently and because men are unlikely to cite female-authored articles, few women are perceived to be top researchers in the field (Klingemann, groffman, and campagna 1989). Xie and Shauman (1998) They reviewed the literature on differences of research productivity between male and female scientists and the puzzle of lower productivity of females. Their answer to this puzzle and if they were able to solve it, is both yes and no. They have found that females scientists are publishing less because of personal characteristics, structural positions and facilitating resources that are conductive to publication. Beside that, they claim that there is a second puzzle. Puzzle of different career trajectories between males and females in science. Structural resources favor females less. Overall sex differences in research productivity is declined in recent years (until their publication in 1998). In their regression results, they have a variable as type of current institution which has high quality university to low quality four-year college. This seemed to control for ivy-league effect of institutions. Prpić (2002) Participation of females in the labor force and academic labor in Eastern Europe has been higher than Northern America or Western European countries and more equal to males. She mentions that accessibility of scientific career for females in USA has been 22% in 1995. But regardless of higher accessibility, female scientists in East European countries had marginal professional positions. Female researchers achieve academic degrees and high(est) academic ranks more rarely and slowly, which makes their qualification structure poorer than the corresponding structure of male scientists Female scientists fall behind their male counterparts in other kinds of collegial recognition, as well: employment at prominent universities and other scientific institutions, prestigious scholarships, permanent tenure, scientific awards Women hold relatively few positions of influence in scientific institutions: they even hold few supervisory positions in organization units, not to mention running an entire scientific institution Exceedingly few female scientists participate in the scientific power structure. This refers equally to their participation in prestigious and influential bodies of national academies, scientific societies, and in advisory and/or editorial boards of scientific journals, i.e., in the bodies that channel scientific development, and in high-level societal and political bodies that design scientific and technological policy Women are paid less in science (often for the same job) than their male counterparts Gender differences in productivity are therefore far from constant and stable. They are sensitive to the time frame, so research should include their trends of development. Interestingly (page 35), she cites literature that female scientists generally come from higher socio-economic statuses compared to their male counterparts. Since it is harder for them to get into scientific careers than males, so they belong to higher status families and they have different images of scientific career in mind when they start it. She concludes that although increased productivity of young Croatian scientists is due to the fact that overall number of publications of both male and female scientists increased in the newer generation, but, she finds that the rate and speed of increase in publications in males are higher than females. Males are more ready to adopt to changing system of academia with higher competition: Men more readily accepted the new standards of scientific production introduced by changes in the system of evaluating scientific work. The theoretic implication of this is that gender differentiation in productivity is not only reflected in the number of publications, but as the different adjustment of scientific performance to new conditions. In conclusions she emphasizes the results of psychological research: Psychological research to date indirectly indicates that the smaller productivity of women scientists is socially generated, because no significant differences were found in the intellectual abilities of women and men who enter science, or stay in it. Gender differences in scientific productivity may potentially also arise from insufficiently investigated and identified psychological characteristics – such as personality, motivation, values and interests of male and female scientists – but these seem to be impregnated with cultural and social influences too. Preston (1994) Investigates why females tend to leave a scientific career twice more their male counterparts. They mention striking historical numbers from females employment in science: In 1982, women represented 22 percent of employed natural scientists, 29 percent of employed social scientists, and 3 percent of employed engineers (NSF Resource Series 87-322) (cite: Survey of doctoral recipients. Surveys of Science Resource Series, Washington, DC: National Science Foundation, 1977- 1986) The conventional explanation that females exit academic (scientific) labor force due to maternity and childbearing responsibilities is incomplete, and they find out that this exit happens more often in early stages of career. Stack (2004) This is one of the rare studies that have looked at academics’ children ages and their research productivity to see if having a child (with different ages) can lower the productivity. They have then looked at gender differences for more than 11 thousand PhD recipients hired in academic jobs. Research on gender and scholarly productivity, the productivity puzzle, has neglected analysis of the influence of children on scientists’ research productivity (e.g., Blackburn and Lawrence, 1995; Keith, 2002; Stack, 1994a, 2002a; Xie and Schuman, 1998, 2003) They cite two previous studies who have looked at the same subject with data on children and research productivity (in conclusion section): This finding was consistent with those of two studies from a quarter century ago. Hargens et al. (1978), in a study of 96, married PhD Chemists, found that gender influenced productivity independent of children. Hamovitch and Morgenstern (1977) found similar results, but included PhDs who were not in the paid labor force. Such persons tend not to have the same level of motivation and do not receive rewards publishing as do employed academics. They found that young children are associated with higher productivity (after controlling covariates of productivity). They mention some limitations (at the end of conclusion), such as flexibility of academic jobs. Leahey (2006) Females specialize less in their research activity and this causes (in interaction with gender) for them to have lower research productivity. She claims that during this long history of research on research productivity, specialization has been under-studied and neglected and her study is one of the first to look at its effect. Based on what she found, having a specialized research program and writing papers in the same specialty area repeatedly promotes productivity. In conclusions: Men’s and women’s different professional networks and collaboration strategies may also be relevant. Men’s wider and more diverse professional networks (Burt 1998; Kanter 1977) may allow them to find collaborators whose interests overlap their own, allowing their research collaborations to reinforce their expertise in one or a few specialty areas, whereas women’s smaller and more homogeneous professional networks (Grant and Ward 1991; Renzulli, Aldrich, and Moody 2000) require them to branch out to other substantive areas if they want to collaborate, resulting in more diversified research programs. I found the processes by which specialization mediates gender differences in productivity to be roughly the same in two fields typically neglected by the sociology of science: sociology and linguistics (Guetzkow, Lamont, and Mallard 2004). However, gender effects were more pronounced in sociology - a field with many ill-defined core areas (Dogan and Pahre 1989) - than in linguistics Abramo, D’Angelo, and Caprasecca (2009b) They studied gender differences mentioned in literature in Italian academic system and they found that females have lower research productivity. They claim that their study although not focused on the causes of lower productivity of females, have some uniqueness, because it has been done on entire Italian universities on approximately 33,000 scientists. They have classified them based on academic level and scientific field of specialization. Grant and Ward (1991) They review sociological publications in three phases, pre-publication, the publication seeking phase and post-publication (citations and notification of works). They conclude that there is little information about how gender politics affect females’ rates of publications and career prospects. They present statistics on the number of females in editorial boards, fundings and coauthorships in sociology journals. Lomperis (1990) She first presents figures of how females has entered the labor force and male dominated jobs like law, medicine and university teaching. Then she cites literature on how scholars have looked at this tremendous change of century and how it can change the nature of academic profession. At the same time she cites a work that females are hired for lower positions: Dr. Benjamin drew on the accumulated data from the AAUP’s annual academic salary surveys and observed that the increased participation of women was “disproportionately in the lower ranks and shows scant evidence of progression through the ranks.” She asks: Are women taking over the professions? If so, how? If not, could at least the nature of the professions be changing by virtue of the increasing presence of women in them? The purpose of this article is to address these questions by focusing on one such profession - college and university teaching. On the notion of “Academic labor market or markets” she mentions: The reference to academic labor markets in the plural here is deliberate. For as Michael McPherson [21, p. 57] has observed “Ph.D.s are highly specialized personnel. Employment conditions differ very widely among disciplines and even among sub-disciplines.” In answering her question on “have females changed the nature of the academic profession?”, she claims on the supply side the change has clearly happened. But on the academic ranks and positions which females have occupied, it has happened mostly been on the places were traditionally males were avoiding, such as lower ranked, lower paid positions with not much future prospects. She concludes by mentioning the increasing hardship of following an academic job for both males and females. An advice by academics to young generation; answering survey questions: “don’t do it, this is not a good time”. But she also mentions that increase in females presence in academic positions differs by fields of science. It is higher in humanities and social sciences compared to hard sciences. Krawczyk and Smyk (2016) In this study we sought to verify the hypothesis that researcher’s gender affects evaluation of his or her work, especially in a field where women only represent a minority. They found that gender of author matters for evaluation of a paper, but seemingly not their age. Beside that, they found that this discrimination is not intentional and can be unconscious: The fraction of guesses that a male-authored paper had been published was 30.6% (14 pct. points) higher than for female-authored ones. If anything, this effect was stronger in female than male subjects. This would represent a clear case of statistical discrimination, in line with the claim of Moss-Racusin et al. (2012) that lack of evidence of (male) in-group favouritism “suggests that the bias is likely unintentional, generated from widespread cultural stereotypes rather than a conscious intention to harm women” Interestingly, females academic’s outputs could be evaluated lower even by females themselves, which is confirmed in an experiment on students. Fox and Stephan (2001) They wanted to compare the objective and subjective image of PhD students toward their career prospects. They found that in certain fields (such as electrical engineering) females have higher hope to get a job as teaching in universities rather than working in industry which might be due to the expectation they have and think that “this is the option open to them”. Buber, Berghammer, and Prskawetz (2011) They mention the high childlessness rate of academic females in Austria and Germany. And they want to relate the childbearing behavior of female scientists with their ideals and subjective idea of how many children they want to have. They wanted to analyze whether high childlessness and low numbers of children are intended or not. They claim that several obstacles impede childbearing like: strong work commitment of the female scientists, need to be geographically mobile, high prevalence of living apart together relationships. Female scientist return back to work quickly after they have a child. Sheltzer and Smith (2014) Females make up over one-half of all doctoral recipients in biology-related fields but are vastly underrepresented at the faculty level in the life sciences. They have reviewed data of research institutes websites and counted the number of male and female PhD and post-docs that are hired compared by the gender of supervisor. They have found that male faculty members hire less female graduate students and post-docs than female faculty members did. Then they have separated prestigious (elite) scientists and looked at their hiring behavior too. They have found that male prestigious scientists tend to train less females compared to other male scientists. While female prestigious scientists do not show a gender bias in hiring. They found that new assistant professors of these departments are mostly postdoctoral researchers from these departments, so the above trend gets reproduced in new faculty hiring as well. They comment that this observation might be due to exclusion of females or self selected absence of females. Renzulli, Aldrich, and Moody (2000) They studied business start-ups. They conceptualize social capital and compared it between males and females. They found that having more kin and more homogeneity in the network can be a disadvantage for the entrepreneur compared to having more females or being a female entrepreneur. Cain and Leahey (2014) They qualitatively study why females are more integrated in some fields (like psychology and life sciences) and less in other fields (engineering and physics) through analyzing accounts of scientific success in these fields. Kahn (1993) They have studied females’ progress among PhD academics in the filed of economics and management which is a highly male dominated field. Many people in corporate and government circles believe that there is a glass ceiling limiting females’ advance to the highest levels of management and professional jobs. Observing and finding gender differences is good and necessary, and it can signal a discrimination going on, but we can not make sure in explanation unless we look and control for probable self-selection bias by females not to continue an academic career, or different amount of effort and talent (if we can measure it) or differences in educational level or in case of analyzing publications, it can be a discrimination happening by the gatekeeper effect of journal editors and peer review process dysfunctions: Gender differences might arise because women and men, faced with the same options and opportunities, have made different choices or investments in their careers; or gender differences might arise because of discrimination at some other level, for instance among journal editors and funding sources or during the educational process. Thus, a finding of gender differences in the hiring and promotion of females in a particular academic field is a necessary but clearly not sufficient condition of discrimination, flagging areas of potential concern. Sotudeh and Khoshian (2014) They have looked at publications and citations of male and female nano-scientists and have found that although number of female scientists in this field are lower, their research productivity and impact is similar to their male counterparts. E. B. Araújo et al. (2017) They have analyzed a sample of 270,000 scientists and found that males are more likely to collaborate with other males, while females are more egalitarian. This holds through different fields and while increasing the number of collaborators each scientist has with the exception of engineering. Considering inter-disciplinarity, males and females behave similarly with exception of natural sciences where females with many collaborators tend to have more collaborators from other fields. Nielsen et al. (2017) They start with claiming that teams (working on scientific projects) can benefit from different kinds of diversity, like scientific discipline, work experience, gender, ethnicity and nationality. But they add that it is not enough to add females to the groups and wait for innovation and efficiency to increase, instead they suggest that it is possible to find a mechanism to build up teams with diversity and reach to the optimum outcome. For example: Women are nearly eight times more likely to lead research projects in biotech firms with flat job-ladders than in more hierarchical academic and pharmaceutical settings. However, even flat structures are not effective unless the newcomers (women or underrepresented minorities) hit a critical mass, defined as representing between 15% and 30% of team members. Recruiting women is not enough: Carefully designed policies and dedicated leadership allow scientific organizations to harness the power of gender diversity for collective innovations and discoveries. Put simply, we can’t afford to ignore such opportunities. Nielsen (2016) Cross-sectional bibliometric study on 3,293 male and female researchers in a Danish university. Looking at link between gender and research performance. It provides evidence challenging the widespread assumption of a persistent performance gap in favor of male researchers. Light (2009) This study reviews prior work on why and how gender inequality affects scientific careers through looking at scientific publications. Light (2013) He has studied publications in AJS and ASR looking at organization of science into specialties. He thinks that these organization of sociology into subfields can be a kind of organizational identity which is working toward disadvantage of females. Using sociological work as a case, these analyses delineate how occupational identities contribute to and differentiate publication success – and thus status hierarchies – for men and women in the field. Potthoff and Zimmermann (2017) They are focused on the issue of gender homophily in citations which is mentioned in other articles, that male authors tend to cite male authors more rather than female authors. Multiple studies report that male scholars cite publications of male authors more often than their female colleagues do — and vice versa. This gender homophily in citations points to a fragmentation of science along gender boundaries. However, it is not yet clear whether it is actually (perceived) gender characteristics or structural conditions related to gender that are causing the heightened citation frequency of same-sex authors. Since scientists tend to cite people working in their own research area, then differences among male and female scholars and their focus in different research areas plays a role in this citation homophily behavior. And gender homophily in citations is partly due to topical boundaries. Interesting to note is that in some of these studies the issue is analyzed from a feminist point of view, that males are discriminating against females in a conscious way, and they often provide prescriptive suggestions on how policy makers or activists in science should take action to limit this kind of bias. There are other studies that takes experimental approach and in practice investigates whether there is a bias in evaluating research work of female and male authors. They found that even females were evaluating other female authors’ works lower. They conclude that the bias can be unconscious. There is studies about human capital stating that the structural forces at work have lead females, from educational point of view, to opt-in for more qualitative specialties and have a different image of themselves. Later, they tend to work in more qualitative fields and subjects which are less central to fields of science and less effective. This causes their works to be valued less and noted less rather than their male counterparts. Cole and Zuckerman (1987) This is one of the pioneering studies on the gender differences in research productivity. They were first to call it research productivity puzzle. It is a qualitative study based on interviews with male and female scientists. Both elite scientists and rank and file (normal scientists) are studied. They have asked academics to comment on their own publication trajectory (timeline), adding demographic and life events (e.g., PhD graduation, marriage, child birth and divorce). They tried to explain increases or decreases in the productivity using these life events and academics’ own interpretations. They claim that females publish less than males, but marriage and motherhood is not the cause. Since they controlled for it and married females with children are publishing equal to their single female counterparts and both of these groups are significantly publishing less than males. Long (1992) They wanted to provide a multidimensional, longitudinal description of the productivity differences between male and female biochemists. They observed that sex differences in publications and citations increased during the first decade of the career but are reversed later in the career. The lower productivity of females results from their over-representation among non-publishers and their under-representation among the extremely productive. Surprisingly, in comparison to other, they saw that patterns of collaboration is similar between males and females. They found that females’ papers on average gets more citations than males, and their lower overall citations are not due to quality of their papers but due to lower number of papers they publish. González-Álvarez and Cervera-Crespo (2017) They have studied 30 neuroscience journals in years 2009-2010 including a total of 66,937 authorships with 79,7 % of the genders being identified that includes 67.1% of male authorships. Surprisingly they observed that females seem to be concentrated as as first author (jonior) position and much less in last (senior) position, which they conclude could be a sign for more participation of females in recent years. In spite of important advances made in recent decades, women are still under-represented in neuroscience research output as a consequence of gender inequality in science overall. Paul-Hus et al. (2015) They claim that social media context can be more gender equal than scientific community which is male dominated. They have looked into the social media metrics to measure impact of research by male and female authors. They wanted to see if impact (as publicity in social media) is different than research impact measured by citations a paper has received. They find significant differences for female authored works impact on social media and they attribute it to male dominance in science compared to more equal context of social media which allows works of female authors to be noticed. The implications for the use of social media metrics as measures of scientific quality are discussed. Burt (1998) He discusses his theory of structural holes and using them to access resources in form of social capital, but he mentions a puzzle, which is the case of females: The entrepreneurial networks linked to early promotion for senior men do not work for women. He claims legitimacy could be the reason of this because females are not accepted as legitimate members of the population, and he is developing over the concept of borrowing network of a strategic partner to get access to social capital. Cole and Zuckerman (1984) It is different from their other article (Cole and Zuckerman 1987). This is more bibliometric and quantitative analysis of publication histories. They have carefully build up a sample of 526 male and female scientists who received doctorates in 1969-1970 with matched profiles (based on department and time of graduation). They found that if impact, in terms of number of citation, is compared in a paper by paper basis, females are cited as often or slightly more often than males, but because females publish less, their work has less impact in the aggregate level. They have examined three explanations for gender differences in productivity: There is no support for the view that women publish less because they collaborate less often than men, when collaboration is measured by extent of multiple authorship. Nor are overall gender differences in citation attributable to gender differences in first authorship, Women are first authors as often as men. Last, there is support for a hypothesis attributing differentials in productivity to differential reinforcement. Women are not only less often reinforced than men, reinforcement being crudely indicated by citations, but they respond to it differently. Women were less apt to maintain or increase their output and more apt to reduce it than comparably cited men at the same levels of prior productivity. Reinforcement has less effect on later output of women than of men. Although gender differences in output and impact are statistically significant, their substantive importance is not self-evident. It is not clear whether observed gender differences signal real disparities in contribution to science. Nor is it clear how productivity should be measured over the course of scientific careers. Questions are also raised about the nature of age, period, and cohort effects at the institutional and societal levels. T. Araújo and Fontainha (2017) They have used a network based empirical approach to build up networks of scientific subjects. They have build five categories of authorships: Our results show the emergence of a specific pattern when the network of co-occurring subjects is induced from a set of papers exclusively authored by men. Such a male-exclusive authorship condition is found to be the solely responsible for the emergence of that particular shape in the network structure. This peculiar trait might facilitate future network analysis of research collaboration and interdisciplinarity. Rivera (2017) She focuses on an interesting topic on the gender discrimination in hiring in academic careers and how hiring committees operate. She calls it “relationship status discrimination”. In this qualitative case study, she found that hiring committees infrequently ask about relationship status of male candidates, while they asked frequently about this from female candidates. When the female candidates partner were working in academic or high status jobs the committee consider them not movable and they exclude these candidates when there were viable male or single female alternatives. Beaudry and Larivière (2016) Female authored papers receive less citations. They add that authors who write with higher number of female coauthors also receive lower citations. They have analyzed the funding and impact factor of journals and size of collaborative teams. They found also that when females aim for the journals with high impact factors as their male counterparts, their probability of getting cited is lower. Hancock and Baum (2010) Similar to other works reviewed: Numerous studies covering a variety of social and physical sciences have regularly concluded two major things about women and academia: (1) women publish less than men, and (2) women make up declining percentages of the professorate as we move up the ladder from assistant to associate to full professor. They discuss the two main explanations put forward by literature that possibly females choose to leave academia which is not a welcoming environment for them, or they are being forced out of academia due to their lack of human capital in terms of publications standards and impact measurements which is termed as leaky pipeline for them. our paper focuses on those women who wish to remain in academia, regardless of how friendly or unfriendly the institutional climate, but do not make it past the assistant professor rank. They present vast descriptive results of background and demographic information on scientists: Our 2009 survey of the members of the International Studies Association (ISA) and subsequent analysis addresses this issue in two ways. First, we wanted to see if women are in fact producing at lower rates than men in international studies, as the literature finds happens in many disciplines. Second, we wanted to understand what factors affect publication rates during the assistant professor years. We focused on the assistant professor years because if women do not publish enough early in their careers, they are presumably far less likely to have long-term academic careers. Our findings suggest a variety of ways in which universities might change their policies to better aid assistant professors in achieving research records that will earn them tenure, and in which individual scholars might think strategically about their research and publications. Barnes and Beaulieu (2017) They discuss an initiative in political science started to improve females participation through yearly conferences through VIM project (Visions in Methodology). They found that females who attend VIM conference are better networked and more productive in terms of publication. 8.3.2 Diversity Lamont (2017) Her essay has 3 parts, in the first part she is focused on moral boundaries in the making of inequality. The second part is focused on exclusion, and part three on academia and academic evaluation and different standards for academic excellence. In part 3, I argue that in the world of of academia, it is crucial to recognize that different disciplines are best at different things and that they shine under different lights. One model (e.g., the standards of economics) does not fit all, even if the institutionalization of international standards of scholarly evaluation aims to eliminate differences. She investigates neoliberalism and how US academia and scientific context is more ready and positive towards “Peer Review” because they have been applying its procedures from long ago and they have a lot of players in the academic system in shape of universities and institutions spread over the states. On the other hand Europe and for example France which have a more central scientific system which can have veto power over the Peer review decisions. She mentions her results in her book (Lamont (2009)) and how different academic disciplines can have different evaluation and excellence measurement procedures and values to define worth and who is worthy to be praised and promoted. Puritty et al. (2017) They ask a good question about diversity in STEM fields: Simply admitting an URM student is not enough if that student feels unwelcome, unheard, and unvalued The current system attracts and retains a relatively narrow range of individuals. Does it produce good scientists? Yes. Does it facilitate a diverse scientific community? Not so much. 8.3.3 Research collaboration (broader views) Katz and Martin (1997) They tried to nswer some broad questions such as what is research collaboration, what motivates scientists to collaborate and h_ow to measure collaborations_. They consider coauthorship as a partial measure of research collaborations and they discuss the limitations of it. They review the literature on four different subjects related (or possible to be categorized as sub-groups) of research collaborations. Laudel (2002) Based on interviews with scientists they have tried to ask about content of collaboration and build a micro theory of it. They found six models of collaborations. They provide interesting insights about collaborations that do not get rewarded. 8.3.4 Research Productivity Fox (1983) They focus on Personality traits of “successful scientists”. “Aligned with these investigations of personality structure are studies which focus upon the biographical background of scientists. These biographical studies have probed a wide range of items including early childhood experiences, sources of derived satisfactions and dissatisfactions, descriptions of parents, attitudes and interests, value preferences, self-descriptions and evaluations. The aim is to determine the biographical characteristics, experiences, and self-descriptions which differentiate the highly productive and creative, from the less productive and creative, scientist. From these studies, one set of biographical attributes emerges strongly and consistently: eminent and productive scientists show marked autonomy, independence, and self-sufficiency early in their lives. This autonomy is apparent in early preferences for teachers who let them alone, in attitudes toward religion, and in dispositions toward personal relations. In their personal relations, specifically, the creative and productive scientists tend to be detached from their immediate families, isolated from social relations, and attached, instead, to the inanimate objects and abstract ideas of their work. These scientists emerge as ‘dominant persons who are not overly concerned with other persons’ lives or with attaining approval for the work [they are] doing’.” (p 287) Hargens, McCann, and Reskin (1978) They have studied whether marital fertility is associated with lower levels of research productivity. Their results show a negative relationship between the two among chemists in USA which holds same for both genders. Pepe and Kurtz (2012) It is a PhD thesis focused on networks of coauthorships, communication activity on mailing list and interpersonal acquaintanceship among members of an interdisciplinary modern laboratory. They found a fluid, non-cliquish, small-world like network of coauthorships, that has overlaps in communities building the whole structure between coauthorship and acquaintanceship networks. Based on this study, he has developed and introduced a digital platform for coauthorship and publications for scientists to collaborate online. Wootton (2013) They have an interesting focus on author name(s) order and position in the by-lines of papers and metadata. They explore how it is possible to use this order to weight the contribution of authors to papers, as it is the general practice in hard and natural sciences. Abramo and D’Angelo (2011b) This is the main and starting paper of Abramo and others which they propose their micro economic function to calculate FSS for research productivity. They discuss how it is possible to use this formula to calculate aggregate research productivity in institution, academic disciplinary sector or national levels: \\[FSS_R = \\frac{1}{t}\\sum_{i=1}^N \\frac{c_i}{\\bar{c}}f_i\\] Abramo, D’Angelo, and Di Costa (2008) They added impact factor of journals to the formula of FSS, but only in university level and not in the individual level. Ellwein, Khachab, and Waldman (1989) For productivity of authors, beside the number of publications, they take the impact factor of journals and author name position in the by-lines of paper into account: \\[P = \\sum_{i=1}^N W_i*Z_i\\] Opthof and Leydesdorff (2010) They focus on document types (publication types) to calculate the impact of paper by dividing it over the average of impact of that type of publications (e.g., books are compared with citations of all the other books in the sample, article with other articles and reviews with each other) Abramo and D’Angelo (2014b) They added academics’ salary to the calculation of FSS. Abramo, Cicero, and D’Angelo (2013) Field of science and academic rank of scientists are added to FSS. Batista, Campiteli, and Kinouchi (2006) They introduced a new calculation method for h-index. Abramo, D’Angelo, and Di Costa (2011) and Abramo and D’Angelo (2014a) They have used FSS for research productivity measurement. They have tried to compare it between academic ranks. Barjak (2006) They have tried to measure computer and internet mediated communication effect on research productivity. Abramo, Cicero, and D’Angelo (2012) They used FSS to measur research productivity in two time frames, cross-sectional, and with different scaling and standardization with mean and median. Finally they found that mean of the citation distribution (for the community) is the better measurement strategy. Egghe (2010) A review of the literature on h-index and its variants and alternatives. Bornmann (2010) They point to skewness of citations distribution and whether to use median or mean to standardize the citations of each publication compared to the community. Way et al. (2016) Existing models and expectations for faculty productivity require revision, as they capture only one of many ways to have a successful career in science. They have studied all the professors in 205 PhD granting institutions in USA and Canada in Computer science field. They have a time series view toward all publications in the scientists career. They have used a sensitivity analysis method to investigate the entire career of the scientists, and then define if the number of published papers are decreasing or increasing. Taking a focal point into account, they then compare the slope of the trend of publications counts before and after that change point. They found four different types of trends and they conclude that only 1/4 of the scientists follow the trend that is mentioned mainly in literature, to have an increasing productivity in early career which then decreases. Leahey (2007) By looking at two disciplines (including sociology and ASR and AJS journals), this study tries to control for specialization effect on research productivity and earnings and salary. 8.3.5 Coauthorship and modelling tie formation Abramo, D’Angelo, and Murgia (2013) Looking at the italian case of coauthorships and how to evaluate propensity of authors to collaborate or not using a simulation. Moody (2005) His differentiation of citation, topics and collaboration networks and also research communities that is the merger between topics and collaboration networks are interesting. It seems this presentation is based on Moody (2004). Here he mentions that sociology is an interstitial discipline (based on Abbott (2001)), meaning that sociology is working on subjects that are borrowed from other fields or there are overlaps with other fields, so it can be considered as a field in the space between other fields which does not have clear borders with them while those fields have clear separations in their idea spaces. Moody (2004) He compares three competeing theories in an effort to explain the structure of collaboation networks in sociology (from ASR and Sociological abstracts). These include 1) A highly clustered network similar to small world phenomenon which is the description based on highly divided picture of sociology that has theories without an overarching theory and composed of multiple disconnected research specialties, 2) A structure mainly concentrated around star scientists with preferential attachement mechanism at work, and 3) A structurally cohesive network. He starts with the idea of _structural cohesion from Durkheim and others which can generate coherent idea systems. He reviews literature on how sociologcial community and collaboration structure looks like, the first assumption is the high divide between different sub-groups of sociology with different theoretical and empirical specialties, which signals a communitiy with clear cut clusters which are connected to each other only by few links and this structure is closest to a small world. Second view is the star production which implies some leaders with high number of publications and citations who are leading the idea space. The structure of network follows a preferential attachement and new members who join the collaboration network work with those who have already a high prestige and status in the network. The third hypothesis is a strucuturally cohesive network in which there is not clear fissures or breaks between different parts of the network which implies that authors of different idea spaces and theories need to refer to each others’ work and those members of the community with high specialty in methodologies and techniques can acquire key positions and status among different sub-sets of the community. “Moody and White (2003) show that this network feature can be exactly characterized as the extent to which a network will remain connected when nodes are removed from the network.” Leahey (2016) In this review article, she is focused on the trends of collaboration in scientific articles and the trend toward more team work in science from sole investigator to team scientist. Rumsey (2006) A PhD thesis with six years sample of four main journals in field of higher education field. She tried to see coauthorship network structures and success in publications and came up with seven grouping of coauthorship strategies authors use based on social capital theories (emphasizing on Burt’s structural holes and Coleman’s Cohesion). Scientists who use both cohesive relationships and bridge between different disconnected communities to increase their publication chances (called complex strategy in this work) are the most interesting cases that manage between coordination costs and pros of cohesive groups in their publication activity. Kuzhabekova (2011) A PhD thesis following Rumsey (2006) on case of Russian Cardiology researchers’ publications. She used Rumsey (2006)’s seven categories of coauthorships to evaluate it in a different sample. Wuchty, Jones, and Uzzi (2007) Presents a big data set on different branches from hard to social sciences. They present a similar trend toward more team work and team production of science. Hill (2009) A PhD thesis and collection of three studies: A method to examine personal and egocentric networks of scientists and how it has affected their decision to go for STEM fields and academic career How various types of collaboration and position in network impacts research productivity of scientists Identifies the knowledge environment to facilitate staffing and knowledge management in scientific collaborations by looking at who knows what 8.3.5.1 Temporal community detection, multiplexity and blockmodelling Mucha et al. (2010) In this paper which is inspiration behind Traag (2014), authors develop and present a new set of models for community detection which can operate on multiplex and temporally evolving networks. It can be applied on the case of coauthorship networks over time. They discuss three samples of data on U.S senate votes which is temporally evolving, students network which is multiplex and Zhacary karate club network with different scales, to see which scale will best match the communities already found in this network. Traag (2014) A PhD thesis in which he is suggesting new developments to the mathematical models developed and suggested in Mucha et al. (2010) to allow community detection for temporally evolving, multiplex, weighted and singed networks with negative ties. Sciabolazza et al. (2017) They use commmunity detection algorithms for a network of coauthorships with two type of ties, writing papers together and writing grant proposals. They try to detect communities which are persistent over a three-year period. They then control their results with an ERGM model. Traag, Krings, and Van Dooren (2013) They discuss how it is possible to define if partitions (communities detected) are meaningful. Rosvall and Bergstrom (2010) This paper along with Reda et al. (2011) are among the pioneers in suggesting to use Alluvial plots to represent temporal evolution of networks and communities detected in them. Yang, Algesheimer, and Tessone (2016) A review of different community detection techniques and procedures on how to choose the best among them. Based on their review of different algorithms: Our results indicate that by taking both accuracy and computing time into account, the Multilevel algorithm, which was proposed by Blondel et al., outperforms all the other algorithms on the set of benchmarks we have examined (although the modularity-based methods are known to suffer from the resolution limit of modularity) Tantipathananandh, Berger-Wolf, and Kempe (2007) Along with their others works (e.g., Reda et al. (2011) and Berger-Wolf, Tantipathananandh, and Kempe (2010)) they discuss the matter of how to detect communities in dynamic social settings and networks. They mention the hardships of temporal community detection and how change in social networks causes the community detection task to be harder than it is supposed to be. Ahajjam, El Haddad, and Badir (2018) They suggest a new methodology to detect leaders in a social network based on centrality measures, then detect communities that have been formed around the authority of those leaders. Moody and White (2003) He presents his idea of structural cohesion and how to detect it in network, which points to the fact that if you remove nodes from the network and the network stays cohesive, it is structurally cohesive. Kronegger, Ferligoj, and Doreian (2011) This paper and comments and replies to it (e.g., Light and Moody (2011), Everett (2011), Doreian, Ferligoj, and Kronegger (2011)) should be looked at as one of the main examples of using blockmodelling for coauthorship networks analysis. Sinkovits et al. (2016) In this paper they propose a method to detect communities after reducing the complexity of the big network graphs, they provide link to Github repository of their methodology’s R scripts. 8.3.5.2 On ERGM, TERGM, SAOM, BERGM Lusher, Koskinen, and Robins (2013) Main textbook describing Exponential Random Graph Models (ERGMs) and pre-conditions to use them. Snijders (2001) He introduces Stochastic Actor Oriented Models (SAOMs). This seems to be one of the first publications in which he is presenting SAOM and how it works. At the end he is mentioning limitations which some are already solved (based on their latest publications). In SAOMs, they try to model the tie formation taking time (previous ties, their formation, dissolution or persistence), actor level attributes, dyad and covariate level attributes and local configurations into account which adds a lot of explanative power, but computationally speaking, it is only applicable to small-scale networks. Snijders, Van de Bunt, and Steglich (2010) Another pioneering text on SAOMs. Zhang et al. (2018) In a study focused on how scientific collaboration is carried out through coauthorship network. They focus on different factors driving coauthorship tie formation and they evaluate hypothesis of homophily, transitivity and prefrential attachement through a rather extensive ERGM. 8.3.5.3 ABMs on science and scientific collaborations Bianchi et al. (2018) An Agent Based Model (ABM) study to simulate different scenarios and behaviors of scientists in a hyper-competititive era. In the literature review they mention interestingly how scientists might strategize and prioritize among their activities to deal with scarcity of resources. By putting more energy and effort on better paying activities (e.g., publications, and grant proposals) they might put less effort on teaching or peer review and other duties that have a voluntary quality and their payoff is less or none. Furthermore, normative tension can occur between the multifaceted priorities of individual scientists (i.e., high publication and citation scores, big grants, consideration and peer esteem) and the real priority of the scientific community, i.e., scientific knowledge development. Although intrinsic to scientific community since the Mertonian era, this misalignment between individual priorities and collective interests has intensified today due to institutional pressure on competition and increasing uncertainty for funding and careers (Balietti et al. 2016) 8.3.6 National VS international coauthorships Sandström and Van den Besselaar (2018) They have tried to do a comparative analysis of the national research funding and evaluation systems and control for some interesting variables like: Differences in funding systems (performance related or not), differences in the level of competition, differences in the level of university autonomy, and differences in the level of academic freedom. Frame and Carpenter (1979) They use 1973 Science Citation Index concluding: Basic research means greater international coauthorships; The larger the national scientific enterprise, the smaller the proportion of international coauthorship; International coauthorships is geographically driven, suggesting that extra-scientific factors (for example, geography, political factors and language) might have an influence F. Narin, Stevens, and Whitlow (1991) Using US national science foundation and European community citation data they conclude that: “Higher (more than two times) citation for papers that are written internationally, the level of international production of science was not dependent on country’s scientific production size and linguistic and cultural factors have a strong influence on international coauthorship, whose patterns are different among EU countries” Moed, Bruin, and R. (1991) They use analytical maps, qualitative, quantitative and bibliometric methods finding that: International scientific cooperation is increasing, Different factors both internal and external to science is effective on it Differences among countries and fields of science in this increase Freshwater, Sherwood, and Drury (2006) International research collaboration in health care has intensified and is frequently regarded as an indicator of quality and a way in which to develop and disseminate scientific knowledge to newly developing countries. They have tried to pinpoint some of the possible processes, practicalities and problems encountered when attempting to establish common ground Kim (2006) They focus on Korean physicist international collaborations and found that multilateral collaboration has increased considerably in the last 20 years though the proportion of international research collaboration remains stable. Bagshaw, Lepp, and Zorn (2007) This work is focused on resolving conflicts that arise during international research collaborations. Valuing diversity and developing cooperative goals, engaging in self-reflection and reflexivity, promoting collaborative dialogue, taking time, and developing trust are discussed as strategies to increase international engagement. Thakur, Wang, and Cozzens (2011) It is a qualitative study with interviews investigating North and South countries’ scientists have differences in motivations for international collaborations. Scientists’ interpretations of these collaborations and opportunities they have found are interesting. Leydesdorff, Park, and Wagner (2014) Using Science citation index and social science citation index in 2011 they found differences among countries. In some countries internationalization is more prevailing than domestic publications. They also probed into country groupings in collaborations. Poirier et al. (2015) By looking at OECD and non-OECD publications and patents from SCOPUS and PATSTAT, they found that: Number of scientific publications coauthored by researchers in OECD countries has a positive and very significant impact on the number of wind energy innovations patented in OECD countries. However, non-OECD countries produce a greater number of patent filings when their researchers collaborate with OECD countries. This suggests that there exist knowledge spillovers between OECD and non-OECD countries that particularly benefit non-OECD countries. Khor and Yu (2016) Using Web of Science data, they conclude that: There is a difference in impact of international collaborations on the citations between young and older universities. For most top institutions, the difference between the citations per paper (CPP) for their publications with and without international coauthorship is positive, with increase of up to 5.0 citations per paper over the period 1996–2003. Yet, for some Asian institutions, by attracting a lot of researchers with international background and making these collaborating “external” authors as internal researchers, these institutions have created a special kind of international collaboration that are not expressed in coauthorship, and the CPP gaps between publications with and without international coauthorship are relatively small (around 0–1 citations per paper increment) for these institutions. Gossart and Özman (2009) They study the case of social scientists in Turkey and their coauthorship networks. They provide comparisons to other countries in Europe and in conclusions they try to reflect on the individual scientists level, structural, contextual and national level factors driving scientific collaborations. This quote from Melin (2000) is interesting: “The scientists themselves should choose with whom they would like to cooperate, and under which forms. Initiatives and directives from politicians and funding agencies are not welcomed by the scientific community and can lead to the establishment of contacts with people other than the scientifically most interesting ones” Zhou and Bornmann (2015) They have looked at all the publications in WOS in a 30-year period (i.e., 1980–2010) to see the trend and growth of the publications from scholars affiliated to either China, Germany or both. They have described these trends and changes. 8.3.7 Fragmentation of sociology Merton (1942) Merton’s main article which puts forward the norms of science Universalism, Communism, Disinterestedness, and Organized Skepticism. Hargens (2004) He evaluates Merton’s effect in social sciences by looking at the works that cite merton’s papers. He concludes that in order to be an impressive scientist in social sciences, you need to have works that can be cited and notified by differnt sub-communities of social scientists. Leahey and Reikowsky (2008) and Leahey, Crockett, and Hunter (n.d.) A primary goal of this paper was to assess how specialization, a defining characteristic of modern science (Dogan &amp; Pahre, 1989, 1990), shapes sociologists’ collaboration styles. They have chosen 71 coauthored papers from four journals (American sociological review, social psychology quarterly, sociology and education and social science research). They did a mixed quantitative and qualitative (latent profile analysis) on them, to figure out the publication profile of sociologists. A total 21 authors have agreed and participated in their interviews. Their results point to the amount of specialization happened in sociology and how academics can collaborate with each other although these specializations has happened. Turner (2006) Turner here mentions what happened to sociology that is so fragmented and incoherent and what can make a discipline cohesive. Babchuk, Keith, and Peters (1999) They compare sociology with other disciplines investigating the trend toward more collaborative sciences and coauthorships which is slower in case of sociology and mathematics. 8.3.8 Specialization and promotion Leahey, Keith, and Crockett (2010) Their main question in this paper is: What does it take to get tenure in an academic discipline? They have analyzed a sample of sociology PhD graduates and built a measure of research specialization. They found that a high specialization has negative effect on promotion in case of males. 8.3.9 ANVUR and Peer review versus bibliometrics Marzolla (2016) This article looked at reports published in ASN (National Scientific Qualification) in Italy. He analyzed the lenght and wordings of the reports and compared them between different academic sectors in Italy concluding that there is no equivalence in quality of the evaluation and reports to candidates which needs to be assessed in future rounds of ASN. Hicks (2012) She did and exhuastive literature review on Performance-based university research funding systems in different countries and academic systems. She tries, in one part, to give comparative view on how research evaluation results are effective on the life of researchers. Marginson and Van der Wende (2007) Authors review and compare existing rankings of universities, e.g., Times Higher education, and Shanghai ranking. They discuss the shortcomings and advantages of each and they introduce CHE ranking from Germany. At the end they conclude on some necessities that rankings and ranking systems need to meet in order not to bias the purposes and cause goal displacement in academia. They briefly mention the issue of rankings becoming the goal instead of the mean and serving the hyper-competition and quantitative production mantra. Bornmann, Mutz, and Daniel (2013) They have replicated and evaluated Leiden Ranking 2011-2012 resutls with a mult-ilevel approach and at the end they have been able to explain some of the differences between the universities by nesting them in their countries. One of their important conclusions is that we need to put country level covarriates in the analysis while looking at universities and provide a ranking of countries. They have also criticised the level of changes publicised by universities when they are able to promote their place in the ranking. They claim if the right confidence interval measures are used, then it is possible to judge whether the changes happened in university’s ranking is significant or not (which is when the Goldstein-adjusted confidence intervals do not overlap). Claassen (2015) He has used a Bayesian hierarchical latent trait model to compare results of the eight different university rankings and he concludes that some of these rankings are biased in favor of the universities in their own countries. At the end he presents two of the rankings with lowest bias and highest fairness: The two unbiased global rankings, from the Center for World University Rankings in Jeddah, and US News &amp; World Report are also the two most accurate. Abramo and D’Angelo (2011a) National research assessment efforts, and how policies like ANVUR in Italy want to evaluate research productivity versus bibliometric assessments and comparing these two methods of evaluation in terms of costs, pros and cons. They mention six evaluation criteria, briefly: Accuracy; The degree of closeness of performance indicators measurements to their true value Robustness; The ability of the system to provide a ranking which is not sensitive to the share of the research product evaluated Validity; The ability of the system to measure what counts Functionality; The ability of the measurement system to serve all the functions it is used for Time; The time needed to carry out the measurement Costs; The direct and indirect costs of measuring At the end they conclude that considering cost and time effectiveness of bibliometric evaluations, they can be at least adopted for formal and natural sciences, and for other disciplines like humanities and social sciences, peer review could be the preferable choices. Abramo, D’Angelo, and Caprasecca (2009a) This paper which is one of the first works of the authors in the series they have published on research evaluation and assessment. It uses a database of hard sciences in Italy, the whole publications as claimed, to compare peer review results of VTR evaluation with bibliometric evaluation. They conclude (same as in Abramo and D’Angelo (2011a)) which in hard sciences bibliometric methods can be a good approach for evaluation and funds allocation with the pros and cons discussed in the paper. Boffo and Moscati (1998) He focused on research evaluation acts in Italy. At the end he is suggesting that one of the different evaluation procedures he suggested need to be selected and put in action in Italy. And this is one of the first works that mentions the tensions in Italian academia after the idea of research evaluation is mentioned. Like the ambiguities in law and decrees. They discuss the role MIUR should play in Italian academic evaluation and pros and cons of having external or internal (or both at the same time) evaluators. Obviously, an academic that is not accustomed to being evaluated will prefer internal evaluation as the lesser evil Bertocchi et al. (2015) They have chosen 590 random papers among 5681 which have been reviewed by ANVUR in VQR 2004-2010. They have compared bibliometric and peer review evaluation of these papers. They have found close and significant agreement between the two methods of evaluation. They have been focused only on some fields from VQR 2004-2010: In this paper, we draw on the experience of the panel that evaluated Italian research in Economics, Management and Statistics during the national assessment exercise (VQR) relative to the period 2004–2010. They clearly mention the difference between blind peer review (the normal peer review) and the “informed peer review” that ANVUR and VQR have applied in their evaluation, which means, refrees are aware of the identity of the authors and where the papers have been already published. This causes some biases in the evaluation and in their results to compare peer review with bibliometric statistics. In other words, we cannot disentangle whether the correlation that we observe depends on an intrinsic relation or on the influence of the information on publication outlets on the reviewers. As a consequence of this caveat, we need to be clear about the policy implications that we can draw from our analysis. Particularly, as noted, we cannot make any claim about the validity of bibliometrics as a substitute for peer review, let alone advocating the substitution of the informed peer review process with bibliometric assessments. The goal of the VQR exercise is to evaluate published work of Italian academics between 2004 and 2010, and therefore this limitation is imposed on us by the very structure and goals of the VQR exercise. Future VQR waves could compare bibliometric analysis and peer review using anonymized published material so that neither the publication outlet nor the name of the authors are revealed to the reviewers. Franceschini and Maisano (2017) They have collected and organized the criticisms directed to VQR 2011-2014 (e.g., Boffo and Moscati (1998), then after VQR 2004-2010, e.g., Baccini and De Nicolao (2016), and after VQR 2011-2014 and three next correspondences are here (Benedetto et al. (2017b); Abramo and D’Angelo (2017); Benedetto et al. (2017a))) They mention three main critical methodological vulnerabilities of the VQR 2011–2014, partly inherited from the VQR 2004–2010, are: Small sample of papers evaluated for each researcher Incorrect and anachronistic use of journal metrics for assessing individual papers misleading normalization and composition of Ci and Ji We are doubtful whether the whole procedure – once completed thanks to the participation of tens of thousands of individuals, including evaluation experts, researchers, administrative staff, government agencies, etc. – will lead to the desired results, i.e., providing reliable information to rank universities and other research institutions, depending on the quality of their research. We understand the importance of national research assessment exercises for guiding strategic decisions, however, we believe that the VQR 2011–2014 has too many vulnerabilities that make it unsound and often controversial. Solutions they suggest: Major vulnerabilities of the VQR 2011–2014 can be (at least partly) solved by (1) extending the bibliometric evaluation procedure to the totality of the papers, (2) avoiding the use of journal metrics in general, and (3) avoiding questionable normalizations/combinations of the indicators in use. Finally, the introduction of the so-called altmetrics could be a way to solve (at least partly) the old problem of estimating the impact of relatively recent articles, without (mis)using journal metrics. Benedetto et al. (2017b) This is an answer to the criticisms raised by Franceschini and Maisano (2017), which mainly considers their critics as not valid or not constructive and they believe authors didn’t read the VQR documents carefully. They answer the criticisms on small sample of research work evaluated, by saying that asking for all the papers published in the period under study is against the principle of treating all areas equally, and it has never been adopted by RAEs or REF in UK. To answer use of journal’s impact as a bibliometric indicator they pose three reasons, large number of community under evaluation, recentness of the publications, and use of two bibliometric indicators instead of one. And for other points on normalization and combination of bibliometric indicators they cite a response on “La Voce” website that they have given recently and they point out that authors didn’t give alternative proposals for the criticisms they raise, i.e., their criticisms are not constructive. Abramo and D’Angelo (2017) This a type of comment on answer of Benedetto et al. (2017b) to criticisms of Franceschini and Maisano (2017) which mainly supports the criticisms and tries to show the answers were not sufficient. They start by mentioning that Benedetto et al. (2017b) have seen all the criticisms as “not-constructive” and lacking proposals of alternatives. They claim that ANVUR staff did not have the necessary knowledge for the evaluation and they were not ready to receive and accept constructive suggestions. So there was a knowledge transfer failure from scientists to practitioners. And they believe that ANVUR previous and current memebers do not have relevant CV and experience to handle a national scale research evaluation exercise. Benedetto et al. (2017a) This is answer of the ANVUR members to Abramo and D’Angelo (2017). They start by stating that Abramo and D’Angelo’s idea of a “Scientometric model of evaluation” that can be applied in different fields of science is a simplistic one and the case of national scale research assessment is more complex and multi-faceted. ANVUR has to evaluate not just research, but also teaching, administrative performance, social impact, student competence etc. which includes hard sciences to humanities and social sciences. The Italian legislator’s choice not to entrust it to scientometricians, but rather to leading scientists and scholars, competent in different fields and highly familiar with the higher education system in a plurality of countries, has been indeed a wise one. And the fact that Abramo and D’Angelo are not even capable to imagine the scope of such an evaluation, even if one remains within the boundaries of “research” (itself a rather differentiated system, which requires the intimate knowledge of scientists and scholars), is highly indicative of the limited horizons within which they move. Abramo and D’Angelo continue by asking the rhetorical question “Why did ANVUR then not enforce the ‘equality’ principle in this case, rather than offering bibliometrics for some and not others?”. Even in this case, the answer is very simple: there are scientific areas, such as social sciences, law, humanities, where bibliometrics indicators are totally unreliable. Whitley (2003) He discusses the macro level policies which might affect how science and scientific discoveries work, he mentions examples from countries with centralized control, e.g., a ministry, on top of higher education system and academia compared to countries without this type of central agency, such as USA, which tend to show different approaches in solving problems and making scientific discoveries. Baccini and De Nicolao (2016) This is another paper which discusses the experiment ANVUR did (mentioned in Bertocchi et al. (2015)) to check for the aggreement between informed peer review and bibliometric analysis of the publications and individual scientists’ productiviy or quality of publications. With this meta-analysis they find out that the results and acceptable and good levels of agreement that ANVUR reported was not right if you consider how to interpret Kappa scores used in the experiment, and they find only one exception of Area 13 which there could be a fair amount of aggreement between the two method of evaluation. They conclude that agencies should not substitute informed peer review and bibliometric evaluation results, since there is differences between the two and the Italian national assessment case is even more error prone, because they have mixed the two evaluation methods and it has made it impossible to disentangle the causes to say if a higher evaluation means a field had performed better science or it was due to higher percentage of bibliometric evaluation of papers (since based on ANVUR results, bibliometric evaluation was giving higher ranks to papers than informed peer review). Geuna et al. (2015) They compare the research assessment initiatives in UK, Italy and other EU countries, including notions of their costs and a brief history of each of the evaluation exercise. They conclude by contrasting two extremely different cases of UK and Italy, where the former has a performance based research assessment in place and the later has followed the UK case, but with more centralized view to research organization, funding allocations and research evaluations. They also point to the hardships of development, implementation and acceptance of a performance-based research funding, discussing the case of UK. Geuna and Piolatto (2016) Similar to Geuna et al. (2015), discusses the case of UK and Italy in national research assessment exercises: European university funding systems have experienced significant changes in the last 30 years. In all countries, non-government funding sources and performance-based competitive allocation systems have increased. The UK and the Italian models would seem to represent two extremes cases; the UK is a more competitive system involving more private funding (about 50% of total university funding), while Italy depends mostly on public funding (about 75% of total university funding) and especially on the central government bulk grant. Ancaiani et al. (2015) This is a paper by ANVUR staff and faculty describing the methodology (combination of bibliometric evaluation and peer review) they applied in VQR 2004-10 and results they achieved in university level. The Italian VQR 2004–10 has been an unprecedented research evaluation exercise, both for its size, having analyzed almost 185,000 research outcomes, and for the adoption of a highly innovative mix of peer review and bibliometric methods. Results obtained have been used by the Italian Ministry and by universities for funds allocation, respectively, at the University and department level. 8.3.10 Scientists geographical mobility Chinchilla-Rodrı́guez et al. (2017) In this article authors have gathered publications data from scientists from ten countries that are affected by US travel ban, they look at how authors who had at least one affiliation to one of these countries were collaborating internationally. They wanted to provide basis to give policy advice to politicians on the effects of these kind of travel bans on scientific productivity and collaborations. Jonkers and Tijssen (2008) Focused on Chinese scientists working abroad who return to China they found that: “Analyzing their mobility history and publication outputs, while host countries may lose human capital when Chinese scientists return home, the so-called “return brain drain”, they may also gain in terms of scientific linkages within this rapidly emerging and globalizing research field\" 8.3.11 Sociology of Academic labor Kalfa, Wilkinson, and Gollan (2018) Authors did in-depth qualitative interviews with academics from a university in Australia that has undergone major reforms in 2007 (e.g., adopting performance based research evaluation system) that has lead to exit of a share of their senior academics. This has been replaced with early career employees. They have focused on how academics react to this increasing managerialism in academia and they have found out that resistance and protest is not that much prevailing among academics. They have used metaphor of game which allows them to consider academics as participants of a game in which they are more and more embedded and they continue to legitimize the game by continuing to play by its rules. Blume (1987) This is a collection of articles published as a book and edited by known scientists in scientomertics and sociology of science. It is focused on the idea of how external players and factors can affect and shape production of science. This effect can stem from these external figures being involved in cooperation with scientists, or in case of constraining priorities of what should be studied by science by means of them providing financial support to scientists (i.e., influencing them in priorities). They cover different aspects of the subject, in reviewing the theoretical positions (e.g., p 3) they mention the distinction that marxist theoretician put between science (“direct knowledge” which “does not contain anything that indicates its social origin”) and research (“tied to social conditions and relations of production”). In another part (e.g., p 277), they focus on the topic of cooperation between social scientists and political actors and “The Policy-Oriented Social Sciences: The Rush to Relevance” which points to efforts by sociologists after world war II to provide answers to social issues in three cases of Italy, France and Germany, while this did not actually happen, at least not until 1960s. He discusses the different paths social sciences took in each of these countries due to relatively different relationship between scientists and political actors and the level of consolidation and instituionalization the scientific fields had experienced in each of those coutexts. They frame the idea behind the book and collection of articles (e.g., p 331) as an effort to comparatively study: “The”bottom up\" initiatives of scientists who wanted their research to be more socially relevant and hence had sought collaboration with non-scientific groups\" They mention (p 345): The traditional picture of internal cognitive criteria versus external non-cognitive criteria fades away, and a two-dimensionality of all the problems related to the science system emerges: between, on the one hand, the social actors intervening in the scientific enterprise, forming coalitions, inter-organizational structures, and arrangements, and the scientists stepping into these relations to mobilize resources or from more idealistic motives; while on the other hand, the substance of the demand is a cognitive reflection of what we might call the proto-scientific mode of a social problem. When the scientists are “over-powered” in such relations, they ought to resist; when they succumb in such a situation, for example because of resource dependency, they may be distracted from the cognitive goals of their fields, and in the long term their knowledge may be reduced to obsolete expertise. Musselin (2008) He starts from work of Mary Henkel and tries to provide the basis of how a sociology of academic work should look like. He provides comparisons and similarities and differences among the studies of academic work which can be similar to dichotomies, like being mertonian, or versus strong programme. He emphasizes that transformation of higher education institutions into managed organizations leads to some questions like: question of situation, condition of work, ways of producing and diffusing knowledge, norms and identities of the academic profession. Abbott (2000) In this paper Abbott talks about the probable future of sociology as a field, if it will survive or not: I realize that there are sociologists in commercial or governmental contexts, but in the United States sociology is dominated by an academic labor market and the training institutions that support that labor market. He argues that sociology is not as coherently centered around a method, as anthropology is around ethnography. Or it is not as coherently centered around a theory as economics is around choice theory or centered around a topic as political science is around power. 8.3.11.1 Burnout of scientists Gill (2009) In this book chapter, author presents many examples of the interviews with academics about their workload. The levels of stress they are experinecing and the notion of fast academia under the effect of neoliberalism which requires academics to be working over time (figures of surveys are presented): Many academics are exhausted, stressed, overloaded, suffering from insomnia, feeling anxious, experiencing feelings of shame, aggression, hurt, guilt and ‘out-of-placeness’ Hanlon (2016) This is similar to the issue of fear of missing out which can happen while scientists try to stay up-to-date with ever growing literature (similar to what discussed here) and it causes them stress. References "],
["references.html", "Chapter 9 References", " Chapter 9 References "],
["references-1.html", "References", " References "]
]
